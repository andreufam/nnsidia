{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDES NEURAIS I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, vamos usar a famosa coleção [MNIST](http://yann.lecun.com/exdb/mnist/) para construir uma rede neural capaz de classificar digitos escritos à mão. Está é uma rede neural conhecida como Multi-layer Perceptron (MLP). Ou seja, dada uma entrada, o modelo deve dizer que dígito ela representa.\n",
    "\n",
    "Esta seção cobre o conceito de Deep Learning e a criação do modelo de classificação com TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "# O que é Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning (ou aprendizado estruturado profundo, ou aprendizado heirarquico ou aprendizagem de máquina profunda) é uma sub-área da aprendizagem de máquina baseado em algoritmos que tentam modelar abstrações de alto nível em dados usando múltiplas camadas de processamento, com estruturas complexas ou não, compostas por múltiplas transformações lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/mod_ID_1_final.png\" alt=\"HTML5 Icon\" style=\"width:600px;height:450px;\">\n",
    "<div style=\"text-align:center\">Tempo de aprendizado profundo. Como no cérebro, modelos profundo se organizam em camadas. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rede neural \"profunda\":** redes neurais com mais de uma camada escondida, seja qual for o tipo da camada (convolutiva, pooling, normalização, totalmente conectada etc). Redes neurais profundas em geral conseguem melhores resultados que redes rasas com mesmo número de parâmetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Aprendizagem\":** no contexto desta aula, trata-se de aprendizagem supervisionada. Por exemplo, no caso de reconhecimento de dígitos, consiste na previsão do dígito correto apartir de padrões obtidos em um conjunto de observações de dígitos previamente conhecidos. Em nosso caso, o alvo da previsão é o dígito (0,1,2,3,4,5,6,7,8,9) e as observações são as matrizes de pixels das imagens dos dígitos. Após algum treino, espera-se que a rede aproxime a uma função que mapeie entradas (imagens dos dígitos) para as saídas (os dígitos). O processo de treino ocorre até que um certo de grau (desejado) de acuidade é atingido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "# Parte I: Classificando MNIST com um modelo simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos classificar MNIST usando uma MLP. Para se familiarizar com MNIST, leia: <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST Descrição</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que é MNIST?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database de digitos escritos a mão com 60000 exemplos de treino e 10000 para teste. É um sub-conjunto da coleção maior NIST. Os dígitos foram normalizados em tamanho e centralizados em uma imagem de tamanho fixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TensorFlow tem sua própria cópia de MNIST. Assim, obtê-lo é trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que usamos o argumtno <span style=\"background-color:#dcdcdc\n",
    "\"> One-hot = True</span>. Isso indica que as labels serão representadas como vetores one-hot. Assim, classes 0 e 5, numa taxonomia {0,1,2,3,4,5}, são representadas como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Dígito representado:     0\n",
    "                        [5]   [4]    [3]    [2]    [1]   [0]  \n",
    "One-hot vector:          0     0      0      0      0     1   \n",
    "\n",
    "Dígito representado:     5\n",
    "                        [5]   [4]    [3]    [2]    [1]   [0]  \n",
    "One-hot vector:          1     0      0      0      0     0   \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compreendendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados estão divididos assim:\n",
    "\n",
    "- Treino (mnist.train) >>  Dados que podem ser usados para treinar o modelo.  \n",
    "        - 55,000 instâncias\n",
    "        - mnist.train.images = entradas (pixels)\n",
    "        - mnist.train.labels = saídas (classes, rótulos, dígitos)\n",
    "  \n",
    "- Validação (mnist.validation) >> Dados que podem ser usados durante treino para testar o modelo, de forma a encontrar melhores hiper-parâmetros.  \n",
    "        - 5,000 instâncias\n",
    "        - mnist.validation.images = entradas\n",
    "        - mnist.validation.labels = saídas\n",
    "  \n",
    "- Teste (mnist.test) >> Dados usados para testar o modelo final. Representam os dados 'reais' ao qual o modelo seria usado se em uma aplicação real.  \n",
    "        - 10,000 instâncias\n",
    "        - mnist.test.images = entrads\n",
    "        - mnist.test.labels = saídas\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos um exemplo de uma imagem de treino:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c45e1d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c286b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.matshow(mnist.train.images[0].reshape((28,28)), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma sessão interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma prática comum é criar os placeholders antes das variáveis. Vamos usar os seguintes placeholders:   \n",
    "\n",
    "__Placeholder 'X':__ espaço para imagens de entrada. \n",
    "* Cada imagem tem 784 pixels em uma matriz 28 x 28   \n",
    "* Argumento 'shape' define tamanho do tensor.  \n",
    "* 1a dimensão = None. Indica que qualquer número pode ser usado (é o tamanho do batch).  \n",
    "* 2a dimensão = 784. Indica o número de pixels em uma imagem 2D linearizada.  \n",
    "      \n",
    "__Placeholder 'Y':__ saída ou labels.  \n",
    "* 10 classes (0,1,2,3,4,5,6,7,8,9)  \n",
    "* 'shape' é como antes, o tamanho do tensor  \n",
    "* 1a dimensão = None. Indica que qualquer número pode ser usado (é o tamanho do batch).  \n",
    "* 2a dimensão = 10. O número de classes.  \n",
    "\n",
    "__dtype__ o tipo dos tensores. Na dúvida, use tf.float32. A limitação é que a função softmax só aceita float32 ou float64. Para mais tipos, veja <a href=\"https://www.tensorflow.org/versions/r0.9/api_docs/python/framework.html#tensor-types\">Documentação do TensorFlow</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x  = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assinalando valores nulos para bias e pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós vamos iniciar bias e pesos com valores nulos. Como veremos mais tarde, a inicialização é uma decisão crítica. Mas, por enquanto, vamos usar uma estratégia ingênua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weight tensor\n",
    "W = tf.Variable(tf.zeros([784,10],tf.float32))\n",
    "# Bias tensor\n",
    "b = tf.Variable(tf.zeros([10],tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute o assinalamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos usando uma sessão interativa, para iniciar as variáveis basta rodar run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the op initialize_all_variables using an interactive session\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando pesos e biases para a entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from our next operation to the picture below is that we are using the mathematical convention for what is being executed in the illustration. The tf.matmul operation performs a matrix multiplication between x (inputs) and W (weights) and after the code add biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/mod_ID_2_final.png\" alt=\"HTML5 Icon\" style=\"width:400px;height:350px;\"> \n",
    "<div style=\"text-align:center\">Pesos e biases dos neurônios. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mathematical operation to add weights and biases to the inputs\n",
    "tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax é uma função de ativação normalmente usadas em problemas de classficação. Ela gera as probabilidades da saída. Por exemplo, o modelo não vai ter 100% de certeza sobre um dígito, digamos 9. De fato, ele vai retornar uma distribuição de probabilidade onde, se ele está certo, o 9 tem a maior probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de perda (loss, cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É a função usada para minimizar a diferença entre as respostas certas (labels) e o estimado pela rede. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), \n",
    "                                              reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de otimização: Gradiente Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TensorFlow suporta muitos otimizadores. Mas vamos usar o mais tradicional de todos, o Gradiente Descendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, vamos usar o _minibatch Gradient Descent_.\n",
    "\n",
    "Na prática, o _Batch Gradient Descent_ não é muito usado porque é muito caro. Para obter o gradiente real, ele tem que processar todas as instâncias de treino. Uma alternativa é estimar apartir de amostras do treino com um tamanho bem menor que o treino todo. Essa amostra é o mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load 50 training examples for each training iteration   \n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy for the simple ANN model is: 90.9200012684 % \n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "acc = accuracy.eval(feed_dict={x: mnist.test.images, \n",
    "                               y_: mnist.test.labels}) * 100\n",
    "print(\"The final accuracy for the simple ANN model is: {} % \".format(acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close() #finish the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "# Quão bom foi o resultado final?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não grande coisa. Em junho de 2016, o melhor resultado para essa coleção era 0.21% de erro (99.79% accurácia) <a href=\"http://cs.nyu.edu/~wanli/dropc/\">veja aqui</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "# Monitorando informações de interesse para posterior análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora analisar o desempenho do nosso programa usando o TensorBoard. Para isso, reorganizamos o código mudando os seguintes aspectos:\n",
    "* _log de informações_: vamos calcular e registrar as informações de custo e acurácia para posterior análise. O ciclo de vida de informação para log envolve:\n",
    "    - A criação de sumários, ou seja,as estatísticas que queremos registrar (várias funções tais como tf.scalar_summary);\n",
    "    - A combinação dos sumários em um única operação, para facilitar a sua execução (tf.merge_all_summaries);\n",
    "    - Escrita/registro físico do sumário (SummaryWriter e add_summary)\n",
    "* _Anotação de escopos e variáveis_: sem uma anotação, as informações fornecidas pelo tensorboard serão confusas. Assim e importante dar nomes para variáveis que nos interessam além de criar escopos. Estes também serão muito úteis em arquiteturas muito maiores para facilitar o compartilhamento de variáveis e aproveitamento de código. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Accuracy:  0.9213\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# reset everything to rerun in jupyter\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# config\n",
    "batch_size = 100\n",
    "learning_rate = 0.5\n",
    "training_epochs = 5\n",
    "logs_path = \"logs/mnist/2\"\n",
    "\n",
    "# input images\n",
    "with tf.name_scope('input'):\n",
    "    # None -> batch size can be any size, 784 -> flattened mnist image\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\") \n",
    "    # target 10 output classes\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")\n",
    "\n",
    "# model parameters will change during training so we use tf.Variable\n",
    "with tf.name_scope(\"weights\"):\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "\n",
    "# bias\n",
    "with tf.name_scope(\"biases\"):\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    # create a summary for *all* biases in this layer\n",
    "    tf.histogram_summary('biases', b)\n",
    "\n",
    "# implement model\n",
    "with tf.name_scope(\"softmax\"):\n",
    "    # y is our prediction\n",
    "    y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# specify cost function\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    # this is our cost\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), \n",
    "                                                  reduction_indices=[1]))\n",
    "\n",
    "# specify optimizer\n",
    "with tf.name_scope('train'):\n",
    "    # optimizer is an \"operation\" which we can execute in a session\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# create a summary for our cost and accuracy\n",
    "# which can be observed in TensorBoard\n",
    "tf.scalar_summary(\"cost\", cross_entropy)\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "# merge all summaries into a single \"operation\" \n",
    "# which we can execute in a session \n",
    "summary_op = tf.merge_all_summaries()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # variables need to be initialized before we can use them\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # create log writer object\n",
    "    writer = tf.train.SummaryWriter(logs_path, \n",
    "                                    graph=tf.get_default_graph())\n",
    "        \n",
    "    # perform training cycles\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        # number of batches in one epoch\n",
    "        batch_count = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for i in range(batch_count):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # perform the operations we defined earlier on batch\n",
    "            _, summary = sess.run([train_op, summary_op], \n",
    "                                  feed_dict={x: batch_x, y_: batch_y})\n",
    "            \n",
    "            # write log\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "            \n",
    "        if epoch % 5 == 0: \n",
    "            print \"Epoch: \", epoch \n",
    "    print \"Accuracy: \", accuracy.eval(feed_dict={x: mnist.test.images, \n",
    "                                                 y_: mnist.test.labels})\n",
    "    print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluída a execução, podemos agora acessar estatísticas sobre o modelo. Para isso, invocamos o tensorboard passando o log de dados:\n",
    "\n",
    "```\n",
    "> tensorboard --logdir=logs/mnist/2 --port=6006\n",
    "  Starting TensorBoard 29 on port 6006\n",
    "  (You can navigate to http://192.168.0.101:6006)\n",
    "```\n",
    "\n",
    "Ao navegar no endereço dado, você vai encontrar as estatísticas coletadas sobre custo e acurácia na aba Events. Na aba grafo, vc vai ver o Grafo de avaliação correspondente ao programa. Abaixo, podemos ver o grafo correspondente:\n",
    "\n",
    "<img src=\"images/tensorboard-example.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que se vc quiser ver o efeito de diferentes tunings de parametros, vc vai ter que rodar seu modelo múltiplas vezes, cada vez usando um diretório diferente para armazenar o log. No fim, vc pode rodar o tensorboard para analisar todos os runs. Por exemplo:\n",
    "\n",
    "`tensorboard --logdir=run1:logs/mnist/1,run2:logs/mnist/2 --port=6006`\n",
    "\n",
    "<img src=\"images/tensorboard-example2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Deep_learning    \n",
    "http://sebastianruder.com/optimizing-gradient-descent/index.html#batchgradientdescent  \n",
    "http://yann.lecun.com/exdb/mnist/  \n",
    "https://www.quora.com/Artificial-Neural-Networks-What-is-the-difference-between-activation-functions  \n",
    "https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este curso é baseado em material da [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). Assim, segue os termos da [licença do MIT](https://bigdatauniversity.com/mit-license/). Aula modificada por Marco Cristo apartir de versão de <a href = \"https://linkedin.com/in/luisotsm\">Luis Otavio Silveira Martins</a>, <a href = \"https://linkedin.com/in/erich-natsubori-sato\"> Erich Natsubori Sato </a></h4>. Material adicional de Imanol Schlag (https://ischlag.github.io/2016/06/04/how-to-use-tensorboard/) e Faizan Shaikh (https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
