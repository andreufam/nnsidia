{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LSTMs/GRUs e a CTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, usamos células em RNNs que consistiam de neurônios artificiais tradicionais. Agora, vamos passar a usar células que implementam memória de um ponto de vista funcional. Elas podem ser usadas no lugar de qualquer célula/unidade tradicional de uma RNN, sendo responsável por ler, escrever ou lembrar de informação fluindo no modelo. \n",
    "\n",
    "A LSTM, em particular, consiste basicamente de uma unidade linear (a celula de informação propriamente dita) envoltas por três portas lógicas, responsáveis pela manutenção dos dados. Uma é responsável por permitir que dados fluam para a célulade informação (entrada), uma pela saída da célula e a última é responável por lembrar ou esquecer de dados de acordo com as necessidades da rede. A GRU é uma versão mais simplificada da LSTM. Ela combina portas da LSTM em menos portas, produzindo um modelo menor.\n",
    "\n",
    "Estas unidades ajuam a resolver o problema de manter estados, porque a rede pode escolher esquecê-los se já não servem mais. Desta forma, o problema dos gradientes é menos importantes com LSTMs e GRUs. De fato, LSTMs e GRUs são tão convenientes que, na prática, pouco se usam RNNs com células que não sejam estas.\n",
    "\n",
    "Nesta aula, vamos usar LSTMs em problemas de reconhecimento de escrita.\n",
    "\n",
    "### Arquitetura Long Short-Term Memory \n",
    "\n",
    "Neste texto, vamos considerar que uma LSTM é formada por três portas lógicas: \"Input\" ou \"Write\", responsável pela escrita na LSTM de dados vindos do resto da RNN; \"Output\" ou \"Read\", responsável pela saída da LSTM para o resto da RNN; e \"Keep\" ou \"Forget\", rsponsável pela manutenção ou modificação de dados armazenados na LSTM.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagrama de uma Long Short-Term Memory Unit*</center>\n",
    "\n",
    "Se você estiver mais interssado em saber sobre LSTMs e suas variantes, incluindo GRUs, leia o blog: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectionist Temporal Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um típico pipeline de reconhecimento temporal, em deep learning, envolve uma rede neural para reconhecimento combinada com algum mecanismo que garanta a consistência no tempo.\n",
    "\n",
    "Por exemplo, na imagem abaixo, temos a representação de uma arquitetura usada em reconhecimento de fala. Nela, os componente neurais (os módulos em azul) são responsáveis por identificar o fonema apartir de algum sinal de entrada (o espectograma, features MEL ou o sinal puro de som, observados em um _frame_ de som). O componente de consistência temporal (no exemplo, a barra roxa que representa a função CTC, mas poderia ser uma HMM), por sua vez, lida com a sequência de possíveis fonemas sendo identificados para entender o que está sendo dito em geral. Em suma, este componente trata do contexto geral.\n",
    "\n",
    "![](images/ctc1.png)\n",
    "\n",
    "Em redes neurais, uma possibilidade para o componente temporal é a função CTC (Connectionist Temporal Classification) proposta por Alex Graves para o problema de reconhecimento de escrita manual (ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando como exemplo o problema de escrita manual, imagine que o usuário escreveu 'dançar'.\n",
    "\n",
    "![](images/dancar.png)\n",
    "\n",
    "Digamos que o nosso modelo está reconhecendo a terceira letra da palavra como sendo \"u\". Podemos dizer que o modelo está aproximando a probabilidade $p$(${\\bf y}$ = 'u' | ${\\bf x}$ = segmento de imagem correspondente à terceira letra em dançar) como a convicção que a rede neural, que está observando aquele segmento de imagem, tem de se tratar de um 'u'. Contudo, o correto seria 'n', algo que pode ser observado pelo contexto todo da palavra, já que 'dançar' é muito mais provavelmente uma palavra do Português que 'dauçar'.\n",
    "\n",
    "Assim, em vez de aprender uma letra por vez, é melhor aprender a sequência de letras que faz mais sentido.\n",
    "\n",
    "Cada sequência pode ser vista como um caminho (representado por $\\pi$) que passa por cada letra reconhecida em cada instante no tempo (com saída softmax $y_{\\pi_t}$). Assim, a probabilidade de uma sequência observada ao longo de $T$ instantes de tempo pode ser descrita como:\n",
    "\n",
    "$$p(\\pi|{\\bf x}) = \\prod_{t}^{T}{y_{\\pi_t}}$$\n",
    "\n",
    "Ou seja, a probabilidade é dada pelo produto das saídas softmax ao longo de $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic Time Warping\n",
    "\n",
    "Mas por que precisamos fazer isso? Afinal, uma RNN/LSTM/GRU já não considera seu passado quando emite uma saída? Sim, mas na prática, nem sempre é simples dizer onde começam e terminam segmentos, nem qual o tamanho 'certo' de uma letra, nem mesmo garantir que as entradas não sejam superpostas. Para lidar com estes problemas, temos duas alternativas:\n",
    "\n",
    "* rotular cada instante no tempo e também descrever onde, mais ou menos, começam e terminam as letras -- hmm, não parece algo muito legal de fazer, né?\n",
    "* rotular uma sequência inteira e deixar a rede advinhar como ela se segmenta -- aqui é onde entra a CTC!\n",
    "\n",
    "Dado o rótulo geral $\\ell$ (por exemplo, $\\ell$ = 'dançar' para a imagem acima), a CTC corresponde à estimativa:\n",
    "\n",
    "$$p(\\ell|{\\bf x}) = \\sum_{i}{p(\\ell|\\pi_i) p(\\pi_i|{\\bf x})}$$\n",
    "\n",
    "Ou seja, a probabilidade de se ler 'dançar' é a soma das probabilidades de ver dançar em suas várias formas (ou seja, marginalizada em $\\pi$), sendo cada forma ponderada por sua possibilidade de ocorrer dada a entrada. Esse passo é chamado _dynamic time warping_.\n",
    "\n",
    "Mas como estimar a probabilidade de $p(\\ell|{\\bf x})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimando a probabilidade do rótulo, dada a entrada\n",
    "\n",
    "Para estimar $p(\\ell|{\\bf x})$, vamos usar um algoritmo de programação dinâmica, chamado _forward-backward_. Para compreendê-lo, vamos usar o exemplo dado por Alex Graves em seus artigo sobre a CTC, onde ele decodifica da palavra 'cat'.\n",
    "\n",
    "![](images/ctc-cat-graves.png)\n",
    "\n",
    "Na figura, cada linha corresponde a uma letra ou vazio (branco) e cada coluna corresponde a um instante no tempo em que uma parte daquela letra (por exemplo, uma coluna de pixels da letra) está sendo observada. As setas indicam os caminhos a serem tomados em termos de escolha de rótulos. Há três possibilidades de transição em cada instante do tempo: \n",
    "\n",
    "* permaneço com o rótulo atual (seta para mesma linha) -- ex: em tempo $t$ vi pixels em 'C'; em tempo $t+1$, continuo vendo pixels, que devem ser de 'C' ainda (mas também poderiam ser de uma letra sobreposta ou ligada); \n",
    "* vou para um próximo rótulo (seta para branco) -- ex: em tempo $t$ vi pixels em 'C'; em tempo $t+1$, não vejo mais pixels, o que sugere que 'C' acabou (mas pode não ter acabado -- posso estar apenas vendo o intervalo antes que ela continue, como seria o caso do ideograma 的); e \n",
    "* vou para o próximo rótulo previsto -- ex: em tempo $t$ não vejo pixels; em tempo $t+1$, vejo pixels, o que sugere que deve ser uma letra depois de 'C' (ou uma continuação, como vimos acima). \n",
    "\n",
    "Deste modo, o rótulo $\\ell$ = ['C','A','T'], pode ser visto como $\\ell'$ = [$\\lambda$,'C',$\\lambda$,'A',$\\lambda$,'T',$\\lambda$], onde $\\lambda$ indica um rótulo vazio (branco)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia chave para estimar $p(\\ell|{\\bf x})$ é que a soma sobre os caminhos correspondentes a uma rotulação pode ser decomposta em uma soma iterativa correspondente aos prefixos daquela rotulação. Estas iterações podem ser calculadas de forma eficiente com variáveis recursivas $\\alpha$ e $\\beta$ que correspondem ao visto antes e depois do tempo $t$.\n",
    "\n",
    "$$p(\\ell|{\\bf x}) = \\sum_{s=1}^{\\ell'}{\\frac{\\alpha_t(s) \\beta_t(s)}{y^{(t)}_{\\ell'_s}}}$$\n",
    "\n",
    "Note que $\\alpha$ e $\\beta$ dependem da saída $y$ da RNN. Assim, durante o treino, cada novo conjunto de previsões da RNN é avaliado usando $p(\\ell|{\\bf x})$ e os neurônios modificam seus pesos de acordo com o gradiente desta função, dado por: \n",
    "\n",
    "$$\\frac{\\partial p(\\ell|{\\bf x})}{\\partial {y^{(t)}_k}} = \\frac{1}{{y^{(t)}_k}^2} \\sum_{s | \\ell'_s = k}{\\alpha_t(s) \\beta_t(s)}$$\n",
    "\n",
    "Para detalhes sobre a CTC, leia o artigo em http://www.cs.toronto.edu/~graves/icml_2006.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tensorflow implementa a CTC como `nn.ctc.loss()`. A seguir, temos um exemplo de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#  Compatibility imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from six.moves import xrange as range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testarmos a CTC, vamos usar uma pequena coleção de imagens que representam os dígitos de 0 a 9. Cada imagem corresponde a uma sequência aleatória de dígitos de comprimento variável (e número de digitos variáveis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/test_varlen.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "10\n",
      "instances 100\n",
      "height_0: 9\n",
      "width_0: 38\n"
     ]
    }
   ],
   "source": [
    "print (data['chars'])\n",
    "print (len(data['chars']))\n",
    "print ('instances', len(data['x']))\n",
    "# height and weight for first image\n",
    "print ('height_0:', len(data['x'][0]))\n",
    "print ('width_0:', len(data['x'][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, podemos ver as primeiras duas sequências de dígitos, uma com 4 dígitos (38 pixels de largura) e outra com 9 dígitos (em 60 pixels de largura). O rótulo correspondente à primeira sequência indica os dígitos que estão presentes (0, 1, 2 e 3). Para a segunda, são 4, 5, 6, 7, 8, 9, 5, 3 e 7. Todas as imagens na coleção têm 8 pixels de altura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slabs = [(np.asarray(data['x'][i]), np.asarray(data['y'][i])) \n",
    "         for i in range(len(data['x']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[4 5 6 7 8 9 5 3 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAABsCAYAAAC2CHP6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8NgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104a9210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAABQCAYAAADfjFSiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110541750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(slabs[i][1])\n",
    "    plt.figure()\n",
    "    plt.imshow(slabs[i][0], cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir lê esta coleção para a memória, fornecendo as sequências, seus rótulos correspondentes e o número de sequências válidas lidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the training or test dataset from disk\n",
    "def get_toy_data(pname):\n",
    "    with open(pname, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    num_examples = len(data['x'])\n",
    "    # note that image shape is modified to columns x lines, since it is expected a\n",
    "    # fixed number of lines and a varying number of columns\n",
    "    seqs = np.asarray([data['x'][t].swapaxes(0, 1) \n",
    "                       for t in range(num_examples) if len(data['y'][t]) > 0])\n",
    "    # get label seqs\n",
    "    labs = np.asarray([np.asarray(data['y'][t]) \n",
    "                       for t in range(num_examples) if len(data['y'][t]) > 0])\n",
    "    return seqs, labs, len(labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que as sequências são transpostas de forma a serem representadas por tantos intervalos de tempo quanto forem as suas larguras e 8 'atributos de entrada' já que isto corresponde a sua altura em pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAD9CAYAAAAieFDnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6kwI6kwI6kwI6kwI6sz/AZGbQaIuY1qyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110862710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAAD+CAYAAABla2jlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAGIJADwf4z49iObQzGmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a291d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqs, _, _ = get_toy_data('data/test_varlen.pkl')\n",
    "for i in range(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(seqs[i], cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir é dada apenas por conveniência. Ela permite gerar sequências aleatórias para testar a LSTM que vamos usar. Mas nesta aula vamos usar a coleção toy descrita antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate synthetical data for training\n",
    "# useful for testing\n",
    "def fake_data(num_examples, num_features, num_labels, min_size = 10, max_size=100):\n",
    "\n",
    "    # Generating different timesteps for each fake data\n",
    "    timesteps = np.random.randint(min_size, max_size, (num_examples,))\n",
    "\n",
    "    # Generating random input\n",
    "    inputs = np.asarray([np.random.randn(t, num_features).astype(np.float32) for t in timesteps])\n",
    "\n",
    "    # Generating random label, the size must be less or equal than timestep in order to achieve the end of the lattice in max timestep\n",
    "    labels = np.asarray([np.random.randint(0, num_labels, \n",
    "                                           np.random.randint(1, inputs[i].shape[0], (1,))).astype(np.int64) \n",
    "                         for i, _ in enumerate(timesteps)])\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar a CTC do tensorflow, precisamos colocar as sequências de entrada no formato esparso usado pela função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, duas sequências de entrada, (0, 1, 3) e (5, 8, 9, 3, 2), serão convertidas para a forma I, V, S, onde I corresponde a uma sequência de pares que indicam o índice da sequência e do valor dentro da sequência; V corresponde às observações correspondentes a cada par; S é um par indicando o número de sequências e o número máximos de valores observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [1, 4]]), array([0, 1, 3, 5, 8, 9, 3, 2], dtype=int32), array([2, 5]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tuple_from([[0,1,3], [5,8,9,3,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as sequências de entrada podem ter tamanho variável, elas precisam ser preenchidas para terem o mesmo tamanho em um certo batch. A função a seguir faz isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen=None, dtype=np.float32,\n",
    "                  padding='post', truncating='post', value=0.):\n",
    "    '''Pads each sequence to the same length: the length of the longest sequence.\n",
    "        If maxlen is provided, any sequence longer than maxlen is truncated to\n",
    "        maxlen. Truncation happens off either the beginning or the end\n",
    "        (default) of the sequence. Supports post-padding (default) and\n",
    "        pre-padding.\n",
    "\n",
    "        Args:\n",
    "            sequences: list of lists where each element is a sequence\n",
    "            maxlen: int, maximum length\n",
    "            dtype: type to cast the resulting sequence.\n",
    "            padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "            truncating: 'pre' or 'post', remove values from sequences larger\n",
    "            than maxlen either in the beginning or in the end of the sequence\n",
    "            value: float, value to pad the sequences to the desired value.\n",
    "        Returns\n",
    "            x: numpy array with dimensions (number_of_sequences, maxlen)\n",
    "            lengths: numpy array with the original sequence lengths\n",
    "    '''\n",
    "    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.,  2.,  0.,  0.],\n",
      "       [ 1.,  2.,  3.,  4.],\n",
      "       [ 1.,  2.,  3.,  0.]], dtype=float32), array([2, 4, 3]))\n",
      "(array([[ 0.,  0.,  1.,  2.],\n",
      "       [ 1.,  2.,  3.,  4.],\n",
      "       [ 0.,  1.,  2.,  3.]], dtype=float32), array([2, 4, 3]))\n",
      "(array([[ 1.,  2.,  0.],\n",
      "       [ 1.,  2.,  3.],\n",
      "       [ 1.,  2.,  3.]], dtype=float32), array([2, 4, 3]))\n"
     ]
    }
   ],
   "source": [
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]]))\n",
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]], padding = 'pre'))\n",
    "print (pad_sequences([[1,2],[1,2,3,4],[1,2,3]], maxlen = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, temos a nossa rede, usando uma RNN dinâmica com células LSTM na camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# number de pixel in columns\n",
    "num_features = 9 \n",
    "# total of digits + blank = 11 symbols\n",
    "num_classes = 11\n",
    "\n",
    "# Hyper-parameters\n",
    "num_hidden = 35\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# data\n",
    "ftrain = 'data/train_varlen.pkl'\n",
    "input_seqs, seq_labels, num_examples = get_toy_data(ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e.g: output of a convolutional net\n",
    "# Has size [batch_size, max_stepsize, num_features], but the\n",
    "# batch_size and max_stepsize can vary along each step\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "shape = tf.shape(inputs)\n",
    "batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "# Here we use sparse_placeholder that will generate a\n",
    "# SparseTensor required by ctc_loss op.\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "# 1d array of size [batch_size]\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Defining the cell\n",
    "cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "\n",
    "# The second output is the last state and we will no use that\n",
    "outputs, _ = tf.nn.dynamic_rnn(cell, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "# Reshaping to apply the same weights over the timesteps\n",
    "outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "# W init = truncated normal with mean 0 and stdev=0.1\n",
    "# bias init Zero initialization\n",
    "W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                     num_classes],\n",
    "                                    stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "### do not include sigmoid because CTC will do that\n",
    "logits = tf.matmul(outputs, W) + b \n",
    "\n",
    "# Reshaping back to the original shape\n",
    "logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "# Time major\n",
    "logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(cost)\n",
    "\n",
    "# Option 2: tf.nn.ctc_beam_search_decoder (slower but better)\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "# Inaccuracy: label error rate\n",
    "ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                      targets))\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliar e nossa implementação, vamos usar uma função que usa a RNN para estimar o rótulo de uma sequência de entrada e decodifica a saída da RNN em forma de uma sequência. As sequências são exibidas antes das previstas, de forma a avaliar a RNN, tanto em treino quanto teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_decoded_seqs(session, X, Y):\n",
    "    # Padding input to max_time_step of this batch\n",
    "    Xp, seqlen = pad_sequences(X)\n",
    "\n",
    "    # Converting to sparse representation so as to to feed SparseTensor input\n",
    "    Ys = sparse_tuple_from(Y)\n",
    "\n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], \n",
    "                    feed_dict={inputs: Xp,\n",
    "                               targets: Ys,\n",
    "                               seq_len: seqlen})\n",
    "    d_dense = tf.sparse_tensor_to_dense(d, default_value=-1)\n",
    "    dense_decoded = d_dense.eval(session=session)\n",
    "    for i, seq in enumerate(dense_decoded):\n",
    "        seq = ' '.join([str(s) for s in seq if s != -1])\n",
    "        print('\\t%d %s --> [%s]' % (i, Y[i], seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliar e nossa implementação, vamos usar uma função que usa a RNN para estimar o rótulo de uma sequência de entrada e decodifica a saída da RNN em forma de uma sequência. As sequências são exibidas antes das previstas, de forma a avaliar a RNN, tanto em treino quanto teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can preprocess the input data here\n",
    "Xtrain = input_seqs\n",
    "Ytrain = seq_labels\n",
    "\n",
    "batch_size = 5\n",
    "num_epochs = 10\n",
    "num_batches_per_epoch = int(num_examples/batch_size)\n",
    "\n",
    "# random cases to evaluate\n",
    "cases_to_show = np.random.randint(0, num_examples - 1, (10,))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    # Initializate the weights and biases\n",
    "    init.run()\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "\n",
    "            # Getting the index\n",
    "            indexes = [i % num_examples \n",
    "                       for i in range(batch * batch_size, (batch + 1) * batch_size)]\n",
    "            Xtrain_b = Xtrain[indexes]\n",
    "            \n",
    "            # Padding input to max_time_step of this batch\n",
    "            Xtrain_b, seqlen_train_b = pad_sequences(Xtrain_b)\n",
    "\n",
    "            # Converting to sparse representation so as to to feed SparseTensor input\n",
    "            Ytrain_b = sparse_tuple_from(Ytrain[indexes])\n",
    "\n",
    "            feed = {inputs: Xtrain_b,\n",
    "                    targets: Ytrain_b,\n",
    "                    seq_len: seqlen_train_b}\n",
    "            batch_cost, _ = s.run([cost, optimizer], feed_dict = feed)\n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += s.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "        if e % 2 == 0:\n",
    "            show_decoded_seqs(s, Xtrain[cases_to_show], \n",
    "                              Ytrain[cases_to_show])        \n",
    "            \n",
    "        # Shuffle the data\n",
    "        shuffled_indexes = np.random.permutation(num_examples)\n",
    "        Xtrain = Xtrain[shuffled_indexes]\n",
    "        Ytrain = Ytrain[shuffled_indexes]\n",
    "\n",
    "        # Metrics mean\n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "\n",
    "        log = \"%2d/%2d, tr_cost = %.3f, tr_ler = %.3f\"\n",
    "        print(log % (e+1, num_epochs, train_cost, train_ler))\n",
    "    \n",
    "    saver.save(s, \"/tmp/ctc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "ftest = 'data/test_varlen.pkl'\n",
    "Xtest, Ytest, num_instances = get_toy_data(ftest)\n",
    "# Padding input to max_time_step of this batch\n",
    "Xtest_p, seqlen_test_p = pad_sequences(Xtest)\n",
    "# Converting to sparse representation so as to to feed SparseTensor input\n",
    "Ytest_s = sparse_tuple_from(Ytest)\n",
    "# test cases\n",
    "cases_to_show = np.random.randint(0, num_instances - 1, (10,))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/ctc_model\")\n",
    "    test_ler = s.run(ler, feed_dict={inputs: Xtest_p,\n",
    "                                     targets: Ytest_s,\n",
    "                                     seq_len: seqlen_test_p})\n",
    "    print ('Evaluation on test set. Error:', test_ler)\n",
    "    show_decoded_seqs(s, Xtest[cases_to_show], \n",
    "                      Ytest[cases_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para todos considerando seriamente a função CTC, aconselho a usar a implementação do Baidu, disponibilizada publicamente em https://github.com/baidu-research/warp-ctc e compatível com tensorflow. Ela é usada nos sistemas de reconhecimento de fala do Baidu e é muito mais eficiente que a implementação original do tensorflow para GPUs e CPUs, tanto em termos de tempo quanto estabilidade numérica (ao menos, em setembro de 2017). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativas à função CTC incluem (a) combinar DNNs com HMMs, mas esta parece ser uma estratégia sendo lentamente substituída, (b) RNNs para transdução de sequências (o modelo de CTC com a inclusão de dependência entre saídas e modelagem de transição de sequências, em outras palavras, um modelo de linguagem -- ver https://arxiv.org/pdf/1211.3711.pdf) e (c) uso de modelos de atenção que incluem no modelo neural o objetivo de aprender a 'olhar' para os 'segmentos' (https://arxiv.org/pdf/1506.07503v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta aula foi baseada nos exemplos de Igor Macedo Quintanilha (https://github.com/igormq/ctc_tensorflow_example) e na explicação sobre CTC de Karl N. (https://gab41.lab41.org/speech-recognition-you-down-with-ctc-8d3b558943f0), além de usar dados criados pelo gerador sintético de Rakeshvar https://github.com/rakeshvar/rnn_ctc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
