{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDES NEURAIS II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, vamos melhorar nossa rede neural anterior para o problema de classificação de dígitos do MNIST. Ao mesmo tempo, vamos introduzir a biblioteca de alto nível `tf.contrib.learn` com aplicação de muitas técnicas de definição de hiper-parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como melhorar o desempenho de uma Rede Neural?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma rede neural é uma estrutura complexa descrita através de muito hiper-parâmetros. Todos eles tem impacto no desempenho da rede. Entre os principais, citamos:\n",
    "\n",
    "* Tipo de Arquitetura\n",
    "    * E para cada tipo, parâmetros específicos como tamanho dos kernels e striding em redes convolutivas;\n",
    "* Número de camadas\n",
    "* Número de neurônios em cada camada\n",
    "* Parâmetros de Regularização\n",
    "    * E para cada método, seus parâmetros específicos como taxa de regularização em L1 e L2 e taxa de dropout\n",
    "* Taxa de aprendizado e evolução da taxa (ex: decaimento exponencial)\n",
    "* Algoritmo de otimização\n",
    "* Valores iniciais de pesos\n",
    "\n",
    "Outras técnicas também podem ter impacto no desempenho da rede, embora não sejam exatamente parâmetros do sistema, como enriquecemento de bases de dados (mesmo de natureza sintética) e uso de ensemble na arquitetura.\n",
    "\n",
    "É muito importante que o experimentador compreenda bem o domínio do problema, busque configurações de parâmetros usados em situações similares na literatura técnica e ganhe o máximo de experiência prática. \n",
    "\n",
    "Muitas dicas adicionais podem ser encontradas nestes links:\n",
    "\n",
    "* http://cs231n.github.io/neural-networks-3/#baby\n",
    "* https://arxiv.org/abs/1206.5533\n",
    "* https://www.quora.com/Machine-Learning-What-are-some-tips-and-tricks-for-training-deep-neural-networks\n",
    "\n",
    "A seguir, vamos ver várias destas técnicas usadas na prática no problema do MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos antes, o estado-da-arte para esse dataset é 99.79%. Nosso melhor resultado anterior ficou em cerca de 92%.\n",
    "\n",
    "Nesta seção para acelerarmos o processo de criação e modificação das redes, vamos usar uma biblioteca de alto nível disponibilizada com o tensorflow, a contrib.learn (embora outras muito boas estejam disponíveis, como a Keras).\n",
    "\n",
    "A API tf.contrib.learn foi criada para facilitar a configuração, treino e avaliação de uma variedade de modelos em Aprendizagem de Máquina. Para criar nosso modelo, vamos seguir estes passos:\n",
    "\n",
    "1. Ler os dados\n",
    "2. Construir uma rede neural\n",
    "3. Treinar o modelo com os dados de treino\n",
    "4. Avaliar a acurácia do modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo uma rede neural de várias camadas com tf.contrib.learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.contrib.learn disponibiliza uma variedade de modelos pré-definidos, chamados Estimators, que você pode usar diretamente sobre seus dados. Em nosso caso, vamos usar o estimador DNNClassifier para construir uma rede neural 'profunda':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.contrib.learn disponibiliza uma variedade de modelos pré-definidos, chamados Estimators, que você pode usar diretamente sobre seus dados. Em nosso caso, vamos usar o estimador DNNClassifier para construir uma rede neural 'profunda':\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"/tmp/iris_model\")\n",
    "The code above first defines the model's feature columns, which specify the data type for the features in the data set. All the feature data is continuous, so tf.contrib.layers.real_valued_column is the appropriate function to use to construct the feature columns. There are four features in the data set (sepal width, sepal height, petal width, and petal height), so dimensions must be set accordingly to 4 to hold all the data.\n",
    "\n",
    "Then, the code creates a DNNClassifier model using the following arguments:\n",
    "\n",
    "feature_columns=feature_columns. The set of feature columns defined above.\n",
    "hidden_units=[10, 20, 10]. Three hidden layers, containing 10, 20, and 10 neurons, respectively.\n",
    "n_classes=3. Three target classes, representing the three Iris species.\n",
    "model_dir=/tmp/iris_model. The directory in which TensorFlow will save checkpoint data during model training. For more on logging and monitoring with TensorFlow, see Logging and Monitoring Basics with tf.contrib.learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Deep_learning    \n",
    "http://sebastianruder.com/optimizing-gradient-descent/index.html#batchgradientdescent  \n",
    "http://yann.lecun.com/exdb/mnist/  \n",
    "https://www.quora.com/Artificial-Neural-Networks-What-is-the-difference-between-activation-functions  \n",
    "https://www.tensorflow.org/versions/r0.9/tutorials/mnist/pros/index.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este curso é baseado em material da [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). Assim, segue os termos da [licença do MIT](https://bigdatauniversity.com/mit-license/). Aula modificada por Marco Cristo apartir de versão de <a href = \"https://linkedin.com/in/luisotsm\">Luis Otavio Silveira Martins</a>, <a href = \"https://linkedin.com/in/erich-natsubori-sato\"> Erich Natsubori Sato </a></h4>. Material adicional de Imanol Schlag (https://ischlag.github.io/2016/06/04/how-to-use-tensorboard/) e Faizan Shaikh (https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
