{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed = 42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3 # inputs for time slot\n",
    "n_neurons = 5 # hidden neurons in just 1 time slot\n",
    "\n",
    "# tensor shape -> (n_batches x n_inputs)\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape = [n_inputs, n_neurons]), \n",
    "                 dtype = tf.float32)\n",
    "Wy = tf.Variable(tf.random_normal(shape = [n_neurons, n_neurons]), \n",
    "                 dtype = tf.float32)\n",
    "b = tf.Variable(tf.zeros([1, n_neurons]), dtype = tf.float32)\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00664975  0.195439    0.08291762  0.08832355 -0.14525607]\n",
      " [ 0.32749006 -0.09047261 -0.30807865  0.20217191 -0.45717433]\n",
      " [ 0.59584385 -0.36221007 -0.61687893  0.31080624 -0.68643111]\n",
      " [ 0.77524525 -0.58375102 -0.80808318  0.41188511 -0.83014971]]\n",
      "[[ 0.83347863 -0.4676269  -0.87743753  0.15186396 -0.87976229]\n",
      " [ 0.91412014 -0.54188269 -0.82953322 -0.37742507 -0.95792758]\n",
      " [ 0.95737088 -0.68740845 -0.8081519  -0.65423918 -0.98491126]\n",
      " [ 0.97921664 -0.83296072 -0.8362062  -0.75839293 -0.99425137]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2 \n",
    "                     [0.9, 1.0, 1.1],   # instance 3\n",
    "                    ])\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3],   # instance 0\n",
    "                     [1.4, 1.5, 1.6],   # instance 1\n",
    "                     [1.7, 1.8, 1.9],   # instance 2 \n",
    "                     [2.0, 2.1, 2.2],   # instance 3\n",
    "                    ])\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = s.run([Y0, Y1],\n",
    "                          feed_dict = {X0: X0_batch, X1: X1_batch})\n",
    "\n",
    "print Y0_val\n",
    "print Y1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `static_rnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3 # inputs for time slot\n",
    "n_neurons = 5 # hidden neurons in just 1 time slot\n",
    "\n",
    "# tensor shape -> (n_batches x n_inputs)\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "# com API de mais alto nivel\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, state = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                           dtype =tf.float32)\n",
    "Y0, Y1 = outputs\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11336877 -0.04618133 -0.04251913  0.08736697  0.14434618]\n",
      " [-0.26662004 -0.18219495  0.02026685  0.23455885  0.54267317]\n",
      " [-0.40747947 -0.31157607  0.08289339  0.37172768  0.7896542 ]\n",
      " [-0.5312956  -0.43035144  0.14487195  0.49438283  0.9109515 ]]\n",
      "[[-0.66259533 -0.50169367  0.22397666  0.52975714  0.94856107]\n",
      " [-0.84929156 -0.5857386   0.39825439  0.45898128  0.98381126]\n",
      " [-0.92375982 -0.65609491  0.5346204   0.44486007  0.9942531 ]\n",
      " [-0.95567167 -0.71526313  0.63692611  0.48122585  0.99774879]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2 \n",
    "                     [0.9, 1.0, 1.1],   # instance 3\n",
    "                    ])\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3],   # instance 0\n",
    "                     [1.4, 1.5, 1.6],   # instance 1\n",
    "                     [1.7, 1.8, 1.9],   # instance 2 \n",
    "                     [2.0, 2.1, 2.2],   # instance 3\n",
    "                    ])\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = s.run([Y0, Y1],\n",
    "                          feed_dict = {X0: X0_batch, X1: X1_batch})\n",
    "\n",
    "print Y0_val\n",
    "print Y1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem necessidade de descrever explicitamente a entrada ao longo do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3 # inputs for time slot\n",
    "n_neurons = 5 # hidden neurons in just 1 time slot\n",
    "n_steps = 2\n",
    "\n",
    "# tensor shape -> (n_batches x n_inputs)\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "# get list of tensors with shape [None, n_inputs]\n",
    "Xseqs = tf.unstack(tf.transpose(X, perm = [1, 0, 2]))\n",
    "\n",
    "# com API de mais alto nivel\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "output_seqs, state = tf.contrib.rnn.static_rnn(basic_cell, Xseqs,\n",
    "                                           dtype =tf.float32)\n",
    "# back to the original shape\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm = [1, 0, 2])\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.15318885  0.12051394 -0.14256774  0.11027262 -0.05871544]\n",
      "  [-0.90414226  0.89195144 -0.63326883  0.70085257 -0.44146615]]\n",
      "\n",
      " [[-0.48086599  0.39384031 -0.28806657  0.26011854 -0.17563742]\n",
      "  [-0.94593662  0.97297293 -0.67838675  0.859218   -0.56859499]]\n",
      "\n",
      " [[-0.71327341  0.61166167 -0.42137903  0.39840218 -0.28780583]\n",
      "  [-0.96981335  0.9921385  -0.73931801  0.93104404 -0.65325063]]\n",
      "\n",
      " [[-0.85203207  0.76443809 -0.53866905  0.52067178 -0.39259726]\n",
      "  [-0.98340499  0.99724239 -0.80625534  0.96356934 -0.70796287]]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2 \n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]],   # instance 3\n",
    "                    ])\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    out_vals = s.run(outputs, feed_dict = {X: X_batch})\n",
    "\n",
    "print out_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desdobramento dinâmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3 # inputs for time slot\n",
    "n_neurons = 5 # hidden neurons in just 1 time slot\n",
    "n_steps = 2\n",
    "\n",
    "# tensor shape -> (n_batches x n_inputs)\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "# com API de mais alto nivel\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, state = tf.nn.dynamic_rnn(basic_cell, X,\n",
    "                                   dtype =tf.float32)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.14834246  0.0544144  -0.12870833  0.04149501 -0.0309626 ]\n",
      "  [ 0.88367331  0.2528224  -0.92533368  0.48299512 -0.16013345]]\n",
      "\n",
      " [[ 0.45225543  0.10361931 -0.47149643  0.210849   -0.10643698]\n",
      "  [ 0.93180227  0.42531857 -0.9779222   0.35922     0.04373024]]\n",
      "\n",
      " [[ 0.67811656  0.15232225 -0.71363842  0.36842591 -0.18070443]\n",
      "  [ 0.9635635   0.5406754  -0.99264485  0.29947734  0.17718439]]\n",
      "\n",
      " [[ 0.82224393  0.20029651 -0.8557173   0.50734007 -0.25296682]\n",
      "  [ 0.98211133  0.60967129 -0.99719095  0.31619012  0.24006009]]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2 \n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]],   # instance 3\n",
    "                    ])\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    out_vals = s.run(outputs, feed_dict = {X: X_batch})\n",
    "\n",
    "print out_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamanhos variáveis na Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3 # inputs for time slot\n",
    "n_neurons = 5 # hidden neurons in just 1 time slot\n",
    "n_steps = 2\n",
    "\n",
    "# tensor shape -> (n_batches x n_inputs)\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_lens = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "# com API de mais alto nivel\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, state = tf.nn.dynamic_rnn(basic_cell, X, dtype =tf.float32,\n",
    "                                   sequence_length = seq_lens)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.05815748 -0.02042178  0.0261902  -0.0287376   0.00827101]\n",
      "  [-0.25962549 -0.59064484 -0.52196658  0.3489787   0.2417295 ]]\n",
      "\n",
      " [[-0.11885347 -0.19865772 -0.13991296  0.07099477  0.06549278]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.17867406 -0.36465546 -0.29849792  0.16932763  0.12228704]\n",
      "  [-0.36642525 -0.73754156 -0.7765432   0.62759364  0.38315642]]\n",
      "\n",
      " [[-0.23720218 -0.51031458 -0.44215211  0.26440096  0.17829153]\n",
      "  [-0.41150665 -0.79461533 -0.84945899  0.72448599  0.44811308]]]\n",
      "[[-0.25962549 -0.59064484 -0.52196658  0.3489787   0.2417295 ]\n",
      " [-0.11885347 -0.19865772 -0.13991296  0.07099477  0.06549278]\n",
      " [-0.36642525 -0.73754156 -0.7765432   0.62759364  0.38315642]\n",
      " [-0.41150665 -0.79461533 -0.84945899  0.72448599  0.44811308]]\n"
     ]
    }
   ],
   "source": [
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]], # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [0.0, 0.0, 0.0]], # padded instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]], # instance 2 \n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]], # instance 3\n",
    "                    ])\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    out_vals, st_vals = s.run([outputs, state], \n",
    "                              feed_dict = {X: X_batch, \n",
    "                                           seq_lens: [2,1,2,2]})\n",
    "\n",
    "print out_vals\n",
    "print st_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação para MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/MNIST_data')\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, state = tf.nn.dynamic_rnn(basic_cell, X, dtype =tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(state, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                         logits = logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "acc = tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, y, 1), tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - acc tr: 0.940000 test: 0.930800\n",
      "1 - acc tr: 0.933333 test: 0.943100\n",
      "2 - acc tr: 0.940000 test: 0.953500\n",
      "3 - acc tr: 0.966667 test: 0.962300\n",
      "4 - acc tr: 0.953333 test: 0.968500\n",
      "5 - acc tr: 0.960000 test: 0.965900\n",
      "6 - acc tr: 0.980000 test: 0.970600\n",
      "7 - acc tr: 0.980000 test: 0.971500\n",
      "8 - acc tr: 0.960000 test: 0.971500\n",
      "9 - acc tr: 0.986667 test: 0.969200\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        for i in range(mnist.train.num_examples // batch_size):\n",
    "            Xb, yb = mnist.train.next_batch(batch_size)\n",
    "            Xb = Xb.reshape(-1, n_steps, n_inputs)\n",
    "            s.run(train_op, feed_dict = {X: Xb, y: yb})\n",
    "        acc_train = acc.eval(feed_dict = {X: Xb, y: yb})\n",
    "        acc_test = acc.eval(feed_dict = {X: X_test, y: y_test})\n",
    "        print '%d - acc tr: %.6f test: %.6f' % (e, acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.reshape((-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "print xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xn = x.reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "print xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
