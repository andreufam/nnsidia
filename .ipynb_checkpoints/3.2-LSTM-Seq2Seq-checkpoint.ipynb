{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LSTMs/GRUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstrações de células de memória de um ponto de vista funcional. Podem ser usadas no lugar de qualquer unidade em uma RNN, sendo responsável por ler, escrever ou lembrar de informação fluindo no modelo. \n",
    "\n",
    "A LSTM, em particular, consiste basicamente de uma unidade linear (a celula de informação propriamente dita) envoltas por três portas lógicas, responsáveis pela manutenção dos dados. Uma é responsável por permitir que dados fluam para a célulade informação (entrada), uma pela saída da célula e a última é responável por lembrar ou esquecer de dados de acordo com as necessidades da rede. A GRU é uma versão mais simplificada da LSTM. Ela combina portas da LSTM em menos portas, produzindo um modelo menor.\n",
    "\n",
    "Estas unidades ajuam a resolver o problema de manter estados, porque a rede pode escolher esquecê-los se já não servem mais. Desta forma, o problema dos gradientes é menor importantes com LSTMs e GRUs.\n",
    "\n",
    "Nesta aula, vamos usar LSTMs em problemas de tradução.\n",
    "\n",
    "### Arquitetura Long Short-Term Memory \n",
    "\n",
    "Neste texto, vamos considerar que uma LSTM é formada por três portas lógicas: \"Input\" ou \"Write\", responsável pela escrita na LSTM de dados vindos do resto da RNN; \"Output\" ou \"Read\", responsável pela saída da LSTM para o resto da RNN; e \"Keep\" ou \"Forget\", rsponsável pela manutenção ou modificação de dados armazenados na LSTM.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagrama de uma Long Short-Term Memory Unit*</center>\n",
    "\n",
    "Se você estiver mais interssado em saber sobre LSTMs e suas variantes, incluindo GRUs, leia o blog: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs Sequence to Sequence: soletrando a partir de pronúncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problema que vamos abordar, queremos traduzir a pronuncia de uma palavra, dada como uma lista de fonemas, para a grafia da palavra. Este problema é mais simples que _fala para texto_ ou _tradução_ (no sentido de não precisarmos de quantidades colossais de dados para ver algo acontecer [:)]); contudo, uma dificuldade aqui é a avaliação na escrita de palavras nunca vistas antes. Isto é díficil porque (1) há muitas pronúncias com várias transcrições razoáveis além de (2) palavras homônicas com transcrições distintas (_read_, no passado e presente, por exemplo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando os dados..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente temos que ler o dicionário de fonemas da CMU, _The CMU pronouncing dictionary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdic = pd.read_csv('data/cmudict-compact.csv', comment=';', \n",
    "                   header = -1, names = ['word', 'pronunciation'],\n",
    "                   keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40150</th>\n",
       "      <td>FACEY</td>\n",
       "      <td>F EY1 S IY0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40151</th>\n",
       "      <td>FACHET</td>\n",
       "      <td>F AE1 CH AH0 T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>FACIAL</td>\n",
       "      <td>F EY1 SH AH0 L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40153</th>\n",
       "      <td>FACIALS</td>\n",
       "      <td>F EY1 SH AH0 L Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40154</th>\n",
       "      <td>FACIANE</td>\n",
       "      <td>F AA0 S IY0 AA1 N EY0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          pronunciation\n",
       "40150    FACEY            F EY1 S IY0\n",
       "40151   FACHET         F AE1 CH AH0 T\n",
       "40152   FACIAL         F EY1 SH AH0 L\n",
       "40153  FACIALS       F EY1 SH AH0 L Z\n",
       "40154  FACIANE  F AA0 S IY0 AA1 N EY0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdic[40150:40155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133779"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mapear índices para letras e fonemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map codes to phonemes\n",
    "def create_phoneme_maps(df):\n",
    "    phonemes = set()\n",
    "    for pro_phonemes in pdic['pronunciation']:\n",
    "        for p in pro_phonemes.split():\n",
    "            phonemes.add(p)\n",
    "    sorted_phonemes = [\"_\"] + sorted(list(phonemes))\n",
    "    index_to_phoneme = dict(enumerate(sorted_phonemes))\n",
    "    return (index_to_phoneme, \n",
    "            dict((v, k) for k,v in index_to_phoneme.items()))\n",
    "\n",
    "# map codes to letters (and special symbol _)\n",
    "def create_letter_maps(): \n",
    "    index_to_letter = dict(enumerate(\"_abcdefghijklmnopqrstuvwxyz\"))\n",
    "    return (index_to_letter,\n",
    "            dict((v, k) for k,v in index_to_letter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 1)\n",
      "('AA0', 1)\n",
      "70\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "index_to_phoneme, phoneme_to_index = create_phoneme_maps(pdic['pronunciation'])\n",
    "index_to_letter, letter_to_index = create_letter_maps()    \n",
    "\n",
    "print (index_to_letter[1], letter_to_index['a'])\n",
    "print (index_to_phoneme[1], phoneme_to_index['AA0'])\n",
    "print len(index_to_phoneme)\n",
    "print len(index_to_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pronounce dict associating words to phoneme codes\n",
    "# Note that very short and very long words, as well as words with no\n",
    "# alphabetical chars, are discarded\n",
    "def create_pronouce_dict(phoneme_to_index):\n",
    "    pronounce_dict = {}\n",
    "    for idx, cols in pdic.iterrows():\n",
    "        word, phone_list = cols['word'], cols['pronunciation'].split()\n",
    "        # filter long words \n",
    "        if len(word) < 5 or len(word) > 15:\n",
    "            continue\n",
    "        # filter words with not alphabetical chars\n",
    "        if any((not c.isalpha() for c in word)):\n",
    "            continue\n",
    "        pronounce_dict[word.lower()] = [phoneme_to_index[p] for p in phone_list]\n",
    "    return pronounce_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pronounce_dict = create_pronouce_dict(phoneme_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar nossos dicionários, vendo a pronúncia de _loved_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict size: 108006\n",
      "loved: [43, 8, 65, 21] ~ L-AH1-V-D\n"
     ]
    }
   ],
   "source": [
    "print 'dict size:', len(pronounce_dict)\n",
    "print '%s: %s ~ %s'%('loved', pronounce_dict['loved'], \n",
    "                   '-'.join([index_to_phoneme[i] for i in pronounce_dict['loved']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding das entradas e labels para a RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(pronounce_dict):\n",
    "    words = np.random.permutation(list(pronounce_dict.keys()))\n",
    "\n",
    "    # (words, max time, embedding size)\n",
    "    labels_ = np.zeros((len(words), 15, 1)) # max allowed word length + 1\n",
    "    input_ = np.zeros((len(words), 16, 1))\n",
    "    for i, w in enumerate(words):\n",
    "        v = pronounce_dict[w]\n",
    "        w = w + \"_\" * (15 - len(w))\n",
    "        v = v + [0] * (16 - len(v))\n",
    "        for j, n in enumerate(v):\n",
    "            input_[i][j] = [n] # input embedding size = 1\n",
    "        for j, letter in enumerate(w):\n",
    "            labels_[i][j] = [letter_to_index[letter]] # output embedding size = 1\n",
    "            \n",
    "    return input_.astype(np.int32), labels_.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, labels_ = pad(pronounce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friesner_______ [[ 6]\n",
      " [18]\n",
      " [ 9]\n",
      " [ 5]\n",
      " [19]\n",
      " [14]\n",
      " [ 5]\n",
      " [18]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n",
      "FRIY1SNER0__________ [[32]\n",
      " [54]\n",
      " [39]\n",
      " [55]\n",
      " [45]\n",
      " [26]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "w = 4321\n",
    "print ''.join([index_to_letter[int(c)] for c in labels_[w]]), labels_[w]\n",
    "print ''.join([index_to_phoneme[int(c)] for c in input_[w]]), input_[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação em treino, teste e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_test   = input_[:10000]\n",
    "input_val    = input_[10000:20000]\n",
    "input_train  = input_[20000:]\n",
    "labels_test  = labels_[:10000]\n",
    "labels_val   = labels_[10000:20000]\n",
    "labels_train = labels_[20000:]\n",
    "\n",
    "data_test  = zip(input_test, labels_test)\n",
    "data_val   = zip(input_val, labels_val)\n",
    "data_train = zip(input_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta classe pega batches aleatórios e os arranja de forma adequada para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataIterator:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.iter = self.make_random_iter()\n",
    "        \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            idxs = self.iter.next()\n",
    "        except StopIteration:\n",
    "            self.iter = self.make_random_iter()\n",
    "            idxs = self.iter.next()\n",
    "        X, Y = zip(*[self.data[i] for i in idxs])\n",
    "        # shape X, Y after zip = [batch_size, max_time, embedding_size]\n",
    "        # shape X, Y after transpose = [max_time, batch_size, embedding_size]\n",
    "        X = np.array(X).transpose(1, 0, 2)  \n",
    "        Y = np.array(Y).transpose(1, 0, 2)\n",
    "        return X, Y\n",
    "\n",
    "    def make_random_iter(self):\n",
    "        splits = np.arange(self.batch_size, len(self.data), self.batch_size)\n",
    "        it = np.split(np.random.permutation(range(len(self.data))), splits)[:-1]\n",
    "        return iter(it)\n",
    "    \n",
    "batch_size = 128\n",
    "train_iter = DataIterator(data_train, batch_size)\n",
    "val_iter = DataIterator(data_val, batch_size)\n",
    "test_iter = DataIterator(data_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2, 1)\n",
      "[[[ 8]\n",
      "  [42]]\n",
      "\n",
      " [[45]\n",
      "  [66]]\n",
      "\n",
      " [[21]\n",
      "  [36]]\n",
      "\n",
      " [[26]\n",
      "  [68]]\n",
      "\n",
      " [[66]\n",
      "  [35]]\n",
      "\n",
      " [[37]\n",
      "  [46]]\n",
      "\n",
      " [[58]\n",
      "  [ 0]]\n",
      "\n",
      " [[34]\n",
      "  [ 0]]\n",
      "\n",
      " [[49]\n",
      "  [ 0]]\n",
      "\n",
      " [[43]\n",
      "  [ 0]]\n",
      "\n",
      " [[21]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]]\n",
      "[[[21]\n",
      "  [17]]\n",
      "\n",
      " [[14]\n",
      "  [21]]\n",
      "\n",
      " [[ 4]\n",
      "  [ 9]]\n",
      "\n",
      " [[ 5]\n",
      "  [26]]\n",
      "\n",
      " [[18]\n",
      "  [26]]\n",
      "\n",
      " [[23]\n",
      "  [ 9]]\n",
      "\n",
      " [[ 9]\n",
      "  [14]]\n",
      "\n",
      " [[20]\n",
      "  [ 7]]\n",
      "\n",
      " [[ 8]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 8]\n",
      "  [ 0]]\n",
      "\n",
      " [[15]\n",
      "  [ 0]]\n",
      "\n",
      " [[12]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 4]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]\n",
      "\n",
      " [[ 0]\n",
      "  [ 0]]]\n"
     ]
    }
   ],
   "source": [
    "temp_iter = DataIterator(data_test, 2)\n",
    "X, Y = temp_iter.next_batch()\n",
    "print X.shape\n",
    "print X\n",
    "print Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando em tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tensorflow.models.rnn import rnn_cell, seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo uma sessão interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# max padded lengths\n",
    "input_seq_length = 16\n",
    "output_seq_length = 15 \n",
    "\n",
    "input_vocab_size = len(index_to_phoneme) # 70\n",
    "output_vocab_size = len(index_to_letter) + 1 # 27 + 1 (end of word)\n",
    "embedding_size = 1 # input and output embedding size\n",
    "embedding_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa RNN tem a seguinte topologia:\n",
    "\n",
    "<img src=\"rnn_seq2seq.png\">\n",
    "\n",
    "Ou seja, a entrada do decodificador (`decode_input`) tem que ser deslocada de 1 dos rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_input = tf.placeholder(tf.int32, shape=(input_seq_length, batch_size, embedding_size))\n",
    "input_seq_lengths = tf.placeholder(dtype = tf.int32, shape=(batch_size,))\n",
    "\n",
    "#labels = [tf.placeholder(tf.int32, shape=(None,), name = \"l_%i\" %i) \n",
    "#          for i in range(output_seq_length)]\n",
    "\n",
    "#decode_input = [tf.zeros_like(encode_input[0], dtype=np.int32, name=\"GO\")] + labels[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima célula é o cerne do nosso modelo. Nossa RNN é formada por células LSTM com dropout entre as camadas. Empilhamos 3 dessas (LSTM+dropout) para formar a rede neural completa. Executamos essa rede com o padrão `seq2seq.embedding_rnn_seq2seq` que permite que a alimentemos com uma sequência normal de números e esta é convertida automaticamente pela própria rede em uma sequência de embeddings de tensores one-hot.\n",
    "\n",
    "Note que nós construimos duas redes no escopo 'decoders'. Uma delas usa `feed_previous = True` enquanto a outra não. Isso é setado para False durante o treino, de forma que mesmo que o aprendiz cometa um erro em uma letra - nós ainda passamos pra ele o rótulo correto em `decoder_inputs`. Como não teríamos os rótulos corretos em um teste real, para o conjunto de teste usamos `feed_previous = True` e o decodificador recebe a letra com máxima probabilidade do último passo da saída do decodificador.\n",
    "\n",
    "`decode_output` é um tensor com forma (batch_size, output_vocab_size). Nós podemos aplicar softmax a este tensor para obter escores logísticos para cada letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Initializer for variable encoder/rnn/basic_lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4eb9dac00c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         sequence_length=input_seq_lengths, time_major=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#  encode_input: [max_time, batch_size, embedding_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0mloop_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=redefined-outer-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2810\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2811\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2632\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2634\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2635\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2582\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2584\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    758\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m           skip_conditionals=True)\n\u001b[0m\u001b[1;32m    761\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    181\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    182\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/layers/base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_graph_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     i, j, f, o = array_ops.split(\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, output_size, build_bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[1;32m   1169\u001b[0m           \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m           initializer=kernel_initializer)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbuild_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_scope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minner_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"constraint\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.pyc\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[0;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       trainable = (variable in tf_variables.trainable_variables() or\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    803\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    806\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     logging.vlog(1, \"Created variable %s with shape %s and init %s\", v.name,\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \"initializer.\" % name)\n\u001b[0m\u001b[1;32m    323\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m           shape = (self._initial_value.get_shape()\n",
      "\u001b[0;31mValueError\u001b[0m: Initializer for variable encoder/rnn/basic_lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
     ]
    }
   ],
   "source": [
    "# ENCODER\n",
    "\n",
    "with tf.variable_scope(\"encoder\") as scope:\n",
    "    # Build RNN cell\n",
    "    encoder_cell = tf.contrib.rnn.BasicLSTMCell(embedding_dim)\n",
    "    #initial_state = encoder_cell.zero_state(batch_size, tf.float32) \n",
    "\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outpus: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "        encoder_cell, encode_input, dtype = tf.float32,\n",
    "        sequence_length=input_seq_lengths, time_major=True)\n",
    "    #  encode_input: [max_time, batch_size, embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ENCODER\n",
    "\n",
    "# Build RNN cell\n",
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(embedding_dim)\n",
    "\n",
    "# Run Dynamic RNN\n",
    "#   encoder_outpus: [max_time, batch_size, num_units]\n",
    "#   encoder_state: [batch_size, num_units]\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encode_input,\n",
    "    sequence_length=source_sequence_length, time_major=True)\n",
    "\n",
    "# DECODER\n",
    "\n",
    "# Build RNN cell\n",
    "decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(embedding_dim)\n",
    "\n",
    "# Helper\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "    decode_input, decoder_lengths, time_major=True)\n",
    "# Decoder\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, encoder_state,\n",
    "    output_layer=projection_layer)\n",
    "# Dynamic decoding\n",
    "outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)\n",
    "logits = outputs.rnn_output\n",
    "\n",
    "projection_layer = layers_core.Dense(\n",
    "    tgt_vocab_size, use_bias=False)\n",
    "\n",
    "# LOSS\n",
    "crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=decoder_outputs, logits=logits)\n",
    "train_loss = (tf.reduce_sum(crossent * target_weights) /\n",
    "    batch_size)\n",
    "\n",
    "# Calculate and clip gradients\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(train_loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "    gradients, max_gradient_norm)\n",
    "\n",
    "# Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "update_step = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "# range(3) para formar uma pilha com 3 camadas\n",
    "cells = [tf.contrib.rnn.DropoutWrapper(\n",
    "        tf.contrib.rnn.BasicLSTMCell(embedding_dim), output_keep_prob=keep_prob\n",
    "    ) for i in range(3)]\n",
    "\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "# outputs, states = embedding_rnn_seq2seq(\n",
    "#    encoder_inputs, decoder_inputs, cell,\n",
    "#    num_encoder_symbols, num_decoder_symbols,\n",
    "#    embedding_size, output_projection=None,\n",
    "#    feed_previous=False)\n",
    "\n",
    "with tf.variable_scope(\"decoders\") as scope:\n",
    "    decode_outputs, decode_state = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, \n",
    "        output_vocab_size, embedding_dim)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    decode_outputs_test, decode_state_test = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, \n",
    "        output_vocab_size, embedding_dim, feed_previous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequence_loss` é entropia cruzada aplicada ao softmax das saídas do decodificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_weights = [tf.ones_like(l, dtype=tf.float32) for l in labels]\n",
    "loss = tf.nn.seq2seq.sequence_loss(decode_outputs, labels, loss_weights, output_vocab_size, embedding_dim)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação é feita usando tanto a perda da seq2seq quanto a precisão, ou seja, a proporção de palavras escritas corretamente pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_feed(X, Y):\n",
    "    feed_dict = {encode_input[t]: X[t] for t in range(input_seq_length)}\n",
    "    feed_dict.update({labels[t]: Y[t] for t in range(output_seq_length)})\n",
    "    return feed_dict\n",
    "\n",
    "def train_batch(data_iter):\n",
    "    X, Y = data_iter.next_batch()\n",
    "    feed_dict = get_feed(X, Y)\n",
    "    feed_dict[keep_prob] = 0.5\n",
    "    _, out = sess.run([train_op, loss], feed_dict)\n",
    "    return out\n",
    "\n",
    "def get_eval_batch_data(data_iter):\n",
    "    X, Y = data_iter.next_batch()\n",
    "    feed_dict = get_feed(X, Y)\n",
    "    feed_dict[keep_prob] = 1.\n",
    "    all_output = sess.run([loss] + decode_outputs_test, feed_dict)\n",
    "    eval_loss = all_output[0]\n",
    "    decode_output = np.array(all_output[1:]).transpose([1,0,2])\n",
    "    return eval_loss, decode_output, X, Y\n",
    "\n",
    "def eval_batch(data_iter, num_batches):\n",
    "    losses = []\n",
    "    predict_loss = []\n",
    "    for i in range(num_batches):\n",
    "        eval_loss, output, X, Y = get_eval_batch_data(data_iter)\n",
    "        losses.append(eval_loss)\n",
    "        \n",
    "        for index in range(len(output)):\n",
    "            real = Y.T[index]\n",
    "            predict = np.argmax(output, axis = 2)[index]\n",
    "            predict_loss.append(all(real==predict))\n",
    "    return np.mean(losses), np.mean(predict_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de execução deixada até cerca de 20000 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    try:\n",
    "        train_batch(train_iter)\n",
    "        if i % 1000 == 0:\n",
    "            val_loss, val_predict = eval_batch(val_iter, 16)\n",
    "            train_loss, train_predict = eval_batch(train_iter, 16)\n",
    "            print (\"val loss   : %f, val predict   = %.1f%%\" %(val_loss, val_predict * 100))\n",
    "            print (\"train loss : %f, train predict = %.1f%%\" %(train_loss, train_predict * 100))\n",
    "            print (\"\")\n",
    "            sys.stdout.flush()\n",
    "    except KeyboardInterrupt:\n",
    "        print (\"interrupted by user\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examinando modelos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu atingi cerca de 41% no conjunto de validação, quando interrompi. Isso parece bem ruim. Vamos ver agora os erros cometidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_loss, output, X, Y = get_eval_batch_data(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"pronúncia\".ljust(40)),\n",
    "print (\"correta\".ljust(17)),\n",
    "print (\"chute do modelo\".ljust(17)),\n",
    "print (\"correto?\")\n",
    "print (\"\")\n",
    "\n",
    "for index in range(len(output)):\n",
    "    phonemes = \"-\".join([index_to_phoneme[p] for p in X.T[index]]) \n",
    "    real = [index_to_letter[l] for l in Y.T[index]] \n",
    "    predict = [index_to_letter[l] for l in np.argmax(output, axis = 2)[index]]\n",
    "   \n",
    "    print (phonemes.split(\"-_\")[0].ljust(40),)\n",
    "    print (\"\".join(real).split(\"_\")[0].ljust(17),)\n",
    "    print (\"\".join(predict).split(\"_\")[0].ljust(17),)\n",
    "    print (str(real == predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os erros não parecem tão terríveis assim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este curso é baseado em material da [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). Assim, segue os termos da [licença do MIT](https://bigdatauniversity.com/mit-license/). Material adicional de Mikesj (https://github.com/mikesj-public/rnn_spelling_bee/blob/master/spelling_bee_RNN.ipynb), Thang Luong, Eugene Brevdo, and Rui Zhao (https://github.com/tensorflow/nmt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdic = pd.read_csv('data/cmudict-compact.csv', comment=';', \n",
    "                   header = -1, names = ['word', 'pronunciation'],\n",
    "                   keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40150</th>\n",
       "      <td>FACEY</td>\n",
       "      <td>F EY1 S IY0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40151</th>\n",
       "      <td>FACHET</td>\n",
       "      <td>F AE1 CH AH0 T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>FACIAL</td>\n",
       "      <td>F EY1 SH AH0 L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40153</th>\n",
       "      <td>FACIALS</td>\n",
       "      <td>F EY1 SH AH0 L Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40154</th>\n",
       "      <td>FACIANE</td>\n",
       "      <td>F AA0 S IY0 AA1 N EY0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word          pronunciation\n",
       "40150    FACEY            F EY1 S IY0\n",
       "40151   FACHET         F AE1 CH AH0 T\n",
       "40152   FACIAL         F EY1 SH AH0 L\n",
       "40153  FACIALS       F EY1 SH AH0 L Z\n",
       "40154  FACIANE  F AA0 S IY0 AA1 N EY0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdic[40150:40155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdic = pdic.sample(n = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_input(inp):    \n",
    "    return ((len(inp) < 5 or      # filter long words \n",
    "             len(inp) > 15) or\n",
    "            # filter words with not alphabetical chars\n",
    "            any((not s.isalpha() for s in inp)))\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_symbols = set()\n",
    "target_symbols = set()\n",
    "for idx, cols in pdic.iterrows():\n",
    "    input_text, phones = cols['word'], cols['pronunciation']\n",
    "    if filter_input(input_text):\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = ['\\t'] + phones.split() + ['\\n']\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text) ###\n",
    "    for symbol in input_text:\n",
    "        if symbol not in input_symbols:\n",
    "            input_symbols.add(symbol)\n",
    "    for symbol in target_text:\n",
    "        if symbol not in target_symbols:\n",
    "            target_symbols.add(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 8117\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 17\n",
      "Number of unique input tokens: 26\n",
      "- A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n",
      "Number of unique output tokens: 71\n",
      "- '\\t \\n AA0 AA1 AA2 AE0 AE1 AE2 AH0 AH1 AH2 AO0 AO1 AO2 AW0 AW1 AW2 AY0 AY1 AY2 B CH D DH EH0 EH1 EH2 ER0 ER1 ER2 EY0 EY1 EY2 F G HH IH0 IH1 IH2 IY0 IY1 IY2 JH K L M N NG OW0 OW1 OW2 OY0 OY1 OY2 P R S SH T TH UH0 UH1 UH2 UW0 UW1 UW2 V W Y Z ZH'\n"
     ]
    }
   ],
   "source": [
    "input_symbols = sorted(list(input_symbols))\n",
    "target_symbols = sorted(list(target_symbols))\n",
    "num_encoder_tokens = len(input_symbols)\n",
    "num_decoder_tokens = len(target_symbols)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('-', ' '.join(input_symbols))\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('-', repr(' '.join(target_symbols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(s, i) for i, s in enumerate(input_symbols)])\n",
    "target_token_index = dict(\n",
    "    [(s, i) for i, s in enumerate(target_symbols)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, sym in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[sym]] = 1.\n",
    "    for t, sym in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_target_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[sym]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[sym]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6493 samples, validate on 1624 samples\n",
      "Epoch 1/10\n",
      "6493/6493 [==============================] - 33s - loss: 1.4754 - val_loss: 1.4040\n",
      "Epoch 2/10\n",
      "6493/6493 [==============================] - 32s - loss: 1.3763 - val_loss: 1.3352\n",
      "Epoch 3/10\n",
      "6493/6493 [==============================] - 32s - loss: 1.2686 - val_loss: 1.2089\n",
      "Epoch 4/10\n",
      "6493/6493 [==============================] - 33s - loss: 1.1384 - val_loss: 1.0879\n",
      "Epoch 5/10\n",
      "6493/6493 [==============================] - 32s - loss: 1.0291 - val_loss: 1.0113\n",
      "Epoch 6/10\n",
      "6493/6493 [==============================] - 35s - loss: 0.9423 - val_loss: 0.9298\n",
      "Epoch 7/10\n",
      "6493/6493 [==============================] - 34s - loss: 0.8649 - val_loss: 0.8926\n",
      "Epoch 8/10\n",
      "6493/6493 [==============================] - 33s - loss: 0.7970 - val_loss: 0.8150\n",
      "Epoch 9/10\n",
      "6493/6493 [==============================] - 33s - loss: 0.7420 - val_loss: 0.7548\n",
      "Epoch 10/10\n",
      "6493/6493 [==============================] - 35s - loss: 0.6906 - val_loss: 0.7234\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('/tmp/ks2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    start = 0 if decoded_sentence[0] != ' ' else 1\n",
    "    return decoded_sentence[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word                             Correct                               Guess\n",
      "     MCELHINNEY          M AE1 K AH0 L HH IH2 N IY0                   M AH0 K L EH1 N T\n",
      "      IMITATING            IH1 M AH0 T EY2 T IH0 NG                  IH2 M IH1 T IH0 NG\n",
      "       BOLANCIK               B AH0 L AE1 N S AH0 K                   B AH0 L AE1 K AH0\n",
      "     GRZYBOWSKI           G ER2 Z IH0 B AW1 S K IY0                   G ER1 Z Z AH0 N Z\n",
      "        CHATHAM                      CH AE1 T AH0 M                    CH AE1 M AH0 T \n",
      "\n",
      "   ORGANIZATION    AO2 R G AH0 N AH0 Z EY1 SH AH0 N                 Y AH0 G R EY1 N AH0\n",
      "        PROMISE                     P R AA1 M AH0 S                   P R EH1 M AH0 S T\n",
      "       BULKHEAD                  B AH1 L K HH EH2 D                     B EH1 L D AH0 \n",
      "\n",
      "        LEIMERT                       L IY1 M ER0 T                     L EH1 M ER0 T \n",
      "\n",
      "       VERNONIA               V ER0 N OW1 N IY0 AH0                  V AE1 N ER0 IH0 NG\n"
     ]
    }
   ],
   "source": [
    "print('%15s %35s %35s'%('Word', 'Correct', 'Guess'))\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    correct = pdic[pdic['word']==input_texts[seq_index]]['pronunciation'].iloc[0]\n",
    "    print('%15s %35s %35s'%(input_texts[seq_index],\n",
    "                           correct,\n",
    "                           decoded_sentence))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AA0 AA1 AA2 AE0 AE1 AE2 AH0 AH1 AH2 AO0 AO1 AO2 AW0 AW1 \n",
    "AW2 AY0 AY1 AY2 B CH D DH EH0 EH1 EH2 ER0 ER1 ER2 EY0 EY1 \n",
    "EY2 F G HH IH0 IH1 IH2 IY0 IY1 IY2 JH K L M N NG OW0 OW1 OW2 OY0\n",
    "OY1 OY2 P R S SH T TH UH0 UH1 UH2 UW0 UW1 UW2 V W Y Z ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipas = '''a\tAA\tɑ\tbalm, bot\n",
    "@\tAE\tæ\tbat\n",
    "A\tAH\tʌ\tbutt\n",
    "c\tAO\tɔ\tbought\n",
    "W\tAW\taʊ\tbout\n",
    "x\tAX\tə\tabout\n",
    "N/A\tAXR[4]\tɚ\tletter\n",
    "Y\tAY\taɪ\tbite\n",
    "E\tEH\tɛ\tbet\n",
    "R\tER\tɝ\tbird\n",
    "e\tEY\teɪ\tbait\n",
    "I\tIH\tɪ\tbit\n",
    "X\tIX\tɨ\troses, rabbit\n",
    "i\tIY\ti\tbeat\n",
    "o\tOW\toʊ\tboat\n",
    "O\tOY\tɔɪ\tboy\n",
    "U\tUH\tʊ\tbook\n",
    "u\tUW\tu\tboot\n",
    "N/A\tUX[4]\tʉ\tdude\n",
    "b\tB\tb\tbuy\n",
    "C\tCH\ttʃ\tChina\n",
    "d\tD\td\tdie\n",
    "D\tDH\tð\tthy\n",
    "F\tDX\tɾ\tbutter\n",
    "L\tEL\tl̩\tbottle\n",
    "M\tEM\tm̩\trhythm\n",
    "N\tEN\tn̩\tbutton\n",
    "f\tF\tf\tfight\n",
    "g\tG\tɡ\tguy\n",
    "h\tHH or H[4]\th\thigh\n",
    "J\tJH\tdʒ\tjive\n",
    "k\tK\tk\tkite\n",
    "l\tL\tl\tlie\n",
    "m\tM\tm\tmy\n",
    "n\tN\tn\tnigh\n",
    "G\tNX or NG[4]\tŋ\tsing\n",
    "N/A\tNX[4]\tɾ̃\twinner\n",
    "p\tP\tp\tpie\n",
    "Q\tQ\tʔ\tuh-oh\n",
    "r\tR\tɹ\trye\n",
    "s\tS\ts\tsigh\n",
    "S\tSH\tʃ\tshy\n",
    "t\tT\tt\ttie\n",
    "T\tTH\tθ\tthigh\n",
    "v\tV\tv\tvie\n",
    "w\tW\tw\twise\n",
    "H\tWH\tʍ\twhy\n",
    "y\tY\tj\tyacht\n",
    "z\tZ\tz\tzoo\n",
    "Z\tZH\tʒ\tpleasure'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipasym = {}\n",
    "for lin in ipas.split('\\n'):\n",
    "    sym = lin.split('\\t')\n",
    "    ipasym[sym[1]] = sym[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
