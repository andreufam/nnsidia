{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICAÇÃO DE SEQUÊNCIAS COM RNNs (LSTMs/GRUs)\n",
    "\n",
    "Nesta seção vamos usar LSTMs e GRUs para resolver três tipos de problemas envolvendo sequências: classificação de sequências de tamanho fixo (aplicada em tarefas como previsão de séries de tempo), classificação de sequências de tamanho variável (aplicada em tarefas como classificação de sentenças em língua natural) e mapeamento de sequência para sequência (aplicada em tarefas como tradução ou diálogo em língua natural). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"intro\"/> Introdução\n",
    "Redes Neurais recorrentes (Recurrent Neural Networks - RNNs) são redes neurais profundas com um mecanismo de auto-alimentação inerente. Na prática, a saída de uma camada é adicionada à próxima entrada, servindo como feedback para própria camada. Abaixo temos uma representação de uma RNN:\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/v7p90neiaqghmpwawpiecmz9n7080m59.png\" alt=\"Representation of a Recurrent Neural Network\" width=80%>\n",
    "\n",
    "RNNs são úteis para lidar com o problema de **manutenção do contexto em dados sequênciais** -- o caso de previsão de tempo, ações em mercado financeiro, palavras em uma frase, etc. Em cada iteração, a unidade de processamento obtem uma entrada e o estado atual da rede (o contexto), e gera como saída um novo estado que **re-alimenta a rede**.\n",
    "\n",
    "Este modelo tem uns problemas sérios. É muito caro manter o estado por um grande número de unidades e, mais ainda, por muito tempo. RNNs são também muito sensíveis a mudanças nos seus parâmetros. Assim, elas são muito sucetíveis a problemas com a otimização via gradientes -- elas crescem exponencialmente (Exploding Gradient) ou vão a zero e se estabilizam (Vanishing Gradient), dificultando muito o aprendizado.\n",
    "\n",
    "Para lidar com estes problemas, muitas técnicas já foram propostas. Uma delas, descrita por Hochreiter e Schmidhuber published em 1997, dota a estrutura de memória, o que a torna capaz de manter informação por longos períodos de tempo e, adicionalmente, resolver o problema de sensibilidade. Isto tonar mais viável fazer backpropagation em RNNs. Estas são as LSTMs (Long short-term memory model).\n",
    "\n",
    "Note que muitas outras soluções foram propostas para estes problemas, o que resultou em muitas arquiteturas, além das LSTMs:\n",
    "\n",
    "- Fully Recurrent Network\n",
    "- Recursive Neural Networks\n",
    "- Hopfield Networks\n",
    "- Elman Networks e Jordan Networks\n",
    "- Echo State Networks\n",
    "- Neural history compressor\n",
    "\n",
    "Nossa opção por LSTMs, de alguma forma, está no fato delas incorporarem uma ideia realmente interessante: neurônios formarem células de memória. A ideia geral de LSTMs deu origem a muitas variantes. Entre elas, uma que tem ganho popularidade são as GRUs, uma forma simplificada de LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a id=\"lstm\"/>LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É uma abstração de como seria uma célula de memória, de um ponto de vista funcional. Ela pode ser usada no lugar de qualquer unidade em uma RNN, sendo responsável por ler, escrever ou lembrar de informação fluindo no modelo. Consiste basicamente de uma unidade linear (a celula de informação propriamente dita) envoltas por três portas lógicas, responsáveis pela manutenção dos dados. Uma é responsável por permitir que dados fluam para a célulade informação (entrada), uma pela saída da célula e a última é responável por lembrar ou esquecer de dados de acordo com as necessidades da rede.\n",
    "\n",
    "Graças à LSTM, é resolvido o problema de manter estados, porque a rede pode escolher esquecê-los se já não servem mais, como o problema dos gradientes, uma vez que as portas lógicas têm derivadas menos suscetíveis a problemas.\n",
    "\n",
    "### Arquitetura Long Short-Term Memory \n",
    "\n",
    "Neste texto, vamos considerar que uma LSTM é formada por três portas lógicas: \"Input\" ou \"Write\", responsável pela escrita na LSTM de dados vindos do resto da RNN; \"Output\" ou \"Read\", responsável pela saída da LSTM para o resto da RNN; e \"Keep\" ou \"Forget\", rsponsável pela manutenção ou modificação de dados armazenados na LSTM.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagrama de uma Long Short-Term Memory Unit*</center>\n",
    "\n",
    "Se você estiver mais interssado em saber sobre LSTMs e suas variantes, incluindo GRUs, leia o blog: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"build\"/> LSTMs com TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:  (55000, 784)\n",
      "Train Labels   (55000, 10)\n",
      "\n",
      "Test Images:   (10000, 784)\n",
      "Test Labels:   (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "trainimgs = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs = mnist.test.images\n",
    "testlabels = mnist.test.labels \n",
    "\n",
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "print \"Train Images: \", trainimgs.shape\n",
    "print \"Train Labels  \", trainlabels.shape\n",
    "print\n",
    "print \"Test Images:  \" , testimgs.shape\n",
    "print \"Test Labels:  \", testlabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compreendendo MNIST \n",
    "\n",
    "O código abaixo mostra exemplos de instâncias de MNIST e seus rótulos, como vetores one-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADtCAYAAAB0xiROAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac1b7f5950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 110 - Class: [8] - Label Vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.] \n",
      "Sample: 345 - Class: [1] - Label Vector: [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.] \n",
      "Sample: 456 - Class: [2] - Label Vector: [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.] \n"
     ]
    }
   ],
   "source": [
    "samplesIdx = [110, 345, 456]  #<-- You can change these numbers here to see other samples\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(testimgs[samplesIdx[0]].reshape([28,28]), cmap='gray')\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0,28,28), np.linspace(0,28,28))\n",
    "X =  xx ; Y =  yy\n",
    "Z =  100*np.ones(X.shape)\n",
    "\n",
    "img = testimgs[77].reshape([28,28])\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.set_zlim((0,200))\n",
    "\n",
    "\n",
    "offset=200\n",
    "for i in samplesIdx:\n",
    "    img = testimgs[i].reshape([28,28]).transpose()\n",
    "    ax.contourf(X, Y, img, 200, zdir='z', offset=offset, cmap=\"gray\")\n",
    "    offset -= 100\n",
    "\n",
    "    ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in samplesIdx:\n",
    "    print \"Sample: {0} - Class: {1} - Label Vector: {2} \".format(i, np.nonzero(testlabels[i])[0], testlabels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imagens como sequências de linhas\n",
    "\n",
    "Vamos tratar uma imagem MNIST $\\in \\mathcal{R}^{28 \\times 28}$ como $28$ sequẽncias de um vetor $\\mathbf{x} \\in \\mathcal{R}^{28}$. \n",
    "\n",
    "#### Nossa RNN simples consiste de:\n",
    "1. Uma camada de entrada que converte uma entrada de $28$ dimensões em uma camada oculta de $128$ neurônios, \n",
    "2. Uma camada oculta com 128 nós LSTM \n",
    "3. Uma camada de saída que converte a saída de $128$ dimensões para $10$ neurônios, cada qual indicando representando um dígito de 0 a 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 100 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A RNN\n",
    "\n",
    "Inicialmente, vamos definir os placeholders para as entradas (x) e rótulos (y), além dos pesos e biases da camada de saída (estava vai ser a única camada com pesos e biases, já que as demais unidades serão LSTMs). A entrada x corresponde a _n_ batches de 28 sequências de 28 valores; a saída y, _n_ batches de 10 valores (já que usamos hot-vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=\"float\", shape=[None, n_steps, n_input], name=\"x\")\n",
    "y = tf.placeholder(dtype=\"float\", shape=[None, n_classes], name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN propriamente dita conecta a entrada x com as LSTMs e estas com a saída. Note que a entrada tem a forma de _batches_ de _passos_ de _entradas_. Contudo, a RNN deve receber _passos_ **listas** de _batches_ de _entradas_, já que vai em cada passo fazer estimativas para o batch inteiro de entradas. Logo, precisamos modificar a forma `x[batches, passos, entradas]` para _passos_ listas de `x[batches, entradas]`. \n",
    "\n",
    "Vamos ver como fazer esta transformação usando apenas numpy, primeiro. Como exemplo suponha que temos 4 batches de 3 passos de 2 entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2)\n",
      "[[[111 112]\n",
      "  [121 122]\n",
      "  [131 132]]\n",
      "\n",
      " [[211 212]\n",
      "  [221 222]\n",
      "  [231 232]]\n",
      "\n",
      " [[311 312]\n",
      "  [321 322]\n",
      "  [331 332]]\n",
      "\n",
      " [[411 412]\n",
      "  [421 422]\n",
      "  [431 432]]]\n"
     ]
    }
   ],
   "source": [
    "# um exemplo com 4 batches de 3 passos de 2 entradas\n",
    "ex_steps = 3 \n",
    "ex_batches = 4\n",
    "ex_inputs = 2\n",
    "txnp = np.array([[[111,112],[121,122],[131,132]], \n",
    "                 [[211,212],[221,222],[231,232]], \n",
    "                 [[311,312],[321,322],[331,332]], \n",
    "                 [[411,412],[421,422],[431,432]]])\n",
    "print txnp.shape\n",
    "print txnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos obter 3 listas de tensores 4x2 Assim, primeiro transformamos nossos tensores 4x3x2 em 3x4x2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 2)\n",
      "[[[111 112]\n",
      "  [211 212]\n",
      "  [311 312]\n",
      "  [411 412]]\n",
      "\n",
      " [[121 122]\n",
      "  [221 222]\n",
      "  [321 322]\n",
      "  [421 422]]\n",
      "\n",
      " [[131 132]\n",
      "  [231 232]\n",
      "  [331 332]\n",
      "  [431 432]]]\n"
     ]
    }
   ],
   "source": [
    "txnp = np.transpose(txnp, [1, 0, 2]) # eixo 0 vira 1 e eixo 1 vira 0\n",
    "print txnp.shape\n",
    "print txnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos transformar o tensor 4x3x2 em um tensor 12x2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "[[111 112]\n",
      " [211 212]\n",
      " [311 312]\n",
      " [411 412]\n",
      " [121 122]\n",
      " [221 222]\n",
      " [321 322]\n",
      " [421 422]\n",
      " [131 132]\n",
      " [231 232]\n",
      " [331 332]\n",
      " [431 432]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "txnp = np.reshape(txnp, [-1, ex_inputs])\n",
    "print txnp.shape\n",
    "print txnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, finalmente, converte-lo em uma lista de 3 tensores 4x2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[111, 112],\n",
      "       [211, 212],\n",
      "       [311, 312],\n",
      "       [411, 412]]), array([[121, 122],\n",
      "       [221, 222],\n",
      "       [321, 322],\n",
      "       [421, 422]]), array([[131, 132],\n",
      "       [231, 232],\n",
      "       [331, 332],\n",
      "       [431, 432]])]\n"
     ]
    }
   ],
   "source": [
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "txnp = np.split(txnp, ex_steps)\n",
    "print txnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em tensorflow, isso pode ser escrito assim: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_to_RNN(x, n_steps):\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(split_dim=0, num_split=n_steps, value=x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que nossa RNN fica: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    x = input_to_RNN(x, n_steps)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(cell=lstm_cell, inputs=x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede neural em si é bem tradicional. Usamos entropia cruzada para o custo; o algoritmo de Adam para minimizar o custo; e acurácia como medida de qualidade: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('forward'):\n",
    "    pred = RNN(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de treino consiste em obter 128 imagens por batch de treino e entregá-las para a RNN-LSTM a cada iteração. Este processo é realizado por um certo número de iterações (training_iters). Ao fim, o modelo é avaliado na coleção de teste: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-46-241fd3ce3424>:1 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Iter 1280, Minibatch Loss= 2.114965, Training Accuracy= 0.22656\n",
      "Iter 2560, Minibatch Loss= 1.689952, Training Accuracy= 0.48438\n",
      "Iter 3840, Minibatch Loss= 1.489810, Training Accuracy= 0.43750\n",
      "Iter 5120, Minibatch Loss= 1.156798, Training Accuracy= 0.64844\n",
      "Iter 6400, Minibatch Loss= 0.963463, Training Accuracy= 0.68750\n",
      "Iter 7680, Minibatch Loss= 1.289312, Training Accuracy= 0.51562\n",
      "Iter 8960, Minibatch Loss= 0.952871, Training Accuracy= 0.69531\n",
      "Iter 10240, Minibatch Loss= 0.725280, Training Accuracy= 0.73438\n",
      "Iter 11520, Minibatch Loss= 0.442451, Training Accuracy= 0.86719\n",
      "Iter 12800, Minibatch Loss= 0.629821, Training Accuracy= 0.80469\n",
      "Iter 14080, Minibatch Loss= 0.543252, Training Accuracy= 0.81250\n",
      "Iter 15360, Minibatch Loss= 0.463248, Training Accuracy= 0.82812\n",
      "Iter 16640, Minibatch Loss= 0.512322, Training Accuracy= 0.83594\n",
      "Iter 17920, Minibatch Loss= 0.356376, Training Accuracy= 0.88281\n",
      "Iter 19200, Minibatch Loss= 0.299460, Training Accuracy= 0.92188\n",
      "Iter 20480, Minibatch Loss= 0.184032, Training Accuracy= 0.96094\n",
      "Iter 21760, Minibatch Loss= 0.557894, Training Accuracy= 0.78906\n",
      "Iter 23040, Minibatch Loss= 0.177531, Training Accuracy= 0.93750\n",
      "Iter 24320, Minibatch Loss= 0.437146, Training Accuracy= 0.85938\n",
      "Iter 25600, Minibatch Loss= 0.381019, Training Accuracy= 0.86719\n",
      "Iter 26880, Minibatch Loss= 0.200219, Training Accuracy= 0.92969\n",
      "Iter 28160, Minibatch Loss= 0.249591, Training Accuracy= 0.93750\n",
      "Iter 29440, Minibatch Loss= 0.289498, Training Accuracy= 0.92188\n",
      "Iter 30720, Minibatch Loss= 0.258397, Training Accuracy= 0.90625\n",
      "Iter 32000, Minibatch Loss= 0.237388, Training Accuracy= 0.91406\n",
      "Iter 33280, Minibatch Loss= 0.320465, Training Accuracy= 0.89844\n",
      "Iter 34560, Minibatch Loss= 0.219524, Training Accuracy= 0.94531\n",
      "Iter 35840, Minibatch Loss= 0.231902, Training Accuracy= 0.92969\n",
      "Iter 37120, Minibatch Loss= 0.336298, Training Accuracy= 0.89062\n",
      "Iter 38400, Minibatch Loss= 0.137300, Training Accuracy= 0.96875\n",
      "Iter 39680, Minibatch Loss= 0.181674, Training Accuracy= 0.93750\n",
      "Iter 40960, Minibatch Loss= 0.345220, Training Accuracy= 0.88281\n",
      "Iter 42240, Minibatch Loss= 0.172509, Training Accuracy= 0.97656\n",
      "Iter 43520, Minibatch Loss= 0.148533, Training Accuracy= 0.93750\n",
      "Iter 44800, Minibatch Loss= 0.144851, Training Accuracy= 0.96875\n",
      "Iter 46080, Minibatch Loss= 0.145678, Training Accuracy= 0.96094\n",
      "Iter 47360, Minibatch Loss= 0.219623, Training Accuracy= 0.95312\n",
      "Iter 48640, Minibatch Loss= 0.231194, Training Accuracy= 0.92969\n",
      "Iter 49920, Minibatch Loss= 0.230363, Training Accuracy= 0.91406\n",
      "Iter 51200, Minibatch Loss= 0.143299, Training Accuracy= 0.92969\n",
      "Iter 52480, Minibatch Loss= 0.191881, Training Accuracy= 0.95312\n",
      "Iter 53760, Minibatch Loss= 0.028954, Training Accuracy= 1.00000\n",
      "Iter 55040, Minibatch Loss= 0.354542, Training Accuracy= 0.89844\n",
      "Iter 56320, Minibatch Loss= 0.124627, Training Accuracy= 0.96094\n",
      "Iter 57600, Minibatch Loss= 0.131009, Training Accuracy= 0.95312\n",
      "Iter 58880, Minibatch Loss= 0.065187, Training Accuracy= 0.99219\n",
      "Iter 60160, Minibatch Loss= 0.148504, Training Accuracy= 0.93750\n",
      "Iter 61440, Minibatch Loss= 0.180989, Training Accuracy= 0.96094\n",
      "Iter 62720, Minibatch Loss= 0.149761, Training Accuracy= 0.96094\n",
      "Iter 64000, Minibatch Loss= 0.124851, Training Accuracy= 0.96094\n",
      "Iter 65280, Minibatch Loss= 0.083794, Training Accuracy= 0.96875\n",
      "Iter 66560, Minibatch Loss= 0.155126, Training Accuracy= 0.92969\n",
      "Iter 67840, Minibatch Loss= 0.170068, Training Accuracy= 0.95312\n",
      "Iter 69120, Minibatch Loss= 0.172764, Training Accuracy= 0.95312\n",
      "Iter 70400, Minibatch Loss= 0.225618, Training Accuracy= 0.93750\n",
      "Iter 71680, Minibatch Loss= 0.105085, Training Accuracy= 0.96094\n",
      "Iter 72960, Minibatch Loss= 0.110651, Training Accuracy= 0.96094\n",
      "Iter 74240, Minibatch Loss= 0.095415, Training Accuracy= 0.97656\n",
      "Iter 75520, Minibatch Loss= 0.073593, Training Accuracy= 0.99219\n",
      "Iter 76800, Minibatch Loss= 0.159389, Training Accuracy= 0.96094\n",
      "Iter 78080, Minibatch Loss= 0.077388, Training Accuracy= 0.98438\n",
      "Iter 79360, Minibatch Loss= 0.098820, Training Accuracy= 0.96875\n",
      "Iter 80640, Minibatch Loss= 0.037794, Training Accuracy= 0.99219\n",
      "Iter 81920, Minibatch Loss= 0.123597, Training Accuracy= 0.96094\n",
      "Iter 83200, Minibatch Loss= 0.114284, Training Accuracy= 0.96094\n",
      "Iter 84480, Minibatch Loss= 0.165293, Training Accuracy= 0.95312\n",
      "Iter 85760, Minibatch Loss= 0.100389, Training Accuracy= 0.96094\n",
      "Iter 87040, Minibatch Loss= 0.068853, Training Accuracy= 0.98438\n",
      "Iter 88320, Minibatch Loss= 0.114537, Training Accuracy= 0.97656\n",
      "Iter 89600, Minibatch Loss= 0.135177, Training Accuracy= 0.96875\n",
      "Iter 90880, Minibatch Loss= 0.139688, Training Accuracy= 0.96094\n",
      "Iter 92160, Minibatch Loss= 0.105082, Training Accuracy= 0.96094\n",
      "Iter 93440, Minibatch Loss= 0.095792, Training Accuracy= 0.96094\n",
      "Iter 94720, Minibatch Loss= 0.170603, Training Accuracy= 0.96094\n",
      "Iter 96000, Minibatch Loss= 0.193548, Training Accuracy= 0.95312\n",
      "Iter 97280, Minibatch Loss= 0.069078, Training Accuracy= 0.99219\n",
      "Iter 98560, Minibatch Loss= 0.076339, Training Accuracy= 0.96875\n",
      "Iter 99840, Minibatch Loss= 0.084555, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.984375)\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        # 128 x 784\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RNNs Dinâmicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo anterior, todas as nossas sequências tinham o mesmo tamanho (28). Em muitos problemas, este não é o caso, com as sequências de entrada tendo tamanho variável. Uma forma de lidar com este problema é normalizando-as para que tenham todas o mesmo tamanho. \n",
    "\n",
    "No exemplo abaixo, vamos ver como mudar a rede dinâmicamente para lidar com os tamanho variáveis. Neste exemplo, vamos construir uma RNN capaz de, dada uma sequência de números, determinar se ela é ou não aleatória. \n",
    "\n",
    "Vamos inicialmente criar uma classe capaz de gerar sequências de números, aleatórias e não aleatórias, dinâmicamente. Para cada sequência, a classe informa sua categoria (aleatória ou não aleatória), seu tamanho e a própria sequencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# ====================\n",
    "#  TOY DATA GENERATOR\n",
    "# ====================\n",
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n",
    "                 max_value=1000):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        for i in range(n_samples):\n",
    "            # Random sequence length\n",
    "            len = random.randint(min_seq_len, max_seq_len)\n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(len)\n",
    "            # Add a random or linear int sequence (50% prob)\n",
    "            if random.random() < .5:\n",
    "                # Generate a linear sequence\n",
    "                rand_start = random.randint(0, max_value - len)\n",
    "                s = [[float(i)/max_value] for i in\n",
    "                     range(rand_start, rand_start + len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                # Generate a random sequence\n",
    "                s = [[float(random.randint(0, max_value))/max_value]\n",
    "                     for i in range(len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([0., 1.])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen\n",
    "\n",
    "    def to_str(self, seq):\n",
    "        strout = ''\n",
    "        batch_data, batch_labels, batch_seqlen = seq\n",
    "        for i in range(len(batch_labels)):\n",
    "            strout += str(batch_labels[i]) + ' ' + str(batch_seqlen[i]) + ' ' + str(batch_data[i]) + '\\n'\n",
    "        return strout\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como um exemplo de uso da classe, vamos exibir os batches criados para 12 sequências aleatórias. Para cada sequênica é exibido sua label (one-hot), o tamanho da sequência e a sequência em si. Note que as sequências são geradas com zeros à direita (_right padding_), quando elas têm tamanho menor que `max_seq_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "[0.0, 1.0] 4 [[0.1], [0.2], [0.4], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 0.0] 4 [[0.6], [0.7], [0.8], [0.9], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[0.0, 1.0] 8 [[0.3], [0.1], [0.7], [0.0], [0.9], [0.4], [0.6], [0.4], [0.0], [0.0]]\n",
      "\n",
      "batch 1\n",
      "[1.0, 0.0] 8 [[0.0], [0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.0], [0.0]]\n",
      "[0.0, 1.0] 9 [[0.6], [1.0], [0.3], [0.1], [0.1], [0.4], [1.0], [0.3], [0.6], [0.0]]\n",
      "[1.0, 0.0] 7 [[0.0], [0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.0], [0.0], [0.0]]\n",
      "\n",
      "batch 2\n",
      "[1.0, 0.0] 7 [[0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9], [0.0], [0.0], [0.0]]\n",
      "[0.0, 1.0] 6 [[0.2], [0.5], [0.7], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 0.0] 10 [[0.0], [0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9]]\n",
      "\n",
      "batch 3\n",
      "[1.0, 0.0] 6 [[0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.0], [0.0], [0.0], [0.0]]\n",
      "[0.0, 1.0] 6 [[0.3], [0.8], [1.0], [0.1], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
      "[1.0, 0.0] 9 [[0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9], [0.0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 12\n",
    "batch_size = 3\n",
    "tsd = ToySequenceData(n_samples, max_seq_len=10, \n",
    "                      min_seq_len=3, max_value=10)\n",
    "n_batches = n_samples / batch_size\n",
    "for i in range(n_batches):\n",
    "    s = tsd.next(batch_size)\n",
    "    print('batch %d\\n%s' % (i, tsd.to_str(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo terá, no máximo, 20 entradas, conectadas a 64 unidades ocultas, que por sua vez se conectam a 2 neurônios na saída (classes aleatório e não-aleatório). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 20 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "testset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN é criada como antes. Ao preparar a entrada, consideramos que os tensores tem no máximo seq_max_len passos. Neste exemplo, apenas para ilustração, usamos uma GRU no lugar de uma LSTM. Uma GRU (Gated Recurrent Unit, Cho et al, 2014) é uma variante de uma LSTM. Ela combina os gates _forget_ e _input_ em um único gate _update_. Ela também combina os estados oculto e da célula, além de outras pequenas mudanças, que a tornam um modelo mais simples que as LSTMs (embora menos intuitivos). Na prática, elas tem desempenho similar a LSTMs, mas com custo geral menor, pois são menos complexas.\n",
    "\n",
    "O aspecto mais importante de uma RNN dinâmica, contudo, é que _a saída do passo anterior que nos interessa corresponde ao tamanho da sequência_. Por exemplo, se a última sequência tinha tamanho 5, é a saída da 5a unidade (GRU em nosso exemplo) que deve ser estado oculto (de entrada) para a primeira unidade da próxima sequência. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    x = input_to_RNN(x, seq_max_len)\n",
    "    \n",
    "    # Define a GRU cell with tensorflow\n",
    "    gru_cell = tf.nn.rnn_cell.GRUCell(n_hidden)\n",
    "\n",
    "    # Get GRU cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.nn.rnn(gru_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.pack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mais, seguem as técnicas tradicionais de treino e teste, como antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,\n",
    "                                             seqlen: batch_seqlen})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                      seqlen: test_seqlen}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs Sequence to Sequence: soletrando a partir de pronúncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De https://github.com/mikesj-public/rnn_spelling_bee/blob/master/spelling_bee_RNN.ipynb. Dados de _The CMU pronouncing dictionary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, vamos criar um modelo que, dada a pronuncia de uma palavra como uma lista de fonemas, ele tenta escrever corretamente a palavra. Este problema é mais simples que _fala para texto_ ou _tradução_ (no sentido de não precisarmos de quantidades colossais de dados para ver algo acontecer [:)]); contudo, uma dificuldade aqui é a avaliação na escrita de palavras nunca vistas antes. Isto é díficil porque (1) há muitas pronúncias com várias transcrições razoáveis além de (2) palavras homônicas com transcrições distintas (_read_, no passado e presente, por exemplo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando os dados..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example line of file : \n",
      "SPELLING  S P EH1 L IH0 NG\n"
     ]
    }
   ],
   "source": [
    "cmu_dict_raw = open(\"cmudict-0.7b\").read()\n",
    "\n",
    "first_line = \"A  AH0\"\n",
    "last_line = \"ZYWICKI  Z IH0 W IH1 K IY0\"\n",
    "\n",
    "lines = cmu_dict_raw.split(\"\\n\")\n",
    "\n",
    "for i, l in enumerate(lines):\n",
    "    if l == first_line:\n",
    "        first_index = i\n",
    "    if l == last_line:\n",
    "        last_index = i\n",
    "        \n",
    "print \"Example line of file : \"\n",
    "print lines[113108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a 1\n",
      "AA0 1\n"
     ]
    }
   ],
   "source": [
    "# dictionaries to convert between indexes and letters/phonemes\n",
    "\n",
    "phonemes = set()\n",
    "\n",
    "for l in lines[first_index : last_index + 1]:\n",
    "    word, pronounce = l.split(\"  \")\n",
    "    for phoneme in pronounce.split():\n",
    "        phonemes.add(phoneme)\n",
    "        \n",
    "sorted_phonemes = [\"_\"] + sorted(list(phonemes))\n",
    "\n",
    "index_to_phoneme = dict(enumerate(sorted_phonemes))\n",
    "phoneme_to_index = dict((v, k) for k,v in index_to_phoneme.items())\n",
    "\n",
    "index_to_letter = dict(enumerate(\"_abcdefghijklmnopqrstuvwxyz\"))\n",
    "letter_to_index = dict((v, k) for k,v in index_to_letter.items())\n",
    "\n",
    "print index_to_letter[1], letter_to_index['a']\n",
    "print index_to_phoneme[1], phoneme_to_index['AA0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 8, 65] ['L', 'AH1', 'V']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "pronounce_dict = {}\n",
    "\n",
    "for l in lines[first_index : last_index + 1]:\n",
    "    word, phone_list = l.split(\"  \")\n",
    "    pronounce_dict[word.lower()] = [phoneme_to_index[p] for p in phone_list.split()]\n",
    "    \n",
    "print pronounce_dict['love'], [index_to_phoneme[i] for i in pronounce_dict['love']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior palavra do vocubulário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supercalifragilisticexpialidocious\n",
      "[55, 64, 53, 26, 42, 6, 43, 7, 32, 54, 5, 41, 7, 43, 37, 55, 57, 35, 42, 25, 42, 55, 53, 38, 6, 43, 7, 21, 48, 56, 7, 55]\n"
     ]
    }
   ],
   "source": [
    "max_k = max([len(k) for k,v in pronounce_dict.items()])\n",
    "max_v = max([len(v) for k,v in pronounce_dict.items()])\n",
    "for k,v in pronounce_dict.items():\n",
    "    if len(k) == max_k or  len(v) == max_v:\n",
    "        print k\n",
    "        print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos nos livrar de palavras muito longas ou com pontuação e espaço:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antes: 133779\n",
      "depois: 108006\n"
     ]
    }
   ],
   "source": [
    "bad_ct = set()\n",
    "\n",
    "letters = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "print 'antes:', len(pronounce_dict)\n",
    "for k, v in pronounce_dict.items():\n",
    "    if len(k) < 5 or len(k) > 15:\n",
    "        del pronounce_dict[k]\n",
    "        continue\n",
    "    for c in k:\n",
    "        if c not in letters:\n",
    "            del pronounce_dict[k]\n",
    "            break\n",
    "print 'depois:', len(pronounce_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide linhas em palavras e fonemas, converte para índices (com padding); separa em treino, teste e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pairs = np.random.permutation(list(pronounce_dict.keys()))\n",
    "\n",
    "input_ = np.zeros((len(pairs), 16))\n",
    "labels_ = np.zeros((len(pairs), 15))\n",
    "\n",
    "for i, k in enumerate(pairs):\n",
    "    v = pronounce_dict[k]\n",
    "    k = k + \"_\" * (15 - len(k))\n",
    "    v = v + [0] * (16 - len(v))\n",
    "    for j, n in enumerate(v):\n",
    "        input_[i][j] = n\n",
    "    for j, letter in enumerate(k):\n",
    "        labels_[i][j] = letter_to_index[letter]\n",
    "        \n",
    "input_ = input_.astype(np.int32)\n",
    "labels_ = labels_.astype(np.int32)\n",
    "\n",
    "input_test   = input_[:10000]\n",
    "input_val    = input_[10000:20000]\n",
    "input_train  = input_[20000:]\n",
    "labels_test  = labels_[:10000]\n",
    "labels_val   = labels_[10000:20000]\n",
    "labels_train = labels_[20000:]\n",
    "\n",
    "data_test  = zip(input_test, labels_test)\n",
    "data_val   = zip(input_val, labels_val)\n",
    "data_train = zip(input_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando em tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tensorflow.models.rnn import rnn_cell, seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo uma sessão interativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq_length = 16\n",
    "output_seq_length = 15\n",
    "batch_size = 128\n",
    "\n",
    "input_vocab_size = 70\n",
    "output_vocab_size = 28\n",
    "embedding_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa RNN tem a seguinte topologia:\n",
    "\n",
    "<img src=\"rnn_seq2seq.png\">\n",
    "\n",
    "Ou seja, a entrada do decodificador (`decode_input`) tem que ser deslocada de 1 dos rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_input = [tf.placeholder(tf.int32, shape=(None,), name = \"ei_%i\" %i) \n",
    "                for i in range(input_seq_length)]\n",
    "\n",
    "labels = [tf.placeholder(tf.int32, shape=(None,), name = \"l_%i\" %i) \n",
    "          for i in range(output_seq_length)]\n",
    "\n",
    "decode_input = [tf.zeros_like(encode_input[0], dtype=np.int32, name=\"GO\")] + labels[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima célula é o cerne do nosso modelo. Nossa RNN é formada por células LSTM com dropout entre as camadas. Empilhamos 3 dessas (LSTM+dropout) para formar a rede neural completa. Executamos essa rede com o padrão `seq2seq.embedding_rnn_seq2seq` que permite que a alimentemos com uma sequência normal de números e esta é convertida automaticamente pela própria rede em uma sequência de embeddings de tensores one-hot.\n",
    "\n",
    "Note que nós construimos duas redes no escopo 'decoders'. Uma delas usa `feed_previous = True` enquanto a outra não. Isso é setado para False durante o treino, de forma que mesmo que o aprendiz cometa um erro em uma letra - nós ainda passamos pra ele o rótulo correto em `decoder_inputs`. Como não teríamos os rótulos corretos em um teste real, para o conjunto de teste usamos `feed_previous = True` e o decodificador recebe a letra com máxima probabilidade do último passo da saída do decodificador.\n",
    "\n",
    "`decode_output` é um tensor com forma (batch_size, output_vocab_size). Nós podemos aplicar softmax a este tensor para obter escores logísticos para cada letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "# range(3) para formar uma pilha com 3 camadas\n",
    "cells = [tf.nn.rnn_cell.DropoutWrapper(\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(embedding_dim), output_keep_prob=keep_prob\n",
    "    ) for i in range(3)]\n",
    "\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "\n",
    "with tf.variable_scope(\"decoders\") as scope:\n",
    "    decode_outputs, decode_state = tf.nn.seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, output_vocab_size, embedding_dim)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    decode_outputs_test, decode_state_test = tf.nn.seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, output_vocab_size, embedding_dim,\n",
    "    feed_previous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequence_loss` é entropia cruzada aplicada ao softmax das saídas do decodificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_weights = [tf.ones_like(l, dtype=tf.float32) for l in labels]\n",
    "loss = tf.nn.seq2seq.sequence_loss(decode_outputs, labels, loss_weights, output_vocab_size, embedding_dim)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-9f5df2c7784a>:1 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta classe pega batches aleatórios e os arranja de forma adequada para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataIterator:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.iter = self.make_random_iter()\n",
    "        \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            idxs = self.iter.next()\n",
    "        except StopIteration:\n",
    "            self.iter = self.make_random_iter()\n",
    "            idxs = self.iter.next()\n",
    "        X, Y = zip(*[self.data[i] for i in idxs])\n",
    "        X = np.array(X).T\n",
    "        Y = np.array(Y).T\n",
    "        return X, Y\n",
    "\n",
    "    def make_random_iter(self):\n",
    "        splits = np.arange(self.batch_size, len(self.data), self.batch_size)\n",
    "        it = np.split(np.random.permutation(range(len(self.data))), splits)[:-1]\n",
    "        return iter(it)\n",
    "    \n",
    "train_iter = DataIterator(data_train, 128)\n",
    "val_iter = DataIterator(data_val, 128)\n",
    "test_iter = DataIterator(data_test, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação é feita usando tanto a perda da seq2seq quanto a precisão, ou seja, a proporção de palavras escritas corretamente pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_feed(X, Y):\n",
    "    feed_dict = {encode_input[t]: X[t] for t in range(input_seq_length)}\n",
    "    feed_dict.update({labels[t]: Y[t] for t in range(output_seq_length)})\n",
    "    return feed_dict\n",
    "\n",
    "def train_batch(data_iter):\n",
    "    X, Y = data_iter.next_batch()\n",
    "    feed_dict = get_feed(X, Y)\n",
    "    feed_dict[keep_prob] = 0.5\n",
    "    _, out = sess.run([train_op, loss], feed_dict)\n",
    "    return out\n",
    "\n",
    "def get_eval_batch_data(data_iter):\n",
    "    X, Y = data_iter.next_batch()\n",
    "    feed_dict = get_feed(X, Y)\n",
    "    feed_dict[keep_prob] = 1.\n",
    "    all_output = sess.run([loss] + decode_outputs_test, feed_dict)\n",
    "    eval_loss = all_output[0]\n",
    "    decode_output = np.array(all_output[1:]).transpose([1,0,2])\n",
    "    return eval_loss, decode_output, X, Y\n",
    "\n",
    "def eval_batch(data_iter, num_batches):\n",
    "    losses = []\n",
    "    predict_loss = []\n",
    "    for i in range(num_batches):\n",
    "        eval_loss, output, X, Y = get_eval_batch_data(data_iter)\n",
    "        losses.append(eval_loss)\n",
    "        \n",
    "        for index in range(len(output)):\n",
    "            real = Y.T[index]\n",
    "            predict = np.argmax(output, axis = 2)[index]\n",
    "            predict_loss.append(all(real==predict))\n",
    "    return np.mean(losses), np.mean(predict_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de execução deixada até cerca de 20000 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss   : 3.216738, val predict   = 0.0%\n",
      "train loss : 3.217064, train predict = 0.0%\n",
      "\n",
      "val loss   : 0.923874, val predict   = 0.2%\n",
      "train loss : 0.943416, train predict = 0.6%\n",
      "\n",
      "val loss   : 0.587645, val predict   = 8.2%\n",
      "train loss : 0.583814, train predict = 8.0%\n",
      "\n",
      "val loss   : 0.455057, val predict   = 14.2%\n",
      "train loss : 0.446224, train predict = 15.5%\n",
      "\n",
      "val loss   : 0.379664, val predict   = 16.8%\n",
      "train loss : 0.383763, train predict = 19.1%\n",
      "\n",
      "val loss   : 0.335629, val predict   = 22.9%\n",
      "train loss : 0.334294, train predict = 23.2%\n",
      "\n",
      "val loss   : 0.316641, val predict   = 27.2%\n",
      "train loss : 0.305840, train predict = 25.0%\n",
      "\n",
      "val loss   : 0.290137, val predict   = 28.1%\n",
      "train loss : 0.273253, train predict = 29.7%\n",
      "\n",
      "val loss   : 0.263898, val predict   = 32.2%\n",
      "train loss : 0.262774, train predict = 31.8%\n",
      "\n",
      "val loss   : 0.264169, val predict   = 30.9%\n",
      "train loss : 0.239268, train predict = 35.0%\n",
      "\n",
      "val loss   : 0.245243, val predict   = 34.2%\n",
      "train loss : 0.228171, train predict = 36.8%\n",
      "\n",
      "val loss   : 0.236577, val predict   = 34.6%\n",
      "train loss : 0.213116, train predict = 37.7%\n",
      "\n",
      "val loss   : 0.222518, val predict   = 37.6%\n",
      "train loss : 0.209775, train predict = 38.1%\n",
      "\n",
      "val loss   : 0.226416, val predict   = 37.1%\n",
      "train loss : 0.192899, train predict = 42.6%\n",
      "\n",
      "val loss   : 0.221179, val predict   = 39.0%\n",
      "train loss : 0.191377, train predict = 42.6%\n",
      "\n",
      "val loss   : 0.208909, val predict   = 40.3%\n",
      "train loss : 0.174448, train predict = 46.2%\n",
      "\n",
      "val loss   : 0.206419, val predict   = 39.6%\n",
      "train loss : 0.171818, train predict = 44.4%\n",
      "\n",
      "val loss   : 0.207944, val predict   = 42.4%\n",
      "train loss : 0.163578, train predict = 48.0%\n",
      "\n",
      "val loss   : 0.190042, val predict   = 43.1%\n",
      "train loss : 0.155769, train predict = 49.0%\n",
      "\n",
      "val loss   : 0.190026, val predict   = 41.1%\n",
      "train loss : 0.155520, train predict = 49.6%\n",
      "\n",
      "interrupted by user\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    try:\n",
    "        train_batch(train_iter)\n",
    "        if i % 1000 == 0:\n",
    "            val_loss, val_predict = eval_batch(val_iter, 16)\n",
    "            train_loss, train_predict = eval_batch(train_iter, 16)\n",
    "            print \"val loss   : %f, val predict   = %.1f%%\" %(val_loss, val_predict * 100)\n",
    "            print \"train loss : %f, train predict = %.1f%%\" %(train_loss, train_predict * 100)\n",
    "            print\n",
    "            sys.stdout.flush()\n",
    "    except KeyboardInterrupt:\n",
    "        print \"interrupted by user\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examinando modelos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu atingi cerca de 41% no conjunto de validação, quando interrompi. Isso parece bem ruim. Vamos ver agora os erros cometidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_loss, output, X, Y = get_eval_batch_data(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronúncia                               correta           chute do modelo   correto?\n",
      "\n",
      "AE0-N-T-OW1-N-IY0-OW0                    antonio           antonio           True\n",
      "R-AW1-N-D-AH2-P                          roundup           roundup           True\n",
      "K-AH0-D-UW1-M-IY0                        kadumi            cadumi            False\n",
      "T-OY0-UW1                                toyoo             towee             False\n",
      "T-EH1-D-F-ER0-D                          tedford           tedford           True\n",
      "AE1-M-IH0-D-AA0-N                        amidon            amidon            True\n",
      "P-R-IH1-T-IY0-ER0                        prettier          pritier           False\n",
      "B-AO1-R-T-AH0-N                          borten            borton            False\n",
      "T-AA1-M-P-K-IH0-N-S-IH0-Z                tompkinses        tompkinces        False\n",
      "K-IH1-M-AH0-L                            kimmel            kimmel            True\n",
      "K-EH2-R-AH0-T-AO1-T-AH0-M-IY0            keratotomy        caratomity        False\n",
      "AA1-K-Y-AH0-P-AY2-ER0                    occupier          occupier          True\n",
      "K-L-IH1-N-T                              clint             klint             False\n",
      "S-IY1-N-ER0                              seanor            seaner            False\n",
      "EH1-L-F-IH0-SH                           elfish            elfish            True\n",
      "K-W-IH1-N-IY0                            quinney           quinny            False\n",
      "S-AE1-N-T-IY0                            santi             santi             True\n",
      "W-AO1-D-AH0-L                            wadle             wadle             True\n",
      "AE1-G-ER0-D                              agard             aggard            False\n",
      "B-IY0-AA0-N-CH-IY1-N-IY0                 bianchini         biancini          False\n",
      "M-AH0-K-ER1-D-IY0                        mccurdy           mccurdy           True\n",
      "M-UH1-R-M-AH0-N                          moormann          moorman           False\n",
      "B-AA1-B-S-T                              bobst             bobst             True\n",
      "S-T-R-IY1-T                              streett           street            False\n",
      "AE0-M-B-AE2-S-AH0-D-AO1-R-IY0-AH0-L      ambassadorial     ambassadiaral     False\n",
      "K-L-OW1-Z-IH0-NG                         closing           closing           True\n",
      "M-IH0-HH-AA1-L-EH0-K                     michalek          mihalek           False\n",
      "R-AA1-B-ER0-S-AH0-N                      robberson         roberson          False\n",
      "L-OW1-D-IH0-NG-Z                         loadings          lodings           False\n",
      "S-ER0-AA0-T-AO1-R-IY0                    serratore         seratori          False\n",
      "T-AE1-K-T-IH0-K                          tactic            tactic            True\n",
      "P-R-EH1-S-IY0-AH0-N-T                    prescient         preceenet         False\n",
      "S-P-AY1-K-AE2-CH-ER0                     spycatcher        spicatucher       False\n",
      "P-R-AA1-S-T-EY2-T                        prostate          prostate          True\n",
      "M-AW1-CH-ER0                             maucher           maucher           True\n",
      "M-EH1-N-S-IH0-K                          mensik            mensick           False\n",
      "L-IH1-N-D-HH-OW2-L-M                     lindholm          lindholm          True\n",
      "B-L-EY1-Z                                blaize            blays             False\n",
      "N-ER1-V-AH0-S                            nervous           nervis            False\n",
      "K-AH1-B-IH0-CH-EH0-K                     kubicek           kubezek           False\n",
      "D-AO1-S-AH0-N                            dawson            dossen            False\n",
      "B-AE1-R-AH0-S                            barrus            barrus            True\n",
      "L-AA1-N-OW0                              llano             lano              False\n",
      "S-AY1-T                                  sight             sight             True\n",
      "W-EH1-L-F-ER0-D                          welford           welford           True\n",
      "G-AA1-R-L-IH0-K                          garlic            garlick           False\n",
      "T-AH1-N-AH0-JH-AH0-Z                     tonnages          tunages           False\n",
      "P-IY0-AE1-N-OW0                          piano             piano             True\n",
      "P-AA1-M-P-AA2-N-Z                        pompons           pompons           True\n",
      "L-OW1-D-ER0-Z                            loaders           loders            False\n",
      "M-AE1-T-S-AH0                            matzoh            matza             False\n",
      "W-EH2-S-T-HH-AE1-M-P-T-AH0-N             westhampton       westamphan        False\n",
      "R-IH1-CH-ER0-D                           richerd           richard           False\n",
      "B-AA1-B-AH0-N                            bobbin            bobben            False\n",
      "P-AA2-L-IY0-V-AY1-N-AH0-L                polyvinyl         polivinal         False\n",
      "K-EY1-JH-D                               caged             caged             True\n",
      "W-AO1-R-IY0-ER0                          warrior           warrier           False\n",
      "P-AE2-T-R-AH0-N-IH1-M-IH0-K              patronymic        patronimic        False\n",
      "S-T-R-IY1-B                              strebe            streeb            False\n",
      "B-R-IH1-L-Y-AH0-N-T                      brilliant         brilliant         True\n",
      "G-AA1-R-D-Z                              guards            gards             False\n",
      "AA1-D-IH0-G-AA0-R-D                      odegaard          odigard           False\n",
      "CH-IY1-Z-IY0-ER0                         cheesier          chesier           False\n",
      "K-AW1-N-S-IH0-L-Z                        councils          counciles         False\n",
      "HH-AE1-M-AH0-L                           hammel            hammel            True\n",
      "D-IH0-T-EY1-N-IH0-NG                     detaining         detaining         True\n",
      "D-UW1-AH0-L-Z                            duels             duels             True\n",
      "F-UH0-R-IY1-N-IY0                        furini            furini            True\n",
      "AO0-R-OW0-P-EH1-Z-AH0                    oropeza           oropesa           False\n",
      "F-R-IY1-K-S                              freaks            freeks            False\n",
      "K-R-IH1-S-T-L-IY2-B                      christlieb        christlebe        False\n",
      "F-IH1-G-M-IH0-N-T-S                      figments          figments          True\n",
      "M-OW1-T-AH0-V-EY0-T-ER0                  motivator         motivater         False\n",
      "V-AH1-L-K-AH0-N-Z                        vulcans           vulkens           False\n",
      "M-EH0-L-IY1-T-OW0                        melito            melito            True\n",
      "D-ER1-W-IH0-N                            derwin            durwin            False\n",
      "AE1-M-R-EH0-P                            amrep             amrep             True\n",
      "EH1-R-AH0-G-AH0-N-S                      arrogance         aragance          False\n",
      "W-EY1-S-T                                waste             wased             False\n",
      "M-IH0-L-EH1-F-S-K-IY0                    milewski          milewski          True\n",
      "AY1-L-ER0                                isler             eiler             False\n",
      "AW1-S-T-AH0-L                            austell           oustal            False\n",
      "D-AW1-N-AH0-N                            downen            downan            False\n",
      "S-N-OW1-B-ER2-D                          snowbird          snowbird          True\n",
      "N-AE1-SH-AH0-N-AE2-L-EY0                 nationale         nationale         True\n",
      "N-AA0-Y-AA1-R                            najar             nayar             False\n",
      "G-AY1-D-P-OW2-S-T-S                      guideposts        guideposts        True\n",
      "P-R-AH0-V-EH1-R-AH0-K-EY0-T-AH0-D        prevaricated      proveracated      False\n",
      "W-UW1-P-IY0                              whoopie           whoopy            False\n",
      "SH-IY1-V-Z                               sheaves           sheves            False\n",
      "M-EH2-R-EY1-B-IY0-AH0-N                  mehrabian         marrabian         False\n",
      "S-L-AA1-P-AH0-L-IY0                      sloppily          sloppley          False\n",
      "T-AH0-N-AY1-T                            tonight           tonight           True\n",
      "L-IH2-T-AH0-G-EY1-SH-AH0-N               litigation        litigation        True\n",
      "S-AH1-M-ER0-L-IH0-N                      sumerlin          summerlin         False\n",
      "F-EH1-R-IY0-M-AH0-N                      ferryman          ferriman          False\n",
      "S-EH1-D-R-IH0-K                          cedric            sedric            False\n",
      "M-IH1-CH-AH0-L                           michell           michel            False\n",
      "L-EH1-G-IH0-T                            leget             leggett           False\n",
      "AO1-R-N-ER0                              orner             orner             True\n",
      "S-OW1-L-IH0-T-R-AA0-N                    solitron          solitron          True\n",
      "F-IH2-G-Y-ER0-EY1-SH-AH0-N               figuration        figuration        True\n",
      "S-T-OW1-L-T-S                            stoeltze          stoltz            False\n",
      "Y-UW1-OW0-L-T                            ewoldt            eulet             False\n",
      "R-IY1-Z-ER0                              reser             reaser            False\n",
      "G-L-AE1-M-ER0-AY0-Z-IH0-NG               glamorizing       glamorizing       True\n",
      "W-IH1-N-T-ER0-TH-ER0                     winterthur        winterther        False\n",
      "M-AH0-CH-IH1-Z-M-OW0                     machismo          machismo          True\n",
      "OW2-V-ER0-EH0-K-S-AY1-T-IH0-NG           overexciting      overexiting       False\n",
      "HH-AA1-R-D-SH-IH0-P                      hardship          hardship          True\n",
      "W-ER1-L-D-P-AE2-S                        worldpass         worldpass         True\n",
      "L-UH1-R-IH0-NG                           luhring           luering           False\n",
      "R-IY2-AH0-W-EY1-K-AH0-N-IH0-NG           reawakening       reawakining       False\n",
      "R-EH1-N-T-AH0-L                          rental            rentle            False\n",
      "S-AH1-CH-ER0                             sucher            sutcher           False\n",
      "ZH-IH1-R-AH0-N                           giron             jeron             False\n",
      "B-L-IH1-S-T-ER0                          blister           blister           True\n",
      "D-AH1-D-L-IY0                            dudley            dudley            True\n",
      "JH-OW2-K-AA1-R                           dzhokhar          jocahr            False\n",
      "SH-L-AA1-B-OW0-M                         schlobohm         schlobom          False\n",
      "P-IH1-NG-K-ER0-M-AH0-N                   pinkerman         pinkerman         True\n",
      "B-R-AE1-N-D                              brande            brand             False\n",
      "F-EY1-Z-D                                fazed             faised            False\n",
      "D-AY0-S-EH1-K-T                          dissect           disect            False\n",
      "S-V-EH1-N-S-K                            svensk            svensk            True\n",
      "B-EH1-R-IH0-NG-Z                         barings           berrings          False\n",
      "AY1-K-AH0-L-B-ER0-G-ER0                  eichelberger      eichelberger      True\n",
      "G-AH0-V-AA1-L-D-AH0                      gavalda           gavalda           True\n"
     ]
    }
   ],
   "source": [
    "print \"pronúncia\".ljust(40),\n",
    "print \"correta\".ljust(17),\n",
    "print \"chute do modelo\".ljust(17),\n",
    "print \"correto?\"\n",
    "print\n",
    "\n",
    "for index in range(len(output)):\n",
    "    phonemes = \"-\".join([index_to_phoneme[p] for p in X.T[index]]) \n",
    "    real = [index_to_letter[l] for l in Y.T[index]] \n",
    "    predict = [index_to_letter[l] for l in np.argmax(output, axis = 2)[index]]\n",
    "   \n",
    "    print phonemes.split(\"-_\")[0].ljust(40),\n",
    "    print \"\".join(real).split(\"_\")[0].ljust(17),\n",
    "    print \"\".join(predict).split(\"_\")[0].ljust(17),\n",
    "    print str(real == predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os erros não parecem tão terríveis assim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este curso é baseado em material da [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). Assim, segue os termos da [licença do MIT](https://bigdatauniversity.com/mit-license/). Material adicional de Aymeric Damien (ver https://github.com/aymericdamien/TensorFlow-Examples para muitos exemplos) e Mikesj (https://github.com/mikesj-public/rnn_spelling_bee/blob/master/spelling_bee_RNN.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
