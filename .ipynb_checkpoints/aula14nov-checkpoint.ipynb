{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos em autocodificadores variacionais, há possivelmente muitos códigos latentes que representam uma certa imagem. Também sabemos que há muito ruído no espaço de entrada, o que nos permite representar uma entrada por um código latente muito menor. \n",
    "\n",
    "Logo, talvez seja possível introduzir ruído em uma entrada, cuidadosamente, sem modificá-la de forma perceptível aos olhos humanos, mas modificando-a significativamente em sua representação latente (ou seja, o \"ruído\" introduzido não é de fato ruído, mas valores escolhidos cuidadosamente para não mudarem significativamente a relação entre os atributos, mas levando-os para fora das suas faixas de valores esperados). Abaixo, temos uma ilustração desta ideia, onde à imagem de um panda é adicionado ruído $\\epsilon$, de forma que a imagem resultante é vista como um gibão pela rede neural, embora pareça ainda um panda para um ser humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/adversarial_img_1.png\" alt=\"GAN\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este é naturalmente um problema, uma vez que é possível fazer redes neurais cometerem erros modificando cuidadosamente os exemplos dados. Vários estudos têm sido realizados para tornar estes modelos mais robustos a este tipo de erro. Uma estratégia, por exemplo, é treinar a rede neural com exemplos destes casos (chamados adversariais), o que nos leva à seguinte questão:\n",
    "\n",
    "Seria possível criar um modelo discriminador $D$ capaz de aprender o que faz uma imagem real ser real ao olho humando e, assim, discriminá-la de imagens falsas? \n",
    "\n",
    "Se sim, então é viável imaginar também que seria possível criar _modelos geradores de imagens falsas que, em competição com $D$, fossem capazes de criar imagens tão convincentes a ponto de $D$ não ser mais capaz de diferenciá-las de imagens verdadeiras!_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O _insight_ acima nos leva à proposição das Redes Geradoras Adversariais (GANs -- _Generated Adversarial Networks_, Goodfellow _et al_, 2014 -- https://arxiv.org/abs/1406.2661). GANs são combinações de redes neurais que treinam de forma competitiva. Mais especificamente, GANs são formadas por duas redes, uma discriminadora (_D_) e uma geradora (_G_). Sem perda de generalidade, suponha que temos uma GAN projetada para gerar imagens. A rede discriminadora _D_ desta GAN é treinada em imagens reais e imagens da rede geradora _G_ e tem por objetivo determinar _que imagens são as de G_. O objetivo de _G_, por sua vez, é gerar imagens que _D_ não consiga discernir das imagens reais. Logo, se _G_ for bem sucedida, ela gera imagens mais realistas.  \n",
    "\n",
    "Esta ideia tem sido aplicada com grande sucesso na resolução de muitas tarefas (geração de faces, ambientes, fotos; geração de imagens apartir e fotos; geração de texto apartir de exemplos de texto; geração de imagens apartir de exemplos de imagens; criação e analogias; criação de imagens/textos apartir de exemplos; obtenção de imagens de alta resolução de imagens de baixa resolução, etc), de forma a tornar modelos geradores especialmente úteis atualmente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como funcionam GANs?\n",
    "\n",
    "Para entendermos melhor, a figura abaixo ilustra uma GAN. Nesta figura, $p_{data}(x)$ é a distribuição de probabilidade real dos dados; $x$ é uma amostra tirada de $p_{data}(x)$; $p(z)$ é a distribuição de probabilidade do gerador, onde $z$ é uma amostra de $p(z)$; G(x) é a rede geradora e D(x) a discriminadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gan1.jpg\" alt=\"GAN\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede geradora $G$ gera um novo dado apartir de uma amostra aleatória $z$ obtida da distribuição de probabilidade $p(z)$. O dado gerado é fornecido como entrada para o discriminador $D(x)$. A tarefa do discriminador é distinguir entradas reais das geradas. Para isso, ele obtem uma entrada $x$ da distribuição de dados reais $p_{data}(x)$. Assim, $D(x)$ apenas tem que classificar as entradas, forncecendo uma estimativa probabilística sobre se elas são geradas ou reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento da GAN pode ser expresso como uma disputa entre $G$ e $D$, ou seja, a meta é $G$ minimizar a capacidade de discriminação que $D$ está tentando maximizar. Isto pode ser expresso com ajuda da seguinte função:\n",
    "\n",
    "$$V(G, D) = E_{x \\sim p_{data}(x)}[\\log D(x)] + E_{z \\sim p(z)}[\\log (1 - D(G(z)))]$$\n",
    "\n",
    "Na função $V$, o primeiro designa a esperança de que os dados da distribuição real $p(x)$ sejam reconhecidos como reais por D (a função usa entropias em lugar de probabilidades). O segundo termo é esperança de que os dados gerados de $p(z)$ serão identificados como falsos por D. Logo, o objetivo de $D$ é maximizar $V$ enquanto $G$ quer minimizar $V$. Ou seja, temos uma corrida armamentista entre $D$ e $G$ -- cada um vai querer se especializar nos pontos fracos do outro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando uma GAN com Keras e Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula, vamos treinar uma GAN para gerar dígitos da MNIST. Para isso, vamos ler os dígitos da MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados da MNIST serão normalizados para ficarem entre -1 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X_train = mnist.train.images\n",
    "\n",
    "# Rescale -1 to 1, 28x28\n",
    "X_train = (X_train.astype(np.float32) - 0.5) / 0.5\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções abaixo são apenas para visualizarmos melhor o andamento do treino. A função `smooth` suaviza um série de dados usando média móvel e a função `plot_images` exibe 8 imagens aleatórias dos dígitos sendo gerados pela GAN, para observamos se a rede esta evoluindo com o tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# moving average smoothing\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_imgs(epoch, generator, cols = 8):\n",
    "    noise = np.random.normal(0, 1, (cols, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    f, axes = plt.subplots(1, cols)\n",
    "    for i, a in enumerate(axes):\n",
    "        a.imshow(gen_imgs[i,:,:,0], cmap = 'gray', interpolation='nearest')\n",
    "        a.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A arquitetura da rede que vamos implementar é ilustrada na figura a seguir. A rede é composta por dois componentes, o gerador e o discriminador. A entrada do gerador são 100-D vetores aleatórios enquanto a sua saída são imagens 28x28, como as da MNIST. O componente gerador é treinado para aprender se uma imagem é real. A figura também indica que no treinamento do discriminador, ele recebe tanto imagens reais quanto geradas pelo gerador. Por sua vez, no treino do gerador, imagens reais não são usadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ganmodel0.png\" alt=\"GAN to implement\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "noise_shape = (100,)\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir temos a implementação do gerador em Keras. O ruído de entrada é dado por um 100-D vetor aleatório. Usamos leakyRelu e BatchNormalization nas camadas ocultas. A camada final usa tangente hiperbólica para gerar imagens com pixels entre -1 a 1, como as imagens reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator(noise_shape = (100,), \n",
    "                    img_shape = (28, 28, 1)):\n",
    "    gen = Sequential()\n",
    "    gen.add(Dense(256, input_shape=noise_shape))\n",
    "    gen.add(LeakyReLU(alpha=0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(512))\n",
    "    gen.add(LeakyReLU(alpha=0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(1024))\n",
    "    gen.add(LeakyReLU(alpha=0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    gen.add(Reshape(img_shape))\n",
    "    gen.summary()\n",
    "\n",
    "    gen_input = Input(shape=noise_shape)\n",
    "    gen_output = gen(gen_input)\n",
    "    return Model(gen_input, gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "\n",
    "# Build and compile the generator\n",
    "generator = build_generator(noise_shape, img_shape)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir temos a implementação do _discriminador_ em Keras. Esta é uma rede densa tradicional, sem BatchNormalization, e com LeakyRelu. A camada final usa sigmoid para gerar estimativas que funcionem como probabilidades (0 a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape = (28, 28, 1)):\n",
    "    disc = Sequential()\n",
    "    disc.add(Flatten(input_shape=img_shape))\n",
    "    disc.add(Dense(512))\n",
    "    disc.add(LeakyReLU(alpha=0.2))\n",
    "    disc.add(Dense(256))\n",
    "    disc.add(LeakyReLU(alpha=0.2))\n",
    "    disc.add(Dense(1, activation='sigmoid'))\n",
    "    disc.summary()\n",
    "\n",
    "    disc_input = Input(shape=img_shape)\n",
    "    disc_output = disc(disc_input)\n",
    "    return Model(disc_input, disc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GAN, em si, é uma combinação do gerador com o discriminador. Assim, definimos nossa rede combinada como o gerador conectado ao discriminador. Note que na rede combinada, o discriminador não é treinável. Na prática, ele será treinado em separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, chegamos ao treino. A ideia geral do treino é dada abaixo (considere $b$ o tamanho do _batch_):\n",
    "\n",
    "* Para cada época:\n",
    "    * Treine o discriminador (ou seja, apenas a rede Discriminator)\n",
    "        * Usando $b/2$ imagens do gerador rotuladas como falsas (0)\n",
    "        * Usando $b/2$ imagens reais (do batch) rotuladas como reais (1)\n",
    "    * Treine o gerador (ou seja, a rede inteira, combinada, com o Discriminator 'congelado')\n",
    "        * Usando $b/2$ imagens do gerador rotuladas como reais (1), pois o gerador G quer _enganar_ o discriminador D. O resultado desta estratégia é que se D achar que uma imagem enviada por G é real, ele foi efetivamente enganado e nada precisa mudar em G. Se, por outro lado, D achar que é falsa, então G precisa mudar sua estratégia, uma vez que D não foi enganado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que não há um critério muito claro de parada aqui. Você deve checar manualmente a qualidade dos dados gerados para ver se eles são apropriados e já é possível parar. Mas uma vez que você tem um gerador confiável e funcional, você pode replicar qualquer dígito. Em uma escala maior, você pode replicar coisas como textos de reviews, fotos, músicas... você tem uma máquina que parece efetivamente inteligente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras arquiteturas para GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas novas arquiteturas de GANs têm surgido na literatura. O site https://deephunt.in/the-gan-zoo-79597dc8c347 dá uma boa ideia da imensa diversidade de ideias nessa área. Abaixo, citamos algumas com implementações disponíveis:\n",
    "\n",
    "* __ACGAN__ -- Auxiliary Classifier Generative Adversarial Network. Paper: https://arxiv.org/abs/1610.09585. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py. \n",
    "* __Adversarial Autoencoders__. Paper: https://arxiv.org/abs/1511.05644. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/aae/adversarial_autoencoder.py.\n",
    "* __BEGAN__ -- Boundary Equilibrium Generative Adversarial Networks. Paper: https://arxiv.org/abs/1703.10717. Implementação: https://github.com/carpedm20/BEGAN-tensorflow. Vamos ver BEGANs em detalhe na próxima aula.\n",
    "* __BiGAN__ -- Bidirectional Generative Adversarial Network. Além de mapear o espaço latente $z$ para os dados, a GAN também aprende a mapear os dados de volta para o espaço latente. Ela é útil para aprendizado não- e semi-supervisionado já que mapeamento latente pode ser visto como um tipo de rotulação semântica. Paper: https://arxiv.org/abs/1605.09782. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/bigan/bigan.py.\n",
    "    <img src=\"images/bigan.png\" alt=\"exemplos BEGAN\" style=\"width: 400px;\"/>\n",
    "* __CCGAN__ -- Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks. Paper: https://arxiv.org/abs/1611.06430. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/ccgan/ccgan.py.\n",
    "* __Context Encoder__: Paper: https://arxiv.org/abs/1604.07379. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/context_encoder/context_encoder.py.\n",
    "* __DiscoGAN__: Paper: https://arxiv.org/pdf/1703.05192.pdf. Implementação: https://github.com/carpedm20/DiscoGAN-pytorch.\n",
    "* __DCGAN__ -- Deep Convolutional Generative Adversarial Network. Gerador é uma rede de convolução. Normalmente usa técnicas de upsampling e convolução transposta para inverter a direção do sinal. Paper: https://arxiv.org/abs/1511.06434. Implementação: https://github.com/Zackory/Keras-MNIST-GAN.\n",
    "* __InfoGAN__ -- Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. Paper: https://arxiv.org/abs/1606.03657. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/infogan/infogan.py.\n",
    "* __SGAN__ -- Semi-supervised Generative Adversarial Network. Paper: https://arxiv.org/abs/1606.01583. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/sgan/sgan.py.\n",
    "* __WGAN__ -- Wasserstein Generative Adversarial Network. Além de usar a distância de Wasserstein, essa GAN garante que o discriminador dê sempre gradientes úteis para o gerador (+1 se acerta real e -1, caso contrário). Paper: https://arxiv.org/abs/1701.07875. Implementação: https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan/wgan.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código baseado em Erik Lindernoren (https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py). Algumas figuras e ideias do blog de Faizan Shaikh (https://www.analyticsvidhya.com/blog/2017/06/introductory-generative-adversarial-networks-gans/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
