{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Feedforward (FNN/DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota de aula, 14 de setembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print mnist.train.num_examples\n",
    "print mnist.test.num_examples\n",
    "print mnist.validation.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwiI4gMBUXwgIIoPBPR/JYe+sOvUkxUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11433e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(1, mnist.train.num_examples)\n",
    "img = mnist.train.images[idx].reshape((28,28))\n",
    "plt.matshow(img, cmap = 'gray')\n",
    "print mnist.train.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Activation(object):\n",
    "    \"\"\"Funcao de ativacao\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def init(self, n_inputs, n_outputs):\n",
    "        'Xavier'\n",
    "        if self.name == 'sigmoid':\n",
    "            s = np.sqrt(2. / (n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        elif self.name == 'relu':\n",
    "            s = 2. / np.sqrt((n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        else:\n",
    "            return tf.random_uniform([n_inputs, n_outputs], -1.0, 1.0)\n",
    "        \n",
    "    def fire(self, ypred):\n",
    "        if self.name == 'sigmoid':\n",
    "            return tf.nn.sigmoid(ypred) \n",
    "        elif self.name == 'relu':\n",
    "            return tf.nn.relu(ypred) \n",
    "        else:\n",
    "            return ypred\n",
    "            \n",
    "class Layer(object):\n",
    "    \"\"\"Camada de rede neural sequencial\"\"\"\n",
    "    def __init__(self, units, activation = None, name = None):\n",
    "        self.units = units\n",
    "        self.name = name \n",
    "        self.activation = activation if activation != None else Activation('')\n",
    "        \n",
    "    def output(self, X):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        with tf.name_scope(self.name):\n",
    "            self.W = tf.Variable(self.activation.init(n_inputs, self.units), name = 'W')\n",
    "            self.b = tf.Variable(tf.zeros([self.units]), name = 'b')\n",
    "            ypred = self.activation.fire(tf.matmul(X, self.W) + self.b)\n",
    "        return ypred\n",
    "\n",
    "class LossFunction(object):\n",
    "    def __init__(self, name = 'sigmoid'):\n",
    "        self.name = name\n",
    "\n",
    "    def get(self, yreal, ypred):\n",
    "        if self.name == 'sigmoid':\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = yreal, logits = ypred) \n",
    "        return tf.reduce_mean(loss, name = 'lossf')\n",
    "    \n",
    "class Optimizer(object):\n",
    "    def __init__(self, name = 'sgd', lrate = 0.1):\n",
    "        self.name = name\n",
    "        self.lrate = lrate\n",
    "\n",
    "    def get(self, lossf):\n",
    "        if self.name == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(learning_rate = self.lrate) \n",
    "        return opt.minimize(lossf)\n",
    "    \n",
    "class FeedforwardNeuralNet(object):\n",
    "    \"\"\"Rede neural sequencial\"\"\"\n",
    "    def __init__(self, input_dim, lrate = 0.1):\n",
    "        self.input_dim = input_dim\n",
    "        self.lrate = lrate\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, units, activation = None, name = None):\n",
    "        \"\"\"Adiciona camadas para rede neural\"\"\"\n",
    "        self.layers += [Layer(units, activation, name)]\n",
    "    \n",
    "    def compile(self, loss = 'sigmoid', optimizer = 'sgd'):\n",
    "        \"\"\"Cria grafo da rede neural\"\"\"\n",
    "        self.X = tf.placeholder(tf.float32, \n",
    "                           shape = (None, self.input_dim), \n",
    "                           name = 'X')\n",
    "        self.y = tf.placeholder(tf.int64, shape = (None), name = 'y')\n",
    "        \n",
    "        # cria layers\n",
    "        with tf.name_scope('layers'):\n",
    "            layer_in = self.X\n",
    "            for layer in self.layers:\n",
    "                layer_out = layer.output(layer_in)\n",
    "                layer_in = layer_out\n",
    "                    \n",
    "        # loss function\n",
    "        with tf.name_scope('loss'):\n",
    "            self.lossf = LossFunction(loss).get(self.y, layer_out)\n",
    "    \n",
    "        # optimizer\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op = Optimizer(optimizer, self.lrate).get(self.lossf)\n",
    "            \n",
    "        # evalution metrics\n",
    "        with tf.name_scope('eval'):\n",
    "            correct = tf.nn.in_top_k(layer_out, self.y, 1)\n",
    "            self.acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            \n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "    def fit(self, train_data, n_epochs, batch_size, val_data = None):\n",
    "        \"\"\"Executa treino da rede neural\"\"\"\n",
    "        num_batches = train_data.num_examples // batch_size\n",
    "        with tf.Session() as s:\n",
    "            s.run(self.init_op)\n",
    "            for e in range(n_epochs):\n",
    "                tloss = 0.\n",
    "                for i in range(num_batches):\n",
    "                    X_b, y_b = train_data.next_batch(batch_size)\n",
    "                    _, loss_e = s.run([self.train_op, self.lossf], \n",
    "                                      feed_dict = {self.X: X_b, self.y: y_b})\n",
    "                    tloss += loss_e\n",
    "                acc_train = s.run(self.acc, \n",
    "                                  feed_dict = {self.X: X_b, self.y: y_b})\n",
    "                if val_data:\n",
    "                    acc_val = s.run(self.acc, \n",
    "                                    feed_dict = {self.X: val_data.images, \n",
    "                                                 self.y: val_data.labels})\n",
    "                    print '%2d loss: %.8f acct: %.3f accv: %.3f' % (e, \n",
    "                                                                    tloss/num_batches, \n",
    "                                                                    acc_train, acc_val)\n",
    "                else:\n",
    "                    print '%2d loss: %.8f acc: %.3f' % (e, tloss/num_batches, acc_train)\n",
    "            self.saver.save(s, '/tmp/model.ckpt')\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Avalia rede neural em colecao de teste\"\"\"\n",
    "        with tf.Session() as s:\n",
    "            self.saver.restore(s, '/tmp/model.ckpt')\n",
    "            acc_test = s.run(self.acc, \n",
    "                             feed_dict = {self.X: X_test, self.y: y_test})\n",
    "        return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('sigmoid'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('sigmoid'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.75213411 acct: 0.880 accv: 0.875\n",
      " 1 loss: 0.37330848 acct: 0.960 accv: 0.900\n",
      " 2 loss: 0.30337257 acct: 0.860 accv: 0.915\n",
      " 3 loss: 0.26375390 acct: 0.960 accv: 0.922\n",
      " 4 loss: 0.23598204 acct: 0.960 accv: 0.930\n",
      " 5 loss: 0.21503733 acct: 0.960 accv: 0.933\n",
      " 6 loss: 0.19778006 acct: 0.880 accv: 0.935\n",
      " 7 loss: 0.18335625 acct: 0.960 accv: 0.941\n",
      " 8 loss: 0.17090644 acct: 0.900 accv: 0.944\n",
      " 9 loss: 0.15972942 acct: 0.940 accv: 0.943\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94139999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('sigmoid'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('sigmoid'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.62858660 acct: 0.920 accv: 0.909\n",
      " 1 loss: 0.32681460 acct: 0.940 accv: 0.919\n",
      " 2 loss: 0.29023756 acct: 0.960 accv: 0.927\n",
      " 3 loss: 0.26500587 acct: 0.880 accv: 0.929\n",
      " 4 loss: 0.24366607 acct: 0.960 accv: 0.936\n",
      " 5 loss: 0.22405101 acct: 0.980 accv: 0.942\n",
      " 6 loss: 0.20560956 acct: 1.000 accv: 0.947\n",
      " 7 loss: 0.18955311 acct: 0.980 accv: 0.952\n",
      " 8 loss: 0.17470819 acct: 0.980 accv: 0.955\n",
      " 9 loss: 0.16276454 acct: 0.980 accv: 0.958\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95249999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('relu'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('relu'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.25013319 acct: 1.000 accv: 0.961\n",
      " 1 loss: 0.09850866 acct: 1.000 accv: 0.971\n",
      " 2 loss: 0.06528015 acct: 1.000 accv: 0.973\n",
      " 3 loss: 0.04335726 acct: 1.000 accv: 0.976\n",
      " 4 loss: 0.03146065 acct: 1.000 accv: 0.980\n",
      " 5 loss: 0.02178990 acct: 1.000 accv: 0.978\n",
      " 6 loss: 0.01501614 acct: 1.000 accv: 0.981\n",
      " 7 loss: 0.01073761 acct: 1.000 accv: 0.979\n",
      " 8 loss: 0.00757865 acct: 1.000 accv: 0.982\n",
      " 9 loss: 0.00511285 acct: 1.000 accv: 0.981\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota de aula, 19 de setembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valores de SELU para media 0, desvio 1\n",
    "# ver paper para detalhes\n",
    "def selu(z,\n",
    "         scale = 1.0507009873554804934193349852946,\n",
    "         alpha = 1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Activation(object):\n",
    "    \"\"\"Funcao de ativacao\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def init(self, n_inputs, n_outputs):\n",
    "        'Xavier'\n",
    "        if self.name == 'sigmoid':\n",
    "            s = np.sqrt(2. / (n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        elif self.name == 'relu':\n",
    "            s = 2. / np.sqrt((n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        elif self.name == 'selu': ##\n",
    "            s = np.sqrt(1. / n_inputs)\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        else:\n",
    "            return tf.random_uniform([n_inputs, n_outputs], -1.0, 1.0)\n",
    "        \n",
    "    def fire(self, ypred):\n",
    "        def selu(z, ##\n",
    "                 scale = 1.0507009873554804934193349852946, \n",
    "                 alpha = 1.6732632423543772848170429916717):\n",
    "            return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))\n",
    "        \n",
    "        if self.name == 'sigmoid':\n",
    "            return tf.nn.sigmoid(ypred) \n",
    "        elif self.name == 'relu':\n",
    "            return tf.nn.relu(ypred) \n",
    "        elif self.name == 'selu':\n",
    "            return selu(ypred) ## \n",
    "        else:\n",
    "            return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SNN(FeedforwardNeuralNet):\n",
    "    \"\"\"Rede neural sequencial\"\"\"\n",
    "    def __init__(self, input_dim, lrate = 0.1):\n",
    "        FeedforwardNeuralNet.__init__(self, input_dim, lrate)\n",
    "           \n",
    "    def fit(self, train_data, n_epochs, batch_size, val_data = None):\n",
    "        \"\"\"Executa treino da rede neural\"\"\"\n",
    "        # obtendo medias e desvios\n",
    "        self.means = train_data.images.mean(axis=0, keepdims=True)\n",
    "        self.stds = train_data.images.std(axis=0, keepdims=True) + 1e-10\n",
    "        \n",
    "        if val_data:\n",
    "            X_v_scaled = (val_data.images - self.means) / self.stds ##\n",
    "            \n",
    "        num_batches = train_data.num_examples // batch_size\n",
    "        with tf.Session() as s:\n",
    "            s.run(self.init_op)\n",
    "            for e in range(n_epochs):\n",
    "                tloss = 0.\n",
    "                for i in range(num_batches):\n",
    "                    X_b, y_b = train_data.next_batch(batch_size)\n",
    "                    # escalando dados\n",
    "                    X_b_scaled = (X_b - self.means) / self.stds ##\n",
    "                    _, loss_e = s.run([self.train_op, self.lossf], \n",
    "                                      feed_dict = {self.X: X_b_scaled, ##\n",
    "                                                   self.y: y_b})\n",
    "                    tloss += loss_e\n",
    "                acc_train = s.run(self.acc, \n",
    "                                  feed_dict = {self.X: X_b_scaled, ##\n",
    "                                               self.y: y_b})\n",
    "                if val_data:\n",
    "                    acc_val = s.run(self.acc, \n",
    "                                    feed_dict = {self.X: X_v_scaled, ##\n",
    "                                                 self.y: val_data.labels})\n",
    "                    print '%2d loss: %.8f acct: %.3f accv: %.3f' % (e, \n",
    "                                                                    tloss/num_batches, \n",
    "                                                                    acc_train, acc_val)\n",
    "                else:\n",
    "                    print '%2d loss: %.8f acc: %.3f' % (e, tloss/num_batches, acc_train)\n",
    "            self.saver.save(s, '/tmp/model.ckpt')\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Avalia rede neural em colecao de teste\"\"\"\n",
    "        with tf.Session() as s:\n",
    "            self.saver.restore(s, '/tmp/model.ckpt')\n",
    "            X_test_s = (X_test - self.means) / self.stds ##\n",
    "            acc_test = s.run(self.acc, \n",
    "                             feed_dict = {self.X: X_test_s, \n",
    "                                          self.y: y_test})\n",
    "        return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = SNN(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('selu'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('selu'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.84737698 acct: 1.000 accv: 0.942\n",
      " 1 loss: 0.14276210 acct: 1.000 accv: 0.963\n",
      " 2 loss: 0.08204656 acct: 1.000 accv: 0.961\n",
      " 3 loss: 0.07152986 acct: 1.000 accv: 0.974\n",
      " 4 loss: 0.03958635 acct: 1.000 accv: 0.970\n",
      " 5 loss: 0.02553944 acct: 1.000 accv: 0.971\n",
      " 6 loss: 0.01620489 acct: 1.000 accv: 0.970\n",
      " 7 loss: 0.00816851 acct: 1.000 accv: 0.972\n",
      " 8 loss: 0.00552846 acct: 1.000 accv: 0.974\n",
      " 9 loss: 0.00384758 acct: 1.000 accv: 0.972\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97469997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self, name = 'sgd', lrate = 0.1):\n",
    "        self.name = name\n",
    "        self.lrate = lrate\n",
    "\n",
    "    def get(self, lossf):\n",
    "        if self.name == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(learning_rate = self.lrate) \n",
    "        elif self.name == 'adam':\n",
    "            opt = tf.train.AdamOptimizer() \n",
    "        return opt.minimize(lossf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('relu'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('relu'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile(optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.22260752 acct: 0.980 accv: 0.961\n",
      " 1 loss: 0.09181031 acct: 0.980 accv: 0.974\n",
      " 2 loss: 0.06231435 acct: 0.960 accv: 0.975\n",
      " 3 loss: 0.04749824 acct: 0.980 accv: 0.979\n",
      " 4 loss: 0.03818032 acct: 1.000 accv: 0.978\n",
      " 5 loss: 0.03061841 acct: 0.980 accv: 0.981\n",
      " 6 loss: 0.02923365 acct: 1.000 accv: 0.974\n",
      " 7 loss: 0.02118843 acct: 1.000 accv: 0.978\n",
      " 8 loss: 0.02163228 acct: 1.000 accv: 0.979\n",
      " 9 loss: 0.01913158 acct: 1.000 accv: 0.978\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97689998"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile(self, loss = 'sigmoid', optimizer = 'sgd', \n",
    "            dropout_rate = 0.0):\n",
    "    \"\"\"Cria grafo da rede neural\"\"\"\n",
    "    self.X = tf.placeholder(tf.float32, \n",
    "                       shape = (None, self.input_dim), \n",
    "                       name = 'X')\n",
    "    self.y = tf.placeholder(tf.int64, shape = (None), name = 'y')\n",
    "    ## dropout\n",
    "    self.training = tf.placeholder_with_default(False, shape = (),\n",
    "                                                name = 'training')\n",
    "\n",
    "    # cria layers\n",
    "    with tf.name_scope('layers'):\n",
    "        if dropout_rate == 0.0:\n",
    "            layer_in = self.X\n",
    "        else:\n",
    "            layer_in = tf.layers.dropout(self.X, dropout_rate, \n",
    "                                         self.training)\n",
    "        for layer in self.layers:\n",
    "            if dropout_rate == 0.0:\n",
    "                layer_out = layer.output(layer_in)\n",
    "            else:\n",
    "                layer_out = tf.layers.dropout(layer.output(layer_in), \n",
    "                                              dropout_rate, self.training)\n",
    "            layer_in = layer_out\n",
    "\n",
    "    # loss function\n",
    "    with tf.name_scope('loss'):\n",
    "        self.lossf = LossFunction(loss).get(self.y, layer_out)\n",
    "\n",
    "    # optimizer\n",
    "    with tf.name_scope('train'):\n",
    "        self.train_op = Optimizer(optimizer, self.lrate).get(self.lossf)\n",
    "\n",
    "    # evalution metrics\n",
    "    with tf.name_scope('eval'):\n",
    "        correct = tf.nn.in_top_k(layer_out, self.y, 1)\n",
    "        self.acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    self.init_op = tf.global_variables_initializer()\n",
    "    self.saver = tf.train.Saver()\n",
    "\n",
    "def fit(self, train_data, n_epochs, batch_size, val_data = None):\n",
    "    \"\"\"Executa treino da rede neural\"\"\"\n",
    "    num_batches = train_data.num_examples // batch_size\n",
    "    with tf.Session() as s:\n",
    "        s.run(self.init_op)\n",
    "        for e in range(n_epochs):\n",
    "            tloss = 0.\n",
    "            for i in range(num_batches):\n",
    "                X_b, y_b = train_data.next_batch(batch_size)\n",
    "                _, loss_e = s.run([self.train_op, self.lossf], \n",
    "                                  feed_dict = {self.X: X_b, \n",
    "                                               self.y: y_b,\n",
    "                                               self.training: True})\n",
    "                tloss += loss_e\n",
    "            acc_train = s.run(self.acc, \n",
    "                              feed_dict = {self.X: X_b, self.y: y_b})\n",
    "            if val_data:\n",
    "                acc_val = s.run(self.acc, \n",
    "                                feed_dict = {self.X: val_data.images, \n",
    "                                             self.y: val_data.labels})\n",
    "                print '%2d loss: %.8f acct: %.3f accv: %.3f' % (e, \n",
    "                                                                tloss/num_batches, \n",
    "                                                                acc_train, acc_val)\n",
    "            else:\n",
    "                print '%2d loss: %.8f acc: %.3f' % (e, tloss/num_batches, acc_train)\n",
    "        self.saver.save(s, '/tmp/model.ckpt')\n",
    "    \n",
    "FeedforwardNeuralNet.fit = fit\n",
    "FeedforwardNeuralNet.compile = compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('relu'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('relu'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile(optimizer = 'adam', dropout_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.21772785 acct: 0.960 accv: 0.970\n",
      " 1 loss: 0.09097756 acct: 1.000 accv: 0.975\n",
      " 2 loss: 0.06324646 acct: 0.980 accv: 0.977\n",
      " 3 loss: 0.05019373 acct: 1.000 accv: 0.979\n",
      " 4 loss: 0.03827936 acct: 1.000 accv: 0.978\n",
      " 5 loss: 0.03419658 acct: 1.000 accv: 0.976\n",
      " 6 loss: 0.02871753 acct: 1.000 accv: 0.976\n",
      " 7 loss: 0.02164480 acct: 1.000 accv: 0.977\n",
      " 8 loss: 0.02378546 acct: 1.000 accv: 0.980\n",
      " 9 loss: 0.01958281 acct: 1.000 accv: 0.982\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97820002"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notas de aula 21 de setembro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 250, input_dim = 28*28, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s - loss: 0.3204 - acc: 0.9101 - val_loss: 0.1623 - val_acc: 0.9586\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s - loss: 0.1405 - acc: 0.9590 - val_loss: 0.1127 - val_acc: 0.9680\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 3s - loss: 0.0964 - acc: 0.9718 - val_loss: 0.1016 - val_acc: 0.9708\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 3s - loss: 0.0731 - acc: 0.9789 - val_loss: 0.0884 - val_acc: 0.9730\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 3s - loss: 0.0563 - acc: 0.9839 - val_loss: 0.0828 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": [
    "trmodel = model.fit(mnist.train.images,  # X_train\n",
    "                    mnist.train.labels,  # y_train\n",
    "                    epochs = 5,        \n",
    "                    batch_size = 128,\n",
    "                    validation_data = (mnist.validation.images, # X_val\n",
    "                                       mnist.validation.labels)  # y_val\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes de Convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import skimage.measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed = 42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def plot_figs(lst):\n",
    "    if len(lst) == 1:\n",
    "        plt.matshow(lst[0], cmap = 'gray', interpolation = 'nearest')\n",
    "    else:\n",
    "        f, axes = plt.subplots(1, len(lst))\n",
    "        for i, a in enumerate(axes):\n",
    "            a.matshow(lst[i], cmap = 'gray', interpolation = 'nearest')\n",
    "            a.set(aspect = 'equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convoluções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex0 = np.array([[0,0,0,1,0,0,0,0],\n",
    "                [0,0,1,0,0,0,0,0],\n",
    "                [0,1,0,0,0,0,0,0],\n",
    "                [1,0,0,0,0,0,0,0],\n",
    "                [0,0,0,0,1,0,0,0],\n",
    "                [0,0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,0,0,1]])\n",
    "ex1 = np.array([[0,0,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,1,0,0,0],\n",
    "                [0,0,0,0,1,0,0,0]])\n",
    "k0 = np.array([[0,0,0,1],\n",
    "               [0,0,1,0],\n",
    "               [0,1,0,0],\n",
    "               [1,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAB+CAYAAAD4FtBqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a59850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figs([ex0, ex1, k0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv0(a1, a2):\n",
    "    sigmoid = lambda n: 1. / (1 + np.exp(-n))\n",
    "    a1r = a1.reshape((-1, 1))\n",
    "    a2r = a2.reshape((-1, 1))\n",
    "    return sigmoid(np.sum(np.multiply(a1r, a2r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98201379003790845"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAC0CAYAAABIZe24AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzgADKWeAgf4HmkLCX8Rey4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190c61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figs([ex0[:4, :4], k0])\n",
    "conv0(ex0[:4,:4], k0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
