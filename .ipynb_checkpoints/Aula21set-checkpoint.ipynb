{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Feedforward (FNN/DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota de aula, 14 de setembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcocristo/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print mnist.train.num_examples\n",
    "print mnist.test.num_examples\n",
    "print mnist.validation.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAQfCOj/So6zS3DdfcgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d59050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(1, mnist.train.num_examples)\n",
    "img = mnist.train.images[idx].reshape((28,28))\n",
    "plt.matshow(img, cmap = 'gray')\n",
    "print mnist.train.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Activation(object):\n",
    "    \"\"\"Funcao de ativacao\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def init(self, n_inputs, n_outputs):\n",
    "        'Xavier'\n",
    "        if self.name == 'sigmoid':\n",
    "            s = np.sqrt(2. / (n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        elif self.name == 'relu':\n",
    "            s = 2. / np.sqrt((n_inputs + n_outputs))\n",
    "            return tf.truncated_normal((n_inputs, n_outputs), \n",
    "                                       stddev = s)\n",
    "        else:\n",
    "            return tf.random_uniform([n_inputs, n_outputs], -1.0, 1.0)\n",
    "        \n",
    "    def fire(self, ypred):\n",
    "        if self.name == 'sigmoid':\n",
    "            return tf.nn.sigmoid(ypred) \n",
    "        elif self.name == 'relu':\n",
    "            return tf.nn.relu(ypred) \n",
    "        else:\n",
    "            return ypred\n",
    "            \n",
    "class Layer(object):\n",
    "    \"\"\"Camada de rede neural sequencial\"\"\"\n",
    "    def __init__(self, units, activation = None, name = None):\n",
    "        self.units = units\n",
    "        self.name = name \n",
    "        self.activation = activation if activation != None else Activation('')\n",
    "        \n",
    "    def output(self, X):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        with tf.name_scope(self.name):\n",
    "            self.W = tf.Variable(self.activation.init(n_inputs, self.units), name = 'W')\n",
    "            self.b = tf.Variable(tf.zeros([self.units]), name = 'b')\n",
    "            ypred = self.activation.fire(tf.matmul(X, self.W) + self.b)\n",
    "        return ypred\n",
    "\n",
    "class LossFunction(object):\n",
    "    def __init__(self, name = 'sigmoid'):\n",
    "        self.name = name\n",
    "\n",
    "    def get(self, yreal, ypred):\n",
    "        if self.name == 'sigmoid':\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = yreal, logits = ypred) \n",
    "        return tf.reduce_mean(loss, name = 'lossf')\n",
    "    \n",
    "class Optimizer(object):\n",
    "    def __init__(self, name = 'sgd', lrate = 0.1):\n",
    "        self.name = name\n",
    "        self.lrate = lrate\n",
    "\n",
    "    def get(self, lossf):\n",
    "        if self.name == 'sgd':\n",
    "            opt = tf.train.GradientDescentOptimizer(learning_rate = self.lrate) \n",
    "        return opt.minimize(lossf)\n",
    "    \n",
    "class FeedforwardNeuralNet(object):\n",
    "    \"\"\"Rede neural sequencial\"\"\"\n",
    "    def __init__(self, input_dim, lrate = 0.1):\n",
    "        self.input_dim = input_dim\n",
    "        self.lrate = lrate\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, units, activation = None, name = None):\n",
    "        \"\"\"Adiciona camadas para rede neural\"\"\"\n",
    "        self.layers += [Layer(units, activation, name)]\n",
    "    \n",
    "    def compile(self, loss = 'sigmoid', optimizer = 'sgd'):\n",
    "        \"\"\"Cria grafo da rede neural\"\"\"\n",
    "        self.X = tf.placeholder(tf.float32, \n",
    "                           shape = (None, self.input_dim), \n",
    "                           name = 'X')\n",
    "        self.y = tf.placeholder(tf.int64, shape = (None), name = 'y')\n",
    "        \n",
    "        # cria layers\n",
    "        with tf.name_scope('layers'):\n",
    "            layer_in = self.X\n",
    "            for layer in self.layers:\n",
    "                layer_out = layer.output(layer_in)\n",
    "                layer_in = layer_out\n",
    "                    \n",
    "        # loss function\n",
    "        with tf.name_scope('loss'):\n",
    "            self.lossf = LossFunction(loss).get(self.y, layer_out)\n",
    "    \n",
    "        # optimizer\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op = Optimizer(optimizer, self.lrate).get(self.lossf)\n",
    "            \n",
    "        # evalution metrics\n",
    "        with tf.name_scope('eval'):\n",
    "            correct = tf.nn.in_top_k(layer_out, self.y, 1)\n",
    "            self.acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            \n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "    def fit(self, train_data, n_epochs, batch_size, val_data = None):\n",
    "        \"\"\"Executa treino da rede neural\"\"\"\n",
    "        num_batches = train_data.num_examples // batch_size\n",
    "        with tf.Session() as s:\n",
    "            s.run(self.init_op)\n",
    "            for e in range(n_epochs):\n",
    "                tloss = 0.\n",
    "                for i in range(num_batches):\n",
    "                    X_b, y_b = train_data.next_batch(batch_size)\n",
    "                    _, loss_e = s.run([self.train_op, self.lossf], \n",
    "                                      feed_dict = {self.X: X_b, self.y: y_b})\n",
    "                    tloss += loss_e\n",
    "                acc_train = s.run(self.acc, \n",
    "                                  feed_dict = {self.X: X_b, self.y: y_b})\n",
    "                if val_data:\n",
    "                    acc_val = s.run(self.acc, \n",
    "                                    feed_dict = {self.X: val_data.images, \n",
    "                                                 self.y: val_data.labels})\n",
    "                    print '%2d loss: %.8f acct: %.3f accv: %.3f' % (e, \n",
    "                                                                    tloss/num_batches, \n",
    "                                                                    acc_train, acc_val)\n",
    "                else:\n",
    "                    print '%2d loss: %.8f acc: %.3f' % (e, tloss/num_batches, acc_train)\n",
    "            self.saver.save(s, '/tmp/model.ckpt')\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Avalia rede neural em colecao de teste\"\"\"\n",
    "        with tf.Session() as s:\n",
    "            self.saver.restore(s, '/tmp/model.ckpt')\n",
    "            acc_test = s.run(self.acc, \n",
    "                             feed_dict = {self.X: X_test, self.y: y_test})\n",
    "        return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('sigmoid'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('sigmoid'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.75213411 acct: 0.880 accv: 0.875\n",
      " 1 loss: 0.37330848 acct: 0.960 accv: 0.900\n",
      " 2 loss: 0.30337257 acct: 0.860 accv: 0.915\n",
      " 3 loss: 0.26375390 acct: 0.960 accv: 0.922\n",
      " 4 loss: 0.23598204 acct: 0.960 accv: 0.930\n",
      " 5 loss: 0.21503733 acct: 0.960 accv: 0.933\n",
      " 6 loss: 0.19778006 acct: 0.880 accv: 0.935\n",
      " 7 loss: 0.18335625 acct: 0.960 accv: 0.941\n",
      " 8 loss: 0.17090644 acct: 0.900 accv: 0.944\n",
      " 9 loss: 0.15972942 acct: 0.940 accv: 0.943\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94139999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('sigmoid'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('sigmoid'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.62858660 acct: 0.920 accv: 0.909\n",
      " 1 loss: 0.32681460 acct: 0.940 accv: 0.919\n",
      " 2 loss: 0.29023756 acct: 0.960 accv: 0.927\n",
      " 3 loss: 0.26500587 acct: 0.880 accv: 0.929\n",
      " 4 loss: 0.24366607 acct: 0.960 accv: 0.936\n",
      " 5 loss: 0.22405101 acct: 0.980 accv: 0.942\n",
      " 6 loss: 0.20560956 acct: 1.000 accv: 0.947\n",
      " 7 loss: 0.18955311 acct: 0.980 accv: 0.952\n",
      " 8 loss: 0.17470819 acct: 0.980 accv: 0.955\n",
      " 9 loss: 0.16276454 acct: 0.980 accv: 0.958\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95249999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = FeedforwardNeuralNet(28 * 28)\n",
    "\n",
    "model.add(units = 300, activation = Activation('relu'), name = 'h1')\n",
    "model.add(units = 100, activation = Activation('relu'), name = 'h2')\n",
    "model.add(units = 10, name = 'out')\n",
    "\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 loss: 0.25013319 acct: 1.000 accv: 0.961\n",
      " 1 loss: 0.09850866 acct: 1.000 accv: 0.971\n",
      " 2 loss: 0.06528015 acct: 1.000 accv: 0.973\n",
      " 3 loss: 0.04335726 acct: 1.000 accv: 0.976\n",
      " 4 loss: 0.03146065 acct: 1.000 accv: 0.980\n",
      " 5 loss: 0.02178990 acct: 1.000 accv: 0.978\n",
      " 6 loss: 0.01501614 acct: 1.000 accv: 0.981\n",
      " 7 loss: 0.01073761 acct: 1.000 accv: 0.979\n",
      " 8 loss: 0.00757865 acct: 1.000 accv: 0.982\n",
      " 9 loss: 0.00511285 acct: 1.000 accv: 0.981\n"
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train, n_epochs = 10, \n",
    "          batch_size = 50, val_data = mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota de aula, 19 de setembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valores de SELU para media 0, desvio 1\n",
    "# ver paper para detalhes\n",
    "def selu(z,\n",
    "         scale = 1.0507009873554804934193349852946,\n",
    "         alpha = 1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
