{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocodificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_figs(lst, figsize = 12):\n",
    "    f, axes = plt.subplots(1, len(lst), figsize = (figsize, figsize*len(lst)))\n",
    "    for i, a in enumerate(axes):\n",
    "        a.matshow(lst[i], cmap = 'gray', interpolation='nearest')\n",
    "        a.set(aspect='equal')\n",
    "        a.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes auto-codificadoras são aquelas que procuram reproduzir sua entrada na saída. Em geral, elas são formadas por duas redes simétricas, o codificador e o decodificador. A ideia do treino é reduzir o erro de reconstrução. Ou seja, a saída do decodificador deve ser o mais parecido possível com a entrada do codificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/stacked-autoencoder.png\" alt=\"Stacked AEnc\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o critério de otimização por minimizar o erro de reconstrução dispensa a necessidade de supervisão (uma vez que o erro é estimado diretamente da comparação da entrada com a saída). Logo, estes métodos são _não supervisionados_. Estas redes são capazes de aprender códigos baseados em atributos que representam bem a coleção completa dos dados. Ao aprenderem boas representações baseadas no que foi visto na coleção, são adequadas para encontrar anomalias (qualquer entrada que ela não consegue reproduzir bem, depois de treinada, é possívelmente anômala).\n",
    "\n",
    "Estas redes são historicamente importantes em _deep learning_ ao tornaram possível o treino das primeiras redes profundas na segunda metade dos anos 2000. As redes treinadas de forma não supervisionada eram usadas então como ponto inicial de redes profundas, na técnica conhecida como _pré-treino_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores empilhados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede descrita na introdução é chamada autocodificador empilhado, pelo fato de aprender representações sob pilhas de camadas. A seguir, vamos implementar um autocodificador empilhado em tensorflow, para codificar a MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede que vamos implementar tem a seguinte arquitetura:\n",
    "\n",
    "<img src=\"images/stacked-autoencoder.png\" alt=\"Stacked AEnc\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruindo entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de avaliar a qualidade do nosso auto-codificador, é usá-lo para reconstruir a entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def show_reconstructed_digits(X_test, outputs, \n",
    "                              model_path = None):\n",
    "    n_test_digits = len(X_test)\n",
    "    with tf.Session() as s:\n",
    "        if model_path:\n",
    "            saver.restore(s, model_path)\n",
    "        X_recons = outputs.eval(feed_dict={X: X_test})\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n",
    "    for i in range(n_test_digits):\n",
    "        plt.subplot(n_test_digits, 2, i * 2 + 1)\n",
    "        plot_image(X_test[i])\n",
    "        plt.subplot(n_test_digits, 2, i * 2 + 2)\n",
    "        plot_image(X_recons[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando casos anômalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma aplicação interessante é a checagem de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('images/warrior.png') \n",
    "image = np.asarray(im) \n",
    "image_grayscale = image.mean(axis=2).astype(np.float32)\n",
    "image_grayscale /= 255. # normalize between 0 and 1\n",
    "plt.imshow(image_grayscale, cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_recloss(recloss, figs):\n",
    "    fig = plt.figure()\n",
    "    axplot = plt.barh(range(len(figs)), rec_loss, align='center')\n",
    "    for k in range(len(figs)):\n",
    "        aximg = fig.add_axes([0.01, 0.185 + 0.111*k, 0.10, 0.10])\n",
    "        aximg.imshow(figs[k], cmap = 'gray', interpolation='nearest')\n",
    "        aximg.set_xticks([])\n",
    "        aximg.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando espaço latente (o espaço de emdeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ploting coded test images using TSNE\n",
    "from time import time\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import manifold\n",
    "\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, y, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "# t-SNE embedding of the digits dataset\n",
    "def plot_tsne(XX, yy):\n",
    "    print(\"Computing t-SNE embedding\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    t0 = time()\n",
    "    X_tsne = tsne.fit_transform(XX)\n",
    "    plot_embedding(X_tsne, yy,\n",
    "                   \"t-SNE %d embedding of the %d-D digits (time %.2fs)\" %\n",
    "                   (XX.shape[0], XX.shape[1], time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores empilhados com pesos transpostos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira de simplificar o modelo é garantindo que os pesos que serão aprendidos em camadas simétricas são os mesmos (transpostos). Isso é possível se a rede for perfeitamente simétrica. Neste caso, há menos parâmetros para aprender e, portanto, menos problemas com _overfitting_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_h1 = 300\n",
    "n_h2 = 150  # codings\n",
    "n_h3 = n_h1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_h1])\n",
    "weights2_init = initializer([n_h1, n_h2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "# transposed weights (tied!)\n",
    "weights3 = tf.transpose(weights2, name=\"weights3\")  \n",
    "weights4 = tf.transpose(weights1, name=\"weights4\")  \n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_h1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_h2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_h3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "h1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "h2 = activation(tf.matmul(h1, weights2) + biases2)\n",
    "h3 = activation(tf.matmul(h2, weights3) + biases3)\n",
    "outputs = tf.matmul(h3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss = reconstruction_loss + reg_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            s.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(e), \"MSE tr:\", loss_train)\n",
    "        saver.save(s, \"/tmp/my_model_tying_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores empilhados treinados camada-a-camada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes auto-codificadoras com várias camadas podem ser treinadas camada-a-camada. A figura abaixo (do artigo \"Deep networks for motor control functions\") ilustra a construção de auto-codificador usando esta estratégia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/stacked-auto-encoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura, observamos que a rede é primeiro treinada para prever o código $V$ que possibilita mapear $Y$ para $\\hat{Y}$. Uma vez que a saída do decodificador ($\\hat{Y}$) aproxima a entrada do codificador, a camada de código é então usada como entrada de um novo codificador ($V$) que gera um código $W$ com o intuito de prever $\\hat{V}$. Ao fazer isso múltiplas vezes, se obtem uma rede como a terceira ilustrada na figura (A) com camadas $Y$, $V$, $W$ e código $Z$. As metades da rede final  podem ser usadas como codificadoras ou decodificadoras (rede B). \n",
    "\n",
    "Abaixo, vamos usar esta estratégia de construção no tensorflow, usando múltiplos grafos. Note que a função `train_autoencoder` treina um autocodificador raso de uma única camada escondida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def train_autoencoder(X_train, n_neurons, n_epochs, batch_size,\n",
    "                      learning_rate = 0.01, l2_reg = 0.0005,\n",
    "                      activation=tf.nn.elu, seed=42):\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        tf.set_random_seed(seed)\n",
    "\n",
    "        n_inputs = X_train.shape[1]\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "        \n",
    "        my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            activation=activation,\n",
    "            kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n",
    "            kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_reg))\n",
    "\n",
    "        hidden = my_dense_layer(X, n_neurons, name=\"hidden\")\n",
    "        outputs = my_dense_layer(hidden, n_inputs, activation=None, name=\"outputs\")\n",
    "\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "\n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session(graph=g) as s:\n",
    "        init.run()\n",
    "        for e in range(n_epochs):\n",
    "            n_batches = len(X_train) // batch_size\n",
    "            for i in range(n_batches):\n",
    "                print(\"\\r{}%\".format(100 * i // n_batches), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                indices = rnd.permutation(len(X_train))[:batch_size]\n",
    "                X_batch = X_train[indices]\n",
    "                s.run(training_op, feed_dict={X: X_batch})\n",
    "            loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "            print(\"\\r{}\".format(e), \"MSE tr:\", loss_train)\n",
    "        params = dict([(var.name, var.eval()) \n",
    "                       for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])\n",
    "        hidden_val = hidden.eval(feed_dict={X: X_train})\n",
    "        return (hidden_val, \n",
    "                params[\"hidden/kernel:0\"], \n",
    "                params[\"hidden/bias:0\"], \n",
    "                params[\"outputs/kernel:0\"], \n",
    "                params[\"outputs/bias:0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar 2 auto-codificadores: o 1o será treinado nos dados de treino e o 2o na saída da camada escondida do 1o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores empilhados robustos a ruído (Stacked denoising auto-encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que fizemos com CNNs, podemos melhorar a robustez do nosso modelo, fornecendo entradas com ruído. Desta forma, o codificador deve aprender padrões independente do ruído no sinal de entrada. Estes modelos são conhecidos como _stacked denoising autoencoders_.\n",
    "\n",
    "Para implementá-los em TF, temos duas opções comuns: (1) introduzir erro gaussiano na entrada; (2) fazer _droput_ na entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDAe com erro Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_h1 = 300\n",
    "n_h2 = 150  # codings\n",
    "n_h3 = n_h1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for i in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * i // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            s.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(e), \"MSE tr:\", loss_train)\n",
    "        saver.save(s, \"/tmp/my_model_stacked_denoising_gaussian.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDAe com Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_h1 = 300\n",
    "n_h2 = 150  # codings\n",
    "n_h3 = n_h1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for i in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * i // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            s.run(training_op, feed_dict={X: X_batch, training: True})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(e), \"MSE tr:\", loss_train)\n",
    "        saver.save(s, \"/tmp/my_model_stacked_denoising_dropout.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores esparsos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma de melhorar a representação de um auto-codificador é aumentando a esparsidade do modelo. A ideia é que se a rede puder usar apenas um pequeno número de unidades por vez, ela acaba por induzir estas unidades a observarem padrões mais significativos, ou seja, constituirem atributos mais representativos dos dados na coleção.\n",
    "\n",
    "Como vimos antes, uma forma de induzir esparsidade é usar a norma $L_1$. Uma alternativa é usar a divergência de Kullback-Leibler ($D_{KL}$). Uma razão para optar pela $D_{KL}$ é que ela fornece gradientes maiores. A ideia em usá-la é medir a divergência entre a probabilidade de esparsidade desejada $p$ (ou seja, a probabilidade de ativação dos neurônios) e a probabilidade $q$ de ativações observadas (estimada pela média de ativações reais durante o _batch_, que não pode ser tão pequeno, para que as estimativas sejam confiáveis). Isto pode ser calculado como:\n",
    "\n",
    "$$D_{KL}(p || q) = p \\log \\frac{p}{q} + (1 − p) \\log \\frac{1 − p}{1- q}$$\n",
    "\n",
    "A perda $D_{KL}$ é então agregada para todos os neurônios e adicionada à perda de reconstrução. A perda $D_{KL}$ ainda é ponderada por um coeficiente de regularização, como visto a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_h1 = 1000  # sparse codings\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DKL(p, q):\n",
    "    # Kullback Leibler divergence\n",
    "    return p * tf.log(p / q) + (1 - p) * tf.log((1 - p) / (1 - q))\n",
    "\n",
    "learning_rate = 0.01\n",
    "sparsity_target = 0.1 # how much sparsity is disirable?\n",
    "sparsity_weight = 0.2 # regularization coefficient\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])            \n",
    "\n",
    "h1 = tf.layers.dense(X, n_h1, activation=tf.nn.sigmoid) # sigmoid to output probs\n",
    "outputs = tf.layers.dense(h1, n_outputs)                   \n",
    "\n",
    "h1_mean = tf.reduce_mean(h1, axis=0) # batch mean activation\n",
    "sparsity_loss = tf.reduce_sum(DKL(sparsity_target, h1_mean))\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE\n",
    "loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100 # use 100\n",
    "batch_size = 1000 # large to ensure reliable estimates\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for i in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * i // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            s.run(training_op, feed_dict={X: X_batch})\n",
    "        (reconstruction_loss_val, \n",
    "         sparsity_loss_val, \n",
    "         loss_val) = s.run([reconstruction_loss, sparsity_loss, loss], \n",
    "                           feed_dict={X: X_batch})\n",
    "        print(\" %2d MSE tr: %.5f LOSSES sparsity: %.5f total: %.5f\" %\n",
    "             (e, reconstruction_loss_val, sparsity_loss_val, loss_val))\n",
    "        saver.save(s, \"/tmp/my_model_sparse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aucodificadores Variacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos estudar uma nova classe de auto-codificadores, os Variacionais (VAE). Ao do contrário dos que vimos até agora, os VAE são **probabilísticos** (ou seja, seus códigos são determinados por aleatoriedade mesmo depois de treinados) e **geradores** (ou seja, podem criar _novas_ instâncias _similares_ às vistas durante o treino)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para compreendermos esse autocodificador vamos supor que existe um espaço latente $z$, de dimensão menor que o espaço de entradas $x$, capaz de representar o espaço $x$ com o mínimo de informação redundante. Seja $p(z)$ a distribuição anterior (_prior_) do espaço latente $z$, ou seja, nosso conhecimento prévio sobre $z$ (que em nosso caso é assumir $z$ como uma variável com distribuição Gaussiana). A figura abaixo ilustra a ideia deste autocodificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vaegaussian.png\" alt=\"Variational Autoencoder\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nele, o codificador (uma rede neural com pesos e bias $\\phi$) mapeia entradas $x$ para a distribuição posterior $q_\\phi(z|x)$ sobre o espaço latente $z$ (note que a dimensão de $z$ é muito menor que a de $x$ e $q_\\phi(z|x)$ é uma aproximação Gaussiana de $p(z|x)$). Ou seja, as saídas do decodificador são os parâmetros da distribuição $q_\\phi(z|x)$ e, portanto, $z$ é um espaço estocástico. Como esta distribuição é gaussiana, seus parâmetros são as médias e desvios dos eixos do espaço $z$. \n",
    "\n",
    "O decodificador é uma rede neural com pesos e bias $\\theta$. Dados os parâmetros da distribuição $q_\\phi(z|x)$, ele pode amostrar uma instância particular de $z$, para então obter uma reconstrução $\\tilde{x}$ da entrada $x$, usando a distribuição posterior $p_\\theta(x|z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente, este processo perde informação, uma vez que o decodificador tem que obter uma amostra de um espaço de maior dimensionalidade usando uma distribuição baseada em um espaço latente de menor dimensionalidade. _Mas quanta informação ele perde??_ Uma forma de medir isso é calcular o log-likelihood $\\log p_\\phi (x|z)$. Isto nos dá uma medida de quão bem o decodificador aprendeu a reconstruir uma imagem $x$ da sua representação latente $z$. Além disso, como $q_\\phi(z|x)$ é uma aproximação da distribuição real $p(z)$, o ideal é que o modelo tanto reconstrua bem a entrada quanto faça isso com uma distribuição que aproxime o melhor possível $p(z)$. Dada a entrada $x_i$, isso se traduz na seguinte função de perda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ell_i(\\theta, \\phi) = - E_{z\\sim q_\\theta(z\\vert x_i)}[\\log p_\\phi(x_i\\vert z)] + D_{KL}(q_\\theta(z\\vert x_i) \\vert\\vert p(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onde o primeiro componente corresponde à capacidade de reconstruir corretamente a entrada (ou seja, o quão bem o decodificador obtem a entrada $x_i$, dado $z$ -- note que, embora assustador em príncipio, esse termo correspondeà entropia cruzada) e o segundo componente corresponde à diferença entre as distribuições $q_{\\theta}$ e $p$, estimada pela divergência de Kullback-Leibler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema com o VAE é que o treinamento com gradiente descendente requer que o modelo seja diferenciável com respeito aos parâmetros aprendidos, o que pressupõem que o modelo é determinístico -- uma entrada particular gera o mesmo código, dado um conjunto fixado de parâmetros. Se introduzirmos nós que fazem amostragem, o modelo se torna estocástico. Assim, a amostragem é feita por incorporar aos parâmtros do modelo um erro aleatório como entrada. Isso é chamado de _truque da reparametrização_: o modelo estima médias e desvios e, para gerar uma instância aleatória, o decodificador introduz um erro Gaussiano aleatório. Abaixo temos outra ilustração que mostra isso no VAE (do livro _Handson Machine Learning with Scikit-Learn and Tensorflow_). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vae.png\" alt=\"Variational Autoencoder\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, temos um autocodificador com duas camadas ocultas (vermelha e azul). A camada 2, contudo, não produz diretamente o código, mas sim a média $\\mu$ e um desvio $\\sigma$ do espaço latente $z$ (o espaço de codificação). Os códigos que serão usados devem ser _amostrados_ da distribuíção Gaussiana $\\mathcal{N}(\\mu, \\sigma)$. Para isso basta introduzir um erro Guassiano no desvio.\n",
    "\n",
    "O restante da rede é um decodificador como os que vimos antes. A ideia geral do processo é ilustrada na direita. De uma instância de treino no espaço de entrada, é derivado uma distribuição de códigos no espaço de códigos. Desta distribuição é amostrado um código (note que o ponto amostrado não corresponde ao centro da superfície Gaussiana, pois é uma amostra) que possibilita a reconstrução aproximada da saída. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for i in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * i // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            s.run(training_op, feed_dict={X: X_batch})\n",
    "        (loss_val, \n",
    "         reconstruction_loss_val, \n",
    "         latent_loss_val) = s.run([loss, reconstruction_loss, latent_loss], \n",
    "                                  feed_dict={X: X_batch})\n",
    "        print(\" %2d LOSSES train: %.5f reconstruction: %.5f latent: %.5f\" %\n",
    "             (e, loss_val, reconstruction_loss_val, latent_loss_val))\n",
    "        saver.save(s, \"/tmp/my_model_variational.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que VAE não está preso a uma distribuição Gaussiana. De fato, diferentes distribuições podem ser melhores. A grande vantagem da interpretação aleatória do espaço de código (espaço latente) é que ela possibilita a geração de _novos_ casos. Isso permite uma nova classe de modelos e problemas: aqueles em que queremos _gerar_ instâncias a partir de exemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando VAE para gerar dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_digits = 60\n",
    "\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/my_model_variational.ckpt\")\n",
    "    # random codes!\n",
    "    codings_rnd = np.random.normal(size=[n_digits, n_h3])\n",
    "    # decodings\n",
    "    outputs_val = outputs.eval(feed_dict={h3: codings_rnd})\n",
    "\n",
    "plt.figure(figsize=(8,50)) \n",
    "for i in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, i + 1)\n",
    "    plot_image(outputs_val[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando VAE para reconstruir dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding \n",
    "n_digits = 3\n",
    "batch_size = 150\n",
    "X_test, y_test = mnist.test.next_batch(batch_size)\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/my_model_variational.ckpt\")\n",
    "    codings_val = h3.eval(feed_dict={X: X_test})\n",
    "    \n",
    "# decoding\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/my_model_variational.ckpt\")\n",
    "    outputs_val = outputs.eval(feed_dict={h3: codings_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 2.5 * n_digits))\n",
    "for i in range(n_digits):\n",
    "    plt.subplot(n_digits, 2, 1 + 2 * i)\n",
    "    plot_image(X_test[i])\n",
    "    plt.subplot(n_digits, 2, 2 + 2 * i)\n",
    "    plot_image(outputs_val[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando VAE para reconstruir dígitos apartir de dígitos reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_digits = 10\n",
    "X_test, y_test = mnist.test.next_batch(n_digits)\n",
    "\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/my_model_variational.ckpt\")\n",
    "    # example + random\n",
    "    codings_val = h3.eval(feed_dict={X: X_test})\n",
    "    codings_rnd = np.random.normal(size=[n_digits, n_h3]) \n",
    "    outputs_val = outputs.eval(feed_dict={h3: codings_val}) \n",
    "    outputs_rnd = outputs.eval(feed_dict={h3: codings_rnd}) \n",
    "    outputs_val_rnd = outputs.eval(feed_dict={h3: 0.6*codings_val + 0.4*codings_rnd})\n",
    "\n",
    "plt.figure(figsize=(8,50)) \n",
    "for i in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, i + 1)\n",
    "    plot_image(outputs_val[i])\n",
    "plt.figure(figsize=(8,50)) \n",
    "for i in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, i + 1)\n",
    "    plot_image(outputs_rnd[i])\n",
    "plt.figure(figsize=(8,50)) \n",
    "for i in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, i + 1)\n",
    "    plot_image(outputs_val_rnd[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando o espaço latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding \n",
    "cases_to_plot = 1000\n",
    "idxs = np.random.permutation(mnist.test.num_examples)[:cases_to_plot]\n",
    "X_test = mnist.test.images[idxs]\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, \"/tmp/my_model_variational.ckpt\")\n",
    "    codings_val = h3.eval(feed_dict={X: X_test})\n",
    "plot_tsne(codings_val, mnist.test.labels[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolando dígitos com VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def linear_interpolation(p0, p1, t):\n",
    "    return p0 + (p1 - p0) * t\n",
    "\n",
    "def spherical_interpolation(p0, p1, t): # SLERP algorithm\n",
    "    omega = np.arccos(np.dot(p0/norm(p0), p1/norm(p1)))\n",
    "    so = np.sin(omega)\n",
    "    return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que além dos citados, há muitos outros tipos de auto-codificadores que merecem atenção:\n",
    "\n",
    "* _Contractive autoencoder_ (CAE): auto-codificador é criado para reforçar a ideia de que entradas similares tenham códigos similares -- Contractive Auto-Encoders: Explicit Invariance During Feature Extraction, S. Rifai et al. (2011).\n",
    "* _Stacked convolutional autoencoder_: apredem a extrair atributos visuais por reconstruir imagens processadas por camadas de convolução.\n",
    "* _Generative stochastic network_ (GSN): generalização da ideia de autocodificadores robustos a ruidos extendidos para gerar dados.\n",
    "* _Winner-take-all (WTA) autoencoder_: um autocodificador esparso que obtem esparsidade por permitie que apeans k% das maiores ativaçãoes sejam preservadas durante o treino (as outras são zeradas).\n",
    "* _Adversarial autoencoder_: uma rede é treinada para reproduzir sua saída enquanto outra é treinada para achar entradas que a primeira nao consegue reconstruir direito. Ao fim do treino, a primeira rede se torna muito robusta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Material baseado no de de Aurélian Géron (_Handson Machine Learning with Scikit-learn and Tensorflow_), de Jaan Altosaar (https://jaan.io/what-is-variational-autoencoder-vae-tutorial/) e de Miriam Shiffman (http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
