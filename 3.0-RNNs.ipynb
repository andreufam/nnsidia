{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Recorrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def plot_figs(lst):\n",
    "    if len(lst) == 1:\n",
    "        plt.matshow(lst[0], cmap = 'gray', interpolation='nearest')\n",
    "    else:\n",
    "        f, axes = plt.subplots(1, len(lst))\n",
    "        for i, a in enumerate(axes):\n",
    "            a.matshow(lst[i], cmap = 'gray', interpolation='nearest')\n",
    "            a.set(aspect='equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma RNN manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN - Recurrent Neural Networks são redes neurais em que os neurônios tem como entrada a sua saída. Desta forma, eles podem formar memórias.\n",
    "\n",
    "Na prática, elas são implementadas como uma arquitetura copiada múltiplas vezes. Há tantas cópias quantas são os instantes de tempo representados no treino. A saída de cada cópia é entrada para a próxima cópia. O exemplo abaixo descreve uma RNN com 3 neurônios de entrada e cinco de saída em uma célula RNN (ou seja, em um instante do tempo). Supondo que temos treinos com 2 instantes de tempo, a rede teria duas céculas, como no diagrama abaixo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn0.png\" alt=\"Exemplo de RNN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta rede pode ser representada da seguinte forma em tensorflow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00664975  0.19543903  0.08291762  0.08832357 -0.1452561 ]\n",
      " [ 0.32749006 -0.09047262 -0.3080786   0.20217195 -0.4571744 ]\n",
      " [ 0.5958438  -0.3622101  -0.61687875  0.31080633 -0.68643117]\n",
      " [ 0.77524525 -0.58375096 -0.8080832   0.4118852  -0.83014977]]\n",
      "[[ 0.83347845 -0.46762687 -0.8774375   0.15186386 -0.87976223]\n",
      " [ 0.91412014 -0.5418827  -0.82953316 -0.377425   -0.9579276 ]\n",
      " [ 0.95737094 -0.68740857 -0.8081518  -0.65423906 -0.98491126]\n",
      " [ 0.97921664 -0.83296067 -0.8362062  -0.75839305 -0.9942514 ]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2\n",
    "                     [0.9, 1.0, 1.1]])  # instance 3\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3], \n",
    "                     [1.4, 1.5, 1.6], \n",
    "                     [1.7, 1.8, 1.9], \n",
    "                     [2.0, 2.1, 2.2]]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede acima pode ser redefinida usando as funções `BasicRNNCell` e `static_rnn`. Note que neste caso, a função retorna tanto as saídas da rede quanto o estado final dela que, neste caso, corresponde a saída para o último intervalo de tempo (o mesmo que `Y1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03175795 -0.03413978 -0.07811595 -0.17084466  0.05769194]\n",
      " [ 0.2647824  -0.1855583  -0.09740025 -0.39423943  0.23090008]\n",
      " [ 0.4705062  -0.3286492  -0.11661167 -0.57908356  0.39061368]\n",
      " [ 0.6352659  -0.45809147 -0.13573624 -0.7188958   0.5298294 ]]\n",
      "[[ 0.6560341  -0.55838895 -0.17331886 -0.7907961   0.6223338 ]\n",
      " [ 0.74668574 -0.7433905  -0.21191065 -0.88804203  0.7498099 ]\n",
      " [ 0.819032   -0.85158527 -0.25492802 -0.9409765   0.8342795 ]\n",
      " [ 0.87409574 -0.9107835  -0.3030455  -0.96864784  0.88883334]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X0_batch = np.array([[0.0, 0.1, 0.2],   # instance 0\n",
    "                     [0.3, 0.4, 0.5],   # instance 1\n",
    "                     [0.6, 0.7, 0.8],   # instance 2\n",
    "                     [0.9, 1.0, 1.1]])  # instance 3\n",
    "# t = 1\n",
    "X1_batch = np.array([[1.1, 1.2, 1.3], \n",
    "                     [1.4, 1.5, 1.6], \n",
    "                     [1.7, 1.8, 1.9], \n",
    "                     [2.0, 2.1, 2.2]]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No último exemplo, ainda tivemos que criar uma entrada para cada instante de tempo. A seguir, vamos automatizar isso também:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "# get list of n_steps tensors with shape [None, n_inputs]\n",
    "Xseqs = tf.unstack(tf.transpose(X, perm = [1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, Xseqs,\n",
    "                                                dtype=tf.float32)\n",
    "# merge outputs and get final shape (batches, steps, outputs)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm = [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.04925115 -0.08284049  0.04345951  0.07417858 -0.04935264]\n",
      "  [-0.31003428 -0.653252    0.2975074   0.7708711  -0.7909568 ]]\n",
      "\n",
      " [[-0.10946348 -0.27015626  0.10460903  0.315636   -0.30657732]\n",
      "  [-0.44478965 -0.74545705  0.48641342  0.8705064  -0.9062193 ]]\n",
      "\n",
      " [[-0.16888303 -0.4390344   0.16497768  0.522135   -0.5256635 ]\n",
      "  [-0.5563627  -0.81515384  0.6256428   0.92795974 -0.95731807]]\n",
      "\n",
      " [[-0.22709988 -0.58170485  0.22413501  0.68141353 -0.69185454]\n",
      "  [-0.64439976 -0.8667141   0.7194453   0.9599478  -0.9795282 ]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals = sess.run(outputs, feed_dict={X: X_batch})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desdobramento dinâmico no tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, contudo, o tensorflow pode poupar todo o trabalho de transposições e mudanças de formas necessárias antes, se usarmos `dynamic_rnn`. De fato, neste caso, o grafo com todas as células para todos instantes no tempo não é realmente criado. O algoritmo usa um laço e controla o processo de atualização de pesos sem consumir tanta memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.12536903  0.13399065  0.06619322  0.14388642 -0.00558078]\n",
      "  [-0.8059542   0.8031025   0.5078612   0.9504994   0.03800523]]\n",
      "\n",
      " [[-0.34022027  0.37258416  0.2275392   0.5296505   0.02574121]\n",
      "  [-0.9282176   0.87433124  0.43983948  0.9863469  -0.02313488]]\n",
      "\n",
      " [[-0.52458966  0.57034886  0.3772894   0.7756776   0.05701271]\n",
      "  [-0.9695717   0.92235357  0.39642462  0.9957257  -0.12818918]]\n",
      "\n",
      " [[-0.6701199   0.71855885  0.5096064   0.9013169   0.08817277]\n",
      "  [-0.98487884  0.9527805   0.3875124   0.9985012  -0.2507346 ]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [1.4, 1.5, 1.6]],   # instance 1\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals = sess.run(outputs, feed_dict={X: X_batch})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulando sequências com tamanho variável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em todos os exemplos acima, nossas entradas tinham o mesmo tamanho. Em muitos problemas, este não é o caso. Por exemplo, em classificação de tweets, cada tweet pode ter um tamanho variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a RNN vai receber sequências de tamanhos diferentes, é necessário informar a lista dos tamanhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_lens = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                   sequence_length = seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, na entrada, as sequências que tem tamanho menor _tem que ser dadas como zero (padding)_ nos intervalos de tempo que não irão aparecer. Por exemplo, supondo que em nosso exemplo anterior, a segunda instância fosse observada apenas no tempo 0 (sequência de tamanho 1), teríamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.02039886  0.12444817  0.16943736 -0.07733408  0.02524563]\n",
      "  [ 0.71817917  0.8689182   0.96358705 -0.47136068  0.27398974]]\n",
      "\n",
      " [[ 0.22861032  0.41079223  0.60151577 -0.22463728  0.09068716]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.41781637  0.6339729   0.8396396  -0.3623429   0.15535478]\n",
      "  [ 0.94111234  0.9610417   0.9878238  -0.4541795   0.49308285]]\n",
      "\n",
      " [[ 0.57660687  0.7854718   0.9407328  -0.4858594   0.21871774]\n",
      "  [ 0.96774274  0.9768544   0.99471605 -0.5186595   0.54894686]]]\n"
     ]
    }
   ],
   "source": [
    "# t = 0\n",
    "X_batch = np.array([[[0.0, 0.1, 0.2], [1.1, 1.2, 1.3]],   # instance 0\n",
    "                    [[0.3, 0.4, 0.5], [0, 0, 0]],         # instance 1 -- padding\n",
    "                    [[0.6, 0.7, 0.8], [1.7, 1.8, 1.9]],   # instance 2\n",
    "                    [[0.9, 1.0, 1.1], [2.0, 2.1, 2.2]]])  # instance 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    out_vals, state_vals = sess.run([outputs, states], \n",
    "                        feed_dict={X: X_batch, seq_lens: [2,1,2,2]})\n",
    "    \n",
    "print(out_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que as saídas para o tempo 2 para a segunda instância são zero. Além disso, observe que o estado final da segunda instância corresponde, de fato, ao seu valor no tempo 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71817917  0.8689182   0.96358705 -0.47136068  0.27398974]\n",
      " [ 0.22861032  0.41079223  0.60151577 -0.22463728  0.09068716]\n",
      " [ 0.94111234  0.9610417   0.9878238  -0.4541795   0.49308285]\n",
      " [ 0.96774274  0.9768544   0.99471605 -0.5186595   0.54894686]]\n"
     ]
    }
   ],
   "source": [
    "print(state_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o caso em que a saída tem tamanho variável, o reconhecimento do fim prematuro será modelado na própria rede. Por exemplo, em tradução, a rede deve emitir uma frase com um número não previamente conhecido de palavras. Assim, a rede deve emitir cada palavra e, quando considerar pertinente, ela emite uma palavra especial que indica _fim de frase_. Ao analisar a saída da rede, são consideradas apenas as palavras observadas antes de _fim de frase_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O mesmo código em Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 3)              0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 2, 5)              45        \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(2, 3))\n",
    "# return_sequences = False (default): output.shaep is (5), ie, output from last timestep\n",
    "# return_sequences = True: output.shaep is (2, 5), ie, output from all timesteps; \n",
    "output = SimpleRNN(5, return_sequences = True)(visible)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia de classificar as imagens da MNIST usando uma RNN consiste em considerar que cada imagem é formada por uma sequência de linhas de pixels, cada linha vista em um instante de tempo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-ae9b31cef56d>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir uma rede em que cada célula RNN tem 150 neurônios. O estado final da RNN (um código com 150 valores) então será entrada para uma rede densa com dez neurônios agregados via softmax, como ilustrado abaixo (nós vermelhos com dimensão 28, verdes com dimensão 150 e azul com dimensão 10; 28 desdobramentos no tempo). \n",
    "\n",
    "<img src=\"images/rnn1.png\" alt=\"Exemplo de RNN\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 150)               26850     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1510      \n",
      "=================================================================\n",
      "Total params: 28,360\n",
      "Trainable params: 28,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "hidden = SimpleRNN(n_neurons, return_sequences = False)(visible)\n",
    "output = Dense(n_outputs, activation = 'softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_images = mnist.train.images.reshape((55000, 28, 28))\n",
    "train_labels = to_categorical(mnist.train.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar a nossa rede usando batches de 150 instâncias: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "49500/49500 [==============================] - 9s 180us/step - loss: 0.4695 - acc: 0.8612 - val_loss: 0.2184 - val_acc: 0.9378\n",
      "Epoch 2/10\n",
      "49500/49500 [==============================] - 9s 172us/step - loss: 0.2017 - acc: 0.9412 - val_loss: 0.1398 - val_acc: 0.9602\n",
      "Epoch 3/10\n",
      "49500/49500 [==============================] - 8s 171us/step - loss: 0.1588 - acc: 0.9529 - val_loss: 0.1368 - val_acc: 0.9595\n",
      "Epoch 4/10\n",
      "49500/49500 [==============================] - 9s 172us/step - loss: 0.1369 - acc: 0.9601 - val_loss: 0.1082 - val_acc: 0.9684\n",
      "Epoch 5/10\n",
      "49500/49500 [==============================] - 8s 171us/step - loss: 0.1190 - acc: 0.9638 - val_loss: 0.1237 - val_acc: 0.9660\n",
      "Epoch 6/10\n",
      "49500/49500 [==============================] - 8s 170us/step - loss: 0.1053 - acc: 0.9683 - val_loss: 0.0983 - val_acc: 0.9716\n",
      "Epoch 7/10\n",
      "49500/49500 [==============================] - 8s 164us/step - loss: 0.0992 - acc: 0.9707 - val_loss: 0.1078 - val_acc: 0.9691\n",
      "Epoch 8/10\n",
      "49500/49500 [==============================] - 8s 164us/step - loss: 0.0920 - acc: 0.9724 - val_loss: 0.0957 - val_acc: 0.9738\n",
      "Epoch 9/10\n",
      "49500/49500 [==============================] - 8s 164us/step - loss: 0.0869 - acc: 0.9742 - val_loss: 0.1011 - val_acc: 0.9715\n",
      "Epoch 10/10\n",
      "49500/49500 [==============================] - 8s 164us/step - loss: 0.0835 - acc: 0.9755 - val_loss: 0.1047 - val_acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "E em tensorflow puro?\n",
    "\n",
    "```python\n",
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                          logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, y, 1), \n",
    "                                  tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "```\n",
    "\n",
    "Treinamento com batches de 150 instâncias: \n",
    "\n",
    "```python\n",
    "with tf.Session() as s:\n",
    "    init.run()\n",
    "    for e in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            s.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print '%d - accuracy tr: %.6f test: %.6f' % (e, acc_train, acc_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando MNIST com uma RNN de 2 camadas\n",
    "\n",
    "Vamos agora modificar nossa RNN para suportar 2 camadas, como no diagrama a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rnn1multi.png\" alt=\"Exemplo de RNN\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar múltiplas camadas em uma RNN com Keras basta empilhá-las. É claro, desta vez, cada camada anterior deve fornecer tanto saídas quanto estados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 28, 100)           12900     \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 34,010\n",
      "Trainable params: 34,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "h1 = SimpleRNN(n_neurons, return_sequences = True)(visible)\n",
    "h2 = SimpleRNN(n_neurons, return_sequences = False)(h1)\n",
    "output = Dense(n_outputs, activation = 'softmax')(h2)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "32700/49500 [==================>...........] - ETA: 5s - loss: 0.5667 - acc: 0.8214"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e81d003780f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit(train_images, train_labels, epochs = n_epochs, \n\u001b[1;32m----> 2\u001b[1;33m                     batch_size = batch_size, validation_split = 0.1)\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note contudo que nossa arquitetura anterior não corresponde exatamente ao diagrama dado, uma vez que a decisão final da rede depende apenas do último estado da última camada. No diagrama, ao contrário, ela depende dos estados finais das duas camadas. Agora que a rede tem tantos estados finais quanto camadas, a representação a ser fornecida para a rede densa pode envolver qualquer agregação dos estados finais. Abaixo, fornecemos uma representação precisa do diagrama dado, modelando a decisão como a concatenação dos estados finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Lambda\n",
    "\n",
    "# time_steps, input_length\n",
    "visible = Input(shape=(n_steps, n_inputs))\n",
    "h1 = SimpleRNN(n_neurons, return_sequences = True)(visible)\n",
    "h2 = SimpleRNN(n_neurons, return_sequences = False)(h1)\n",
    "h1_last = Lambda(lambda x: x[:,-1,:])(h1)\n",
    "merge = Concatenate()([h1_last, h2])\n",
    "output = Dense(n_outputs, activation = 'softmax')(merge)\n",
    "\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um detalhe importante desta implementação é o uso de uma camada Lambda do Keras. Ela permite que do tensor de entrada h1 (com shape (batch_size, n_layers, n_neurons)) sejam obtidos apenas os estados da última camada (ou seja, x[:, -1, :] para x correspondendo ao valor de h1). O estado obtido (h1_last) é concatenado com o estado final da última camada (h2) e dado como entrada para a camada densa. Camadas Lambda permitem que transformações arbitrárias sejam executadas sobre os dados fluindo entre as camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)        (None, 28, 100)      12900       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           simple_rnn_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)        (None, 100)          20100       simple_rnn_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           lambda_1[0][0]                   \n",
      "                                                                 simple_rnn_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           2010        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 35,010\n",
      "Trainable params: 35,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 5500 samples\n",
      "Epoch 1/10\n",
      "49500/49500 [==============================] - 17s 336us/step - loss: 0.4382 - acc: 0.8655 - val_loss: 0.1799 - val_acc: 0.9458\n",
      "Epoch 2/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.1837 - acc: 0.9450 - val_loss: 0.1290 - val_acc: 0.9627\n",
      "Epoch 3/10\n",
      "49500/49500 [==============================] - 15s 309us/step - loss: 0.1382 - acc: 0.9590 - val_loss: 0.1058 - val_acc: 0.9695\n",
      "Epoch 4/10\n",
      "49500/49500 [==============================] - 15s 310us/step - loss: 0.1237 - acc: 0.9630 - val_loss: 0.1018 - val_acc: 0.9718\n",
      "Epoch 5/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.1071 - acc: 0.9686 - val_loss: 0.0995 - val_acc: 0.9720\n",
      "Epoch 6/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0949 - acc: 0.9715 - val_loss: 0.1023 - val_acc: 0.9709\n",
      "Epoch 7/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0923 - acc: 0.9722 - val_loss: 0.0857 - val_acc: 0.9736\n",
      "Epoch 8/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0849 - acc: 0.9744 - val_loss: 0.0715 - val_acc: 0.9795\n",
      "Epoch 9/10\n",
      "49500/49500 [==============================] - 15s 312us/step - loss: 0.0801 - acc: 0.9759 - val_loss: 0.0858 - val_acc: 0.9725\n",
      "Epoch 10/10\n",
      "49500/49500 [==============================] - 16s 315us/step - loss: 0.0787 - acc: 0.9760 - val_loss: 0.0727 - val_acc: 0.9807\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs = n_epochs, \n",
    "                    batch_size = batch_size, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prevendo séries de tempo\n",
    "### Um modelo $n \\times n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos problemas mais comuns em aprendizado de sequência/temporal é previsão de séries de tempo. Neste caso, dada um evento no tempo, o modelo deve prever o resultado do evento no tempo seguinte. Vamos tomar como exemplo o número de passageiros mensal nos EUA entre 1949 e 1961:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "airline = pd.read_csv('data/airline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>1949-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>1949-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>1949-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>1949-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>1949-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengers        date\n",
       "0         112  1949-01-01\n",
       "1         118  1949-02-01\n",
       "2         132  1949-03-01\n",
       "3         129  1949-04-01\n",
       "4         121  1949-05-01"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eaef4d7208>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eaef4e0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series = airline['passengers']\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora preparar a série para supervisão. A idéia é que cada quantidade de passageiros em um certo momento no tempo seja uma variável útil para prever a quantidade no próximo momento no tempo. Vamos usar a operação shift() do pandas para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(series, target, lag = 1):\n",
    "    # transfor to supervised learning\n",
    "    series = series.iloc[1:]\n",
    "    series = pd.concat([series.shift(1), series], axis = 1)\n",
    "    series.fillna(0, inplace=True)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengers</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129.0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121.0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengers  passengers\n",
       "1         0.0         118\n",
       "2       118.0         132\n",
       "3       132.0         129\n",
       "4       129.0         121\n",
       "5       121.0         135"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised = transform_data(series, 'passengers')\n",
    "supervised_values = supervised.values\n",
    "supervised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos separar os dados em treino e teste, onde o teste corresponde ao horizonte de tempo para o qual prentendemos fazer previsões. Por exemplo, vamos considerar um horizonte de 40 meses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "horizon = 40\n",
    "train, test = supervised_values[0:-horizon], supervised_values[-horizon:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar qualquer previsão, os dados devem ser escalados. Aqui vamos usar uma escala simples para colocar os dados entre -1 e 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.92286501],\n",
       "       [-0.49247312, -0.84573003],\n",
       "       [-0.43225806, -0.86225895],\n",
       "       [-0.44516129, -0.90633609]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[:, 0:-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez escalados os dados, podemos treinar a RNN. Neste caso, vamos usar células LSTM. Em particular, consideramos que cada entrada tenha batch_size = 1, se refira a apenas 1 passo de tempo e tem entrada de comprimento 1 (ou seja, se refere a uma única quantidade de passageiros e nenhuma informação adicional). Como este problema é simples, serão usadas células LSTM com apenas 4 blocos.\n",
    "\n",
    "Como queremos que as células lembrem do estado da computação deixada pelo último batch da época atual, deixamos stateful = True. Assim, mesmo embora a entrada tenha apenas 1 passo de tempo, a rede vai ser influenciada por tantos passos de tempo quanto forem os batches processados ao longo da época. Para isso, vamos treinar cada época por vez, executando os batches na ordem temporal (ou seja, shuffle = False). Como a rede é _stateful_, o estado de um batch é enviado ao próximo até que todos tenham sido processados. Neste ponto, reiniciamos o estado da rede, antes de começar uma nova época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    visible = Input(batch_shape=(batch_size, X.shape[1], X.shape[2]))\n",
    "    hidden = LSTM(neurons, stateful=True)(visible)\n",
    "    output = Dense(1)(hidden)\n",
    "    model = Model(inputs = visible, outputs = output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, \n",
    "                  verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, treinamos nossa LSTM para 100 épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 14ms/step - loss: 0.3319\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.2421\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.1492\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0909\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0770\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0671\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0623\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0586\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0557\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0532\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0510\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0490\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0472\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0455\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0440\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0426\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0414\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0404\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0396\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0389\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0383\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0378\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0373\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0369\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0366\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0362\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0359\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0356\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0353\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0350\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0347\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0345\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0342\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0340\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0337\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0335\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0333\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0331\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0329\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 7ms/step - loss: 0.0327\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0325\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0323\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0321\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0320\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0318\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0316\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0315\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0313\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0311\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0310\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0308\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0307\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0305\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0304\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0302\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0301\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0299\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0298\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0297\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0295\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0294\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0293\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0291\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0290\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0289\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0287\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0286\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0285\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0284\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0282\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0281\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0280\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0279\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0278\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0277\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0275\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0274\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0273\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0272\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0271\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0270\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0269\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0268\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0266\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0265\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0264\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0263\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0263\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0262\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0257\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0256\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0255\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0254\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0254\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0253\n",
      "Epoch 1/1\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.0252\n"
     ]
    }
   ],
   "source": [
    "lstm_model = fit_lstm(train_scaled, 1, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos usar o modelo para prever a série. Para cada elemento do conjunto de teste (X), o modelo prevê o próximo valor (yhat). O valor previsto yhat é corrigido em escala e adicionado ao conjunto de previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X = test_scaled[i, 0:-1] \n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # store forecast\n",
    "    predictions += [yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho final obtido pode ser medido em termos de RMSE e observado graficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 62.302\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(series.values[-horizon:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Time')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRG+MMXHOEr0xxsQ5S/TGGBPn/h8oI8e4VMR0ogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eaf548c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Test for horizon = \" + str(horizon), fontsize=14)\n",
    "plt.plot(series.values[-horizon:], \"-\", markersize=5)\n",
    "plt.plot(series.values[-horizon:], \"bo\", markersize=5, label=\"real\")\n",
    "plt.plot(predictions, \"-\", markersize=10)\n",
    "plt.plot(predictions, \"w*\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Material derivado do livro _Handson Machine Learning with Scikit-learn and Tensorflow_, de Aurélian Géron. A aula sobre Keras usado como previsor de séries de tempo foi baseada no material de Jason Browlee, disponível em https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
